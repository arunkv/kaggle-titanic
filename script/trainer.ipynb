{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training and test data files\n",
    "train_file = '../input/train.csv'\n",
    "test_file = '../input/test.csv'\n",
    "model_file = '../output/titanic.model.json'\n",
    "model_weights_file = '../output/titanic.model.best.hdf5'\n",
    "pred_file = '../output/gender_submission.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 12)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load training data\n",
    "df_train_raw = pd.read_csv(train_file)\n",
    "print(df_train_raw.shape)\n",
    "df_train_raw.info()\n",
    "df_train_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prepare the data for training and testing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "max_name_len = df_train_raw.Name.map(len).max()\n",
    "max_ticket_len = df_train_raw.Ticket.map(len).max()\n",
    "\n",
    "title_list=['Mrs', 'Mr', 'Master', 'Miss', 'Major', 'Rev', 'Dr', 'Ms', 'Mlle',\n",
    "            'Col', 'Capt', 'Mme', 'Countess', 'Don', 'Jonkheer']\n",
    "\n",
    "import string\n",
    "def substrings_in_string(big_string, substrings):\n",
    "    for substring in substrings:\n",
    "        if substring in big_string:\n",
    "            return substring\n",
    "    return np.nan\n",
    "\n",
    "def prep_data(frame, mode='test'):\n",
    "    # Fill missing Age data with median \n",
    "    frame['Age'] = frame['Age'].fillna(frame['Age'].mean())\n",
    "    \n",
    "    # Generate data about whether adult or minor\n",
    "    frame['Adult_Or_Minor'] = frame.apply(lambda row: 0 if row['Age'] < 18 else 1, axis=1)\n",
    "\n",
    "    # Generate data about whether senior citizen\n",
    "    frame['Senior_Citizen'] = frame.apply(lambda row: 0 if row['Age'] > 65 else 1, axis=1)\n",
    "\n",
    "    # Fill missing Fare data with median\n",
    "    frame['Fare'] = frame['Fare'].fillna(frame['Fare'].median())\n",
    "    \n",
    "    # Creating new family_size and fare per person columns \n",
    "    frame['Family_Size'] = frame['SibSp'] + frame['Parch'] + 1\n",
    "    frame['Alone'] = frame.apply(lambda row: 1 if row['Family_Size'] == 1 else 0, axis=1)\n",
    "    frame['Fare_Per_Person'] = frame['Fare']/frame['Family_Size']\n",
    "\n",
    "    # Convert Sex to number\n",
    "    frame['Sex'] = pd.Categorical(frame['Sex']).codes\n",
    "\n",
    "    # Generate data for missing Embarked and convert to number\n",
    "    frame['Embarked'] = frame['Embarked'].fillna('X')\n",
    "    frame['Embarked'] = pd.Categorical(frame['Embarked']).codes\n",
    "    \n",
    "    # Extract title from name\n",
    "    frame['Title'] = frame['Name'].map(lambda x: substrings_in_string(x, title_list))\n",
    "    frame['Title'] = pd.Categorical(frame['Title']).codes\n",
    "\n",
    "    # Convert Name into characters\n",
    "    frame['Name_Length'] = frame.apply(lambda row: len(row['Name']), axis=1)\n",
    "    frame['Words_In_Name'] = frame.apply(lambda row: len(row['Name'].split()), axis=1)    \n",
    "#    for i in range(0, max_name_len):\n",
    "#        col_name = 'Name' + str(i)\n",
    "#        frame[col_name] = frame['Name'].str[i]\n",
    "#        frame[col_name] = frame.apply(lambda row: 0 if isinstance(row[col_name], float) and math.isnan(row[col_name]) else ord(row[col_name]), axis=1)\n",
    "    frame.pop('Name')    \n",
    "    \n",
    "    # Convert Ticket into characters\n",
    "    frame['Ticket_Length'] = frame.apply(lambda row: len(row['Ticket']), axis=1)\n",
    "#    for i in range(0, max_ticket_len):\n",
    "#        col_name = 'Ticket' + str(i)\n",
    "#        frame[col_name] = frame['Ticket'].str[i]\n",
    "#        frame[col_name] = frame.apply(lambda row: 0 if isinstance(row[col_name], float) and math.isnan(row[col_name]) else ord(row[col_name]), axis=1)\n",
    "    frame.pop('Ticket')    \n",
    "    \n",
    "    # Convert Cabin column to whether in cabin\n",
    "    frame['Cabin'] = frame['Cabin'].fillna('')\n",
    "    frame['In_Cabin'] = frame.apply(lambda row: 1 if row['Cabin'] != '' else 0, axis=1)\n",
    "    frame['Number_Of_Cabins'] = frame.apply(lambda row: len(row['Cabin'].split()), axis=1)    \n",
    "    frame.pop('Cabin')\n",
    "    \n",
    "    frame.fillna(0, axis=1)\n",
    "    \n",
    "    # Introduce rows with some noise\n",
    "    if (mode == 'augment'):\n",
    "        print('Adding more rows to training data')\n",
    "        row_count = frame.shape[0]\n",
    "        print('Row count before: ', row_count)\n",
    "        col_std = np.std(frame) \n",
    "        for i in range(0, row_count):\n",
    "            row1 = pd.Series(frame.iloc[i])\n",
    "            row2 = pd.Series(frame.iloc[i])\n",
    "            col_list = frame.columns.tolist()\n",
    "            col_list.remove('PassengerId')\n",
    "            col_list.remove('Survived')\n",
    "            for col in frame.columns.tolist():\n",
    "                row1[col] = row1[col] + np.random.random_sample() * col_std[col]\n",
    "                row2[col] = row2[col] - np.random.random_sample() * col_std[col]\n",
    "            if np.random.random_sample() < 0.33:\n",
    "                frame = frame.append(row1)\n",
    "            if np.random.random_sample() > 0.66:\n",
    "                frame = frame.append(row2)\n",
    "        row_count = frame.shape[0]\n",
    "        print('Row count after: ', row_count)\n",
    "    \n",
    "    \n",
    "    print(\"Before scaling: \")\n",
    "    print(frame.head())\n",
    "    \n",
    "    # Scale everything except PassengerId\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    col_list = frame.columns.tolist()\n",
    "    col_list.remove('PassengerId')\n",
    "    frame = frame[col_list]\n",
    "    np_scaled = min_max_scaler.fit_transform(frame)\n",
    "    frame = pd.DataFrame(np_scaled)\n",
    "    \n",
    "    print(\"After scaling: \")\n",
    "    print(frame.head())\n",
    "\n",
    "    return frame\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before scaling: \n",
      "   PassengerId  Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked  \\\n",
      "0            1         0       3    1  22.0      1      0   7.2500         2   \n",
      "1            2         1       1    0  38.0      1      0  71.2833         0   \n",
      "2            3         1       3    0  26.0      0      0   7.9250         2   \n",
      "3            4         1       1    0  35.0      1      0  53.1000         2   \n",
      "4            5         0       3    1  35.0      0      0   8.0500         2   \n",
      "\n",
      "   Adult_Or_Minor  Senior_Citizen  Family_Size  Alone  Fare_Per_Person  Title  \\\n",
      "0               1               1            2      0          3.62500     11   \n",
      "1               1               1            2      0         35.64165     12   \n",
      "2               1               1            1      1          7.92500      8   \n",
      "3               1               1            2      0         26.55000     12   \n",
      "4               1               1            1      1          8.05000     11   \n",
      "\n",
      "   Name_Length  Words_In_Name  Ticket_Length  In_Cabin  Number_Of_Cabins  \n",
      "0           23              4              9         0                 0  \n",
      "1           51              7              8         1                 1  \n",
      "2           22              3             16         0                 0  \n",
      "3           44              7              6         1                 1  \n",
      "4           24              4              6         0                 0  \n",
      "After scaling: \n",
      "    0    1    2         3      4    5         6         7    8    9    10  \\\n",
      "0  0.0  1.0  1.0  0.271174  0.125  0.0  0.014151  0.666667  1.0  1.0  0.1   \n",
      "1  1.0  0.0  0.0  0.472229  0.125  0.0  0.139136  0.000000  1.0  1.0  0.1   \n",
      "2  1.0  1.0  0.0  0.321438  0.000  0.0  0.015469  0.666667  1.0  1.0  0.0   \n",
      "3  1.0  0.0  0.0  0.434531  0.125  0.0  0.103644  0.666667  1.0  1.0  0.1   \n",
      "4  0.0  1.0  1.0  0.434531  0.000  0.0  0.015713  0.666667  1.0  1.0  0.0   \n",
      "\n",
      "    11        12        13        14        15        16   17    18  \n",
      "0  0.0  0.007076  0.785714  0.157143  0.090909  0.400000  0.0  0.00  \n",
      "1  0.0  0.069568  0.857143  0.557143  0.363636  0.333333  1.0  0.25  \n",
      "2  1.0  0.015469  0.571429  0.142857  0.000000  0.866667  0.0  0.00  \n",
      "3  0.0  0.051822  0.857143  0.457143  0.363636  0.200000  1.0  0.25  \n",
      "4  1.0  0.015713  0.785714  0.171429  0.090909  0.200000  0.0  0.00  \n",
      "(891, 18)\n",
      "[ 1.          1.          0.27117366  0.125       0.          0.01415106\n",
      "  0.66666669  1.          1.          0.1         0.          0.00707553\n",
      "  0.78571427  0.15714286  0.09090909  0.40000001  0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "# Prep training data\n",
    "df_train = prep_data(df_train_raw, mode='test')\n",
    "\n",
    "# Construct the X array\n",
    "X_train = np.array(df_train)[:,1:]\n",
    "X_train = X_train.astype('float32')\n",
    "print(X_train.shape)\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 2)\n",
      "[[ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]]\n"
     ]
    }
   ],
   "source": [
    "# Extract survived data as predictions\n",
    "from keras.utils.np_utils import to_categorical\n",
    "y_train = np.array(df_train)[:,0]\n",
    "y_train = y_train.astype('int')\n",
    "y_train = to_categorical(y_train, 2)\n",
    "print(y_train.shape)\n",
    "print(y_train[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(418, 11)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      "PassengerId    418 non-null int64\n",
      "Pclass         418 non-null int64\n",
      "Name           418 non-null object\n",
      "Sex            418 non-null object\n",
      "Age            332 non-null float64\n",
      "SibSp          418 non-null int64\n",
      "Parch          418 non-null int64\n",
      "Ticket         418 non-null object\n",
      "Fare           417 non-null float64\n",
      "Cabin          91 non-null object\n",
      "Embarked       418 non-null object\n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# Load test data\n",
    "df_test_raw = pd.read_csv(test_file)\n",
    "print(df_test_raw.shape)\n",
    "df_test_raw.head()\n",
    "df_test_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before scaling: \n",
      "   PassengerId  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked  \\\n",
      "0          892       3    1  34.5      0      0   7.8292         1   \n",
      "1          893       3    0  47.0      1      0   7.0000         2   \n",
      "2          894       2    1  62.0      0      0   9.6875         1   \n",
      "3          895       3    1  27.0      0      0   8.6625         2   \n",
      "4          896       3    0  22.0      1      1  12.2875         2   \n",
      "\n",
      "   Adult_Or_Minor  Senior_Citizen  Family_Size  Alone  Fare_Per_Person  Title  \\\n",
      "0               1               1            1      1         7.829200      5   \n",
      "1               1               1            2      0         3.500000      6   \n",
      "2               1               1            1      1         9.687500      5   \n",
      "3               1               1            1      1         8.662500      5   \n",
      "4               1               1            3      0         4.095833      6   \n",
      "\n",
      "   Name_Length  Words_In_Name  Ticket_Length  In_Cabin  Number_Of_Cabins  \n",
      "0           16              3              6         0                 0  \n",
      "1           32              5              6         0                 0  \n",
      "2           25              4              6         0                 0  \n",
      "3           16              3              6         0                 0  \n",
      "4           44              6              7         0                 0  \n",
      "After scaling: \n",
      "    0    1         2      3         4         5    6    7    8    9    10  \\\n",
      "0  1.0  1.0  0.452723  0.000  0.000000  0.015282  0.5  1.0  1.0  0.0  1.0   \n",
      "1  1.0  0.0  0.617566  0.125  0.000000  0.013663  1.0  1.0  1.0  0.1  0.0   \n",
      "2  0.5  1.0  0.815377  0.000  0.000000  0.018909  0.5  1.0  1.0  0.0  1.0   \n",
      "3  1.0  1.0  0.353818  0.000  0.000000  0.016908  1.0  1.0  1.0  0.0  1.0   \n",
      "4  1.0  0.0  0.287881  0.125  0.111111  0.023984  1.0  1.0  1.0  0.2  0.0   \n",
      "\n",
      "         11     12    13   14        15   16   17  \n",
      "0  0.029840  0.625  0.06  0.0  0.200000  0.0  0.0  \n",
      "1  0.013340  0.750  0.38  0.4  0.200000  0.0  0.0  \n",
      "2  0.036922  0.625  0.24  0.2  0.200000  0.0  0.0  \n",
      "3  0.033016  0.625  0.06  0.0  0.200000  0.0  0.0  \n",
      "4  0.015611  0.750  0.62  0.6  0.266667  0.0  0.0  \n",
      "(418, 18)\n",
      "[ 1.          1.          0.45272321  0.          0.          0.01528158\n",
      "  0.5         1.          1.          0.          1.          0.02983973\n",
      "  0.625       0.06        0.          0.2         0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "# Prepare the data for testing\n",
    "df_test = prep_data(df_test_raw)\n",
    "\n",
    "# Construct the X array\n",
    "X_test = np.array(df_test)[:,:]\n",
    "X_test = X_test.astype('float32')\n",
    "print(X_test.shape)\n",
    "print(X_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 891)               16929     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 891)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 445)               396940    \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 445)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 222)               99012     \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 222)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 2)                 446       \n",
      "=================================================================\n",
      "Total params: 513,327\n",
      "Trainable params: 513,327\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build a training network\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, RepeatVector, Flatten, Activation\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(891, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(445, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(222, activation='relu'))\n",
    "model.add(Dropout(0.75))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model_json = model.to_json()\n",
    "with open(model_file, 'w') as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 623 samples, validate on 268 samples\n",
      "Epoch 1/200\n",
      "580/623 [==========================>...] - ETA: 0s - loss: 0.6285 - acc: 0.6345Epoch 00000: val_loss improved from inf to 0.51131, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 1s - loss: 0.6253 - acc: 0.6388 - val_loss: 0.5113 - val_acc: 0.7892\n",
      "Epoch 2/200\n",
      "620/623 [============================>.] - ETA: 0s - loss: 0.5310 - acc: 0.7597Epoch 00001: val_loss improved from 0.51131 to 0.44184, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 1s - loss: 0.5321 - acc: 0.7592 - val_loss: 0.4418 - val_acc: 0.7910\n",
      "Epoch 3/200\n",
      "620/623 [============================>.] - ETA: 0s - loss: 0.4897 - acc: 0.7992Epoch 00002: val_loss improved from 0.44184 to 0.42475, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 1s - loss: 0.4935 - acc: 0.7970 - val_loss: 0.4248 - val_acc: 0.8022\n",
      "Epoch 4/200\n",
      "580/623 [==========================>...] - ETA: 0s - loss: 0.4911 - acc: 0.7698Epoch 00003: val_loss improved from 0.42475 to 0.41049, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 1s - loss: 0.4935 - acc: 0.7673 - val_loss: 0.4105 - val_acc: 0.8228\n",
      "Epoch 5/200\n",
      "580/623 [==========================>...] - ETA: 0s - loss: 0.4578 - acc: 0.8103Epoch 00004: val_loss improved from 0.41049 to 0.40455, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 1s - loss: 0.4688 - acc: 0.8042 - val_loss: 0.4046 - val_acc: 0.8284\n",
      "Epoch 6/200\n",
      "620/623 [============================>.] - ETA: 0s - loss: 0.4843 - acc: 0.8016Epoch 00005: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4836 - acc: 0.8010 - val_loss: 0.4221 - val_acc: 0.8190\n",
      "Epoch 7/200\n",
      "600/623 [===========================>..] - ETA: 0s - loss: 0.4392 - acc: 0.8200Epoch 00006: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4424 - acc: 0.8210 - val_loss: 0.4484 - val_acc: 0.8004\n",
      "Epoch 8/200\n",
      "620/623 [============================>.] - ETA: 0s - loss: 0.4662 - acc: 0.8097Epoch 00007: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4691 - acc: 0.8090 - val_loss: 0.4280 - val_acc: 0.7985\n",
      "Epoch 9/200\n",
      "560/623 [=========================>....] - ETA: 0s - loss: 0.4597 - acc: 0.8107Epoch 00008: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4561 - acc: 0.8130 - val_loss: 0.4138 - val_acc: 0.8302\n",
      "Epoch 10/200\n",
      "600/623 [===========================>..] - ETA: 0s - loss: 0.4576 - acc: 0.8225Epoch 00009: val_loss improved from 0.40455 to 0.38954, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 1s - loss: 0.4525 - acc: 0.8242 - val_loss: 0.3895 - val_acc: 0.8396\n",
      "Epoch 11/200\n",
      "620/623 [============================>.] - ETA: 0s - loss: 0.4299 - acc: 0.8194Epoch 00010: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4288 - acc: 0.8202 - val_loss: 0.3951 - val_acc: 0.8340\n",
      "Epoch 12/200\n",
      "580/623 [==========================>...] - ETA: 0s - loss: 0.4305 - acc: 0.8336Epoch 00011: val_loss improved from 0.38954 to 0.37830, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 1s - loss: 0.4297 - acc: 0.8347 - val_loss: 0.3783 - val_acc: 0.8396\n",
      "Epoch 13/200\n",
      "600/623 [===========================>..] - ETA: 0s - loss: 0.4420 - acc: 0.8208Epoch 00012: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4471 - acc: 0.8170 - val_loss: 0.3925 - val_acc: 0.8470\n",
      "Epoch 14/200\n",
      "600/623 [===========================>..] - ETA: 0s - loss: 0.4435 - acc: 0.8192Epoch 00013: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4386 - acc: 0.8226 - val_loss: 0.3825 - val_acc: 0.8451\n",
      "Epoch 15/200\n",
      "620/623 [============================>.] - ETA: 0s - loss: 0.4318 - acc: 0.8258- ETA: 0s - loss: 0.4722 - accEpoch 00014: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4300 - acc: 0.8266 - val_loss: 0.4030 - val_acc: 0.8451\n",
      "Epoch 16/200\n",
      "620/623 [============================>.] - ETA: 0s - loss: 0.4203 - acc: 0.8298Epoch 00015: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4234 - acc: 0.8274 - val_loss: 0.3888 - val_acc: 0.8377\n",
      "Epoch 17/200\n",
      "620/623 [============================>.] - ETA: 0s - loss: 0.4276 - acc: 0.8339Epoch 00016: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4275 - acc: 0.8331 - val_loss: 0.3827 - val_acc: 0.8414\n",
      "Epoch 18/200\n",
      "620/623 [============================>.] - ETA: 0s - loss: 0.4342 - acc: 0.8363Epoch 00017: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4362 - acc: 0.8355 - val_loss: 0.3938 - val_acc: 0.8433\n",
      "Epoch 19/200\n",
      "600/623 [===========================>..] - ETA: 0s - loss: 0.4331 - acc: 0.8167Epoch 00018: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4312 - acc: 0.8186 - val_loss: 0.3920 - val_acc: 0.8451\n",
      "Epoch 20/200\n",
      "580/623 [==========================>...] - ETA: 0s - loss: 0.4053 - acc: 0.8319Epoch 00019: val_loss improved from 0.37830 to 0.37678, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 2s - loss: 0.4014 - acc: 0.8387 - val_loss: 0.3768 - val_acc: 0.8451\n",
      "Epoch 21/200\n",
      "580/623 [==========================>...] - ETA: 0s - loss: 0.4173 - acc: 0.8250Epoch 00020: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4198 - acc: 0.8242 - val_loss: 0.3851 - val_acc: 0.8321\n",
      "Epoch 22/200\n",
      "580/623 [==========================>...] - ETA: 0s - loss: 0.4293 - acc: 0.8353- ETA: 0s - loss: 0.3661 - acc: 0Epoch 00021: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4282 - acc: 0.8347 - val_loss: 0.4007 - val_acc: 0.8358\n",
      "Epoch 23/200\n",
      "600/623 [===========================>..] - ETA: 0s - loss: 0.3962 - acc: 0.8383Epoch 00022: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4061 - acc: 0.8355 - val_loss: 0.3943 - val_acc: 0.8489\n",
      "Epoch 24/200\n",
      "600/623 [===========================>..] - ETA: 0s - loss: 0.4127 - acc: 0.8217- ETA: 0s - loss: 0.4126 - accEpoch 00023: val_loss did not improve\n",
      "623/623 [==============================] - 1s - loss: 0.4055 - acc: 0.8266 - val_loss: 0.3953 - val_acc: 0.8396\n",
      "Epoch 25/200\n",
      "580/623 [==========================>...] - ETA: 0s - loss: 0.4095 - acc: 0.8362Epoch 00024: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4107 - acc: 0.8387 - val_loss: 0.4384 - val_acc: 0.8358\n",
      "Epoch 26/200\n",
      "580/623 [==========================>...] - ETA: 0s - loss: 0.4092 - acc: 0.8241Epoch 00025: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4109 - acc: 0.8218 - val_loss: 0.3928 - val_acc: 0.8470\n",
      "Epoch 27/200\n",
      "600/623 [===========================>..] - ETA: 0s - loss: 0.4069 - acc: 0.8383Epoch 00026: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4073 - acc: 0.8395 - val_loss: 0.3979 - val_acc: 0.8377\n",
      "Epoch 28/200\n",
      "580/623 [==========================>...] - ETA: 0s - loss: 0.4182 - acc: 0.8319Epoch 00027: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4073 - acc: 0.8355 - val_loss: 0.4019 - val_acc: 0.8321\n",
      "Epoch 29/200\n",
      "600/623 [===========================>..] - ETA: 0s - loss: 0.4035 - acc: 0.8333Epoch 00028: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.3979 - acc: 0.8363 - val_loss: 0.4068 - val_acc: 0.8358\n",
      "Epoch 30/200\n",
      "620/623 [============================>.] - ETA: 0s - loss: 0.4045 - acc: 0.8258Epoch 00029: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4032 - acc: 0.8266 - val_loss: 0.4053 - val_acc: 0.8470\n",
      "Epoch 31/200\n",
      "600/623 [===========================>..] - ETA: 0s - loss: 0.3849 - acc: 0.8392Epoch 00030: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.3889 - acc: 0.8363 - val_loss: 0.4092 - val_acc: 0.8377\n",
      "Epoch 00030: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "checkpointer = ModelCheckpoint(filepath=model_weights_file, verbose=1, save_best_only=True)\n",
    "stopper = EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=10, verbose=1, mode='auto')\n",
    "hist = model.fit(X_train, y_train, epochs=200, batch_size=20, validation_split=0.3,\n",
    "                 callbacks=[checkpointer, stopper], \n",
    "                 verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/891 [=========================>....] - ETA: 0s\n",
      "Training Accuracy: 0.844556678559\n"
     ]
    }
   ],
   "source": [
    "# Load the weights that yielded the best validation accuracy\n",
    "model.load_weights(model_weights_file)\n",
    "\n",
    "# Evaluate the model on the training set\n",
    "score = model.evaluate(X_train, y_train)\n",
    "print(\"\\nTraining Accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.90940678  0.09485527]\n"
     ]
    }
   ],
   "source": [
    "# Predict for test data\n",
    "y_test = model.predict(X_test)\n",
    "print(y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save predictions\n",
    "with open(pred_file, 'w') as f:\n",
    "    f.write('PassengerId,Survived\\n')\n",
    "    for index, y_hat in enumerate(y_test):\n",
    "        prediction = np.argmax(y_hat)\n",
    "        f.write(str(int(df_test_raw.iloc[index]['PassengerId'])) + ',' + str(prediction)+'\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done 2434 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done 3184 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done 4034 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=-1)]: Done 4984 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=-1)]: Done 6034 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=-1)]: Done 7184 tasks      | elapsed:    9.7s\n",
      "[Parallel(n_jobs=-1)]: Done 8434 tasks      | elapsed:   11.4s\n",
      "[Parallel(n_jobs=-1)]: Done 9784 tasks      | elapsed:   13.2s\n",
      "[Parallel(n_jobs=-1)]: Done 11234 tasks      | elapsed:   15.2s\n",
      "[Parallel(n_jobs=-1)]: Done 12784 tasks      | elapsed:   17.3s\n",
      "[Parallel(n_jobs=-1)]: Done 14434 tasks      | elapsed:   19.5s\n",
      "[Parallel(n_jobs=-1)]: Done 16184 tasks      | elapsed:   21.8s\n",
      "[Parallel(n_jobs=-1)]: Done 18034 tasks      | elapsed:   24.3s\n",
      "[Parallel(n_jobs=-1)]: Done 19984 tasks      | elapsed:   26.9s\n",
      "[Parallel(n_jobs=-1)]: Done 20000 out of 20000 | elapsed:   27.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done 2434 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done 3184 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done 4034 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done 4984 tasks      | elapsed:    6.7s\n",
      "[Parallel(n_jobs=-1)]: Done 6034 tasks      | elapsed:    8.1s\n",
      "[Parallel(n_jobs=-1)]: Done 7184 tasks      | elapsed:    9.7s\n",
      "[Parallel(n_jobs=-1)]: Done 8434 tasks      | elapsed:   11.3s\n",
      "[Parallel(n_jobs=-1)]: Done 9784 tasks      | elapsed:   13.1s\n",
      "[Parallel(n_jobs=-1)]: Done 11234 tasks      | elapsed:   14.9s\n",
      "[Parallel(n_jobs=-1)]: Done 12784 tasks      | elapsed:   16.9s\n",
      "[Parallel(n_jobs=-1)]: Done 14434 tasks      | elapsed:   19.1s\n",
      "[Parallel(n_jobs=-1)]: Done 16184 tasks      | elapsed:   21.4s\n",
      "[Parallel(n_jobs=-1)]: Done 18034 tasks      | elapsed:   23.8s\n",
      "[Parallel(n_jobs=-1)]: Done 19984 tasks      | elapsed:   26.3s\n",
      "[Parallel(n_jobs=-1)]: Done 20000 out of 20000 | elapsed:   26.3s finished\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done 1234 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=8)]: Done 1784 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=8)]: Done 2434 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=8)]: Done 3184 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=8)]: Done 4034 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=8)]: Done 4984 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=8)]: Done 6034 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=8)]: Done 7184 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=8)]: Done 8434 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=8)]: Done 9784 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=8)]: Done 11234 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=8)]: Done 12784 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=8)]: Done 14434 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=8)]: Done 16184 tasks      | elapsed:    6.6s\n",
      "[Parallel(n_jobs=8)]: Done 18034 tasks      | elapsed:    7.4s\n",
      "[Parallel(n_jobs=8)]: Done 19984 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=8)]: Done 20000 out of 20000 | elapsed:    8.2s finished\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done 2434 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done 3184 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done 4034 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=-1)]: Done 4984 tasks      | elapsed:    6.5s\n",
      "[Parallel(n_jobs=-1)]: Done 6034 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=-1)]: Done 7184 tasks      | elapsed:    9.3s\n",
      "[Parallel(n_jobs=-1)]: Done 8434 tasks      | elapsed:   11.0s\n",
      "[Parallel(n_jobs=-1)]: Done 9784 tasks      | elapsed:   12.7s\n",
      "[Parallel(n_jobs=-1)]: Done 11234 tasks      | elapsed:   14.6s\n",
      "[Parallel(n_jobs=-1)]: Done 12784 tasks      | elapsed:   16.6s\n",
      "[Parallel(n_jobs=-1)]: Done 14434 tasks      | elapsed:   18.7s\n",
      "[Parallel(n_jobs=-1)]: Done 16184 tasks      | elapsed:   21.5s\n",
      "[Parallel(n_jobs=-1)]: Done 18034 tasks      | elapsed:   23.9s\n",
      "[Parallel(n_jobs=-1)]: Done 19984 tasks      | elapsed:   26.4s\n",
      "[Parallel(n_jobs=-1)]: Done 20000 out of 20000 | elapsed:   26.4s finished\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done 1234 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=8)]: Done 1784 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=8)]: Done 2434 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=8)]: Done 3184 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=8)]: Done 4034 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=8)]: Done 4984 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=8)]: Done 6034 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=8)]: Done 7184 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=8)]: Done 8434 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=8)]: Done 9784 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=8)]: Done 11234 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=8)]: Done 12784 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=8)]: Done 14434 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=8)]: Done 16184 tasks      | elapsed:    6.7s\n",
      "[Parallel(n_jobs=8)]: Done 18034 tasks      | elapsed:    7.5s\n",
      "[Parallel(n_jobs=8)]: Done 19984 tasks      | elapsed:    8.3s\n",
      "[Parallel(n_jobs=8)]: Done 20000 out of 20000 | elapsed:    8.3s finished\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done 2434 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done 3184 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done 4034 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=-1)]: Done 4984 tasks      | elapsed:    6.5s\n",
      "[Parallel(n_jobs=-1)]: Done 6034 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=-1)]: Done 7184 tasks      | elapsed:    9.4s\n",
      "[Parallel(n_jobs=-1)]: Done 8434 tasks      | elapsed:   11.0s\n",
      "[Parallel(n_jobs=-1)]: Done 9784 tasks      | elapsed:   12.8s\n",
      "[Parallel(n_jobs=-1)]: Done 11234 tasks      | elapsed:   14.7s\n",
      "[Parallel(n_jobs=-1)]: Done 12784 tasks      | elapsed:   16.7s\n",
      "[Parallel(n_jobs=-1)]: Done 14434 tasks      | elapsed:   18.9s\n",
      "[Parallel(n_jobs=-1)]: Done 16184 tasks      | elapsed:   21.1s\n",
      "[Parallel(n_jobs=-1)]: Done 18034 tasks      | elapsed:   23.5s\n",
      "[Parallel(n_jobs=-1)]: Done 19984 tasks      | elapsed:   26.1s\n",
      "[Parallel(n_jobs=-1)]: Done 20000 out of 20000 | elapsed:   26.1s finished\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done 1234 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=8)]: Done 1784 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=8)]: Done 2434 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=8)]: Done 3184 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=8)]: Done 4034 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=8)]: Done 4984 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=8)]: Done 6034 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=8)]: Done 7184 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=8)]: Done 8434 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=8)]: Done 9784 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=8)]: Done 11234 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=8)]: Done 12784 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=8)]: Done 14434 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=8)]: Done 16184 tasks      | elapsed:    6.6s\n",
      "[Parallel(n_jobs=8)]: Done 18034 tasks      | elapsed:    7.4s\n",
      "[Parallel(n_jobs=8)]: Done 19984 tasks      | elapsed:    8.1s\n",
      "[Parallel(n_jobs=8)]: Done 20000 out of 20000 | elapsed:    8.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.81705948372615034"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use random forest classification \n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=20000, warm_start=True, n_jobs=-1, random_state=0, verbose=1)\n",
    "clf.fit(X_train, y_train)\n",
    "scores = cross_val_score(clf, X_train, y_train)\n",
    "scores.mean()     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done 1234 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=8)]: Done 1784 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=8)]: Done 2434 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=8)]: Done 3184 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=8)]: Done 4034 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=8)]: Done 4984 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=8)]: Done 6034 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=8)]: Done 7184 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=8)]: Done 8434 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=8)]: Done 9784 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=8)]: Done 11234 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=8)]: Done 12784 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=8)]: Done 14434 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=8)]: Done 16184 tasks      | elapsed:    7.0s\n",
      "[Parallel(n_jobs=8)]: Done 18034 tasks      | elapsed:    7.8s\n",
      "[Parallel(n_jobs=8)]: Done 19984 tasks      | elapsed:    8.7s\n",
      "[Parallel(n_jobs=8)]: Done 20000 out of 20000 | elapsed:    8.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  0.]\n"
     ]
    }
   ],
   "source": [
    "y_test = clf.predict(X_test)\n",
    "print(y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
