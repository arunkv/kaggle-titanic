{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training and test data files\n",
    "train_file = '../input/train.csv'\n",
    "test_file = '../input/test.csv'\n",
    "model_file_male = '../output/titanic.model.male.json'\n",
    "model_weights_file_male = '../output/titanic.model.male.best.hdf5'\n",
    "model_file_female = '../output/titanic.model.female.json'\n",
    "model_weights_file_female = '../output/titanic.model.female.best.hdf5'\n",
    "pred_file = '../output/gender_submission.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prepare the data for training and testing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "title_list=['Mrs', 'Mr', 'Master', 'Miss', 'Major', 'Rev', 'Dr', 'Ms', 'Mlle',\n",
    "            'Col', 'Capt', 'Mme', 'Countess', 'Don', 'Jonkheer']\n",
    "\n",
    "import string\n",
    "def substrings_in_string(big_string, substrings):\n",
    "    for substring in substrings:\n",
    "        if substring in big_string:\n",
    "            return substring\n",
    "    return np.nan\n",
    "\n",
    "def prep_data(frame, augmentation=0):\n",
    "    # Fill missing Age data with median \n",
    "    frame['Age'] = frame['Age'].fillna(frame['Age'].mean())\n",
    "    \n",
    "    # Generate data about whether adult or minor\n",
    "    frame['Adult_Or_Minor'] = frame.apply(lambda row: 0 if row['Age'] < 18 else 1, axis=1)\n",
    "\n",
    "    # Generate data about whether senior citizen\n",
    "    frame['Senior_Citizen'] = frame.apply(lambda row: 0 if row['Age'] > 65 else 1, axis=1)\n",
    "\n",
    "    # Fill missing Fare data with median\n",
    "    frame['Fare'] = frame['Fare'].fillna(frame['Fare'].median())\n",
    "    \n",
    "    # Creating new family_size and fare per person columns \n",
    "    frame['Family_Size'] = frame['SibSp'] + frame['Parch'] + 1\n",
    "    frame['Alone'] = frame.apply(lambda row: 1 if row['Family_Size'] == 1 else 0, axis=1)\n",
    "    frame['Fare_Per_Person'] = frame['Fare']/frame['Family_Size']\n",
    "\n",
    "    # Convert Sex to number\n",
    "    #frame['Sex'] = pd.Categorical(frame['Sex']).codes\n",
    "    frame.pop('Sex')\n",
    "\n",
    "    # Generate data for missing Embarked and convert to number\n",
    "    frame['Embarked'] = frame['Embarked'].fillna('X')\n",
    "    frame['Embarked'] = pd.Categorical(frame['Embarked']).codes\n",
    "    \n",
    "    # Extract title from name\n",
    "    frame['Title'] = frame['Name'].map(lambda x: substrings_in_string(x, title_list))\n",
    "    frame['Title'] = pd.Categorical(frame['Title']).codes\n",
    "\n",
    "    # Convert Name into characters\n",
    "    frame['Name_Length'] = frame.apply(lambda row: len(row['Name']), axis=1)\n",
    "    frame['Words_In_Name'] = frame.apply(lambda row: len(row['Name'].split()), axis=1)    \n",
    "    frame.pop('Name')    \n",
    "    \n",
    "    # Convert Ticket into characters\n",
    "    frame['Ticket_Length'] = frame.apply(lambda row: len(row['Ticket']), axis=1)\n",
    "    frame.pop('Ticket')    \n",
    "    \n",
    "    # Convert Cabin column to whether in cabin\n",
    "    frame['Cabin'] = frame['Cabin'].fillna('')\n",
    "    frame['In_Cabin'] = frame.apply(lambda row: 1 if row['Cabin'] != '' else 0, axis=1)\n",
    "    frame['Number_Of_Cabins'] = frame.apply(lambda row: len(row['Cabin'].split()), axis=1)    \n",
    "    frame.pop('Cabin')\n",
    "    \n",
    "    frame.fillna(0, axis=1)\n",
    "    \n",
    "    # Introduce rows with some noise\n",
    "    if augmentation > 0:\n",
    "        print('Adding more rows to training data')\n",
    "        row_count = frame.shape[0]\n",
    "        print('Row count before: ', row_count)\n",
    "        col_std = np.std(frame) \n",
    "        for i in range(0, row_count):\n",
    "            rand = np.random.random_sample()\n",
    "            if rand < augmentation:\n",
    "                row1 = pd.Series(frame.iloc[i])\n",
    "                row2 = pd.Series(frame.iloc[i])\n",
    "                col_list = frame.columns.tolist()\n",
    "                col_list.remove('PassengerId')\n",
    "                col_list.remove('Survived')\n",
    "                for col in frame.columns.tolist():\n",
    "                    row1[col] = row1[col] + rand * col_std[col]\n",
    "                    row2[col] = row2[col] - rand * col_std[col]\n",
    "                frame = frame.append(row1)\n",
    "                frame = frame.append(row2)\n",
    "        row_count = frame.shape[0]\n",
    "        print('Row count after: ', row_count)\n",
    "    \n",
    "    \n",
    "    print(\"Before scaling: \")\n",
    "    print(frame.head())\n",
    "    \n",
    "    # Scale everything except PassengerId\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    col_list = frame.columns.tolist()\n",
    "    col_list.remove('PassengerId')\n",
    "    frame = frame[col_list]\n",
    "    np_scaled = min_max_scaler.fit_transform(frame)\n",
    "    frame = pd.DataFrame(np_scaled)\n",
    "    \n",
    "    print(\"After scaling: \")\n",
    "    print(frame.head())\n",
    "\n",
    "    return frame\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 12)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load training data\n",
    "df_train_raw = pd.read_csv(train_file)\n",
    "print(df_train_raw.shape)\n",
    "df_train_raw.info()\n",
    "df_train_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arun/anaconda/envs/kaggle/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "/Users/arun/anaconda/envs/kaggle/lib/python3.6/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/arun/anaconda/envs/kaggle/lib/python3.6/site-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/arun/anaconda/envs/kaggle/lib/python3.6/site-packages/ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/arun/anaconda/envs/kaggle/lib/python3.6/site-packages/ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/arun/anaconda/envs/kaggle/lib/python3.6/site-packages/ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/arun/anaconda/envs/kaggle/lib/python3.6/site-packages/ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/arun/anaconda/envs/kaggle/lib/python3.6/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/arun/anaconda/envs/kaggle/lib/python3.6/site-packages/ipykernel_launcher.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/arun/anaconda/envs/kaggle/lib/python3.6/site-packages/ipykernel_launcher.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/arun/anaconda/envs/kaggle/lib/python3.6/site-packages/ipykernel_launcher.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/arun/anaconda/envs/kaggle/lib/python3.6/site-packages/ipykernel_launcher.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/arun/anaconda/envs/kaggle/lib/python3.6/site-packages/ipykernel_launcher.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/arun/anaconda/envs/kaggle/lib/python3.6/site-packages/ipykernel_launcher.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/arun/anaconda/envs/kaggle/lib/python3.6/site-packages/ipykernel_launcher.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/arun/anaconda/envs/kaggle/lib/python3.6/site-packages/ipykernel_launcher.py:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/arun/anaconda/envs/kaggle/lib/python3.6/site-packages/ipykernel_launcher.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding more rows to training data\n",
      "Row count before:  577\n",
      "Row count after:  635\n",
      "Before scaling: \n",
      "   PassengerId  Survived  Pclass        Age  SibSp  Parch     Fare  Embarked  \\\n",
      "0          1.0       0.0     3.0  22.000000    1.0    0.0   7.2500       2.0   \n",
      "4          5.0       0.0     3.0  35.000000    0.0    0.0   8.0500       2.0   \n",
      "5          6.0       0.0     3.0  30.726645    0.0    0.0   8.4583       1.0   \n",
      "6          7.0       0.0     1.0  54.000000    0.0    0.0  51.8625       2.0   \n",
      "7          8.0       0.0     3.0   2.000000    3.0    1.0  21.0750       2.0   \n",
      "\n",
      "   Adult_Or_Minor  Senior_Citizen  Family_Size  Alone  Fare_Per_Person  Title  \\\n",
      "0             1.0             1.0          2.0    0.0           3.6250    7.0   \n",
      "4             1.0             1.0          1.0    1.0           8.0500    7.0   \n",
      "5             1.0             1.0          1.0    1.0           8.4583    7.0   \n",
      "6             1.0             1.0          1.0    1.0          51.8625    7.0   \n",
      "7             0.0             1.0          5.0    0.0           4.2150    6.0   \n",
      "\n",
      "   Name_Length  Words_In_Name  Ticket_Length  In_Cabin  Number_Of_Cabins  \n",
      "0         23.0            4.0            9.0       0.0               0.0  \n",
      "4         24.0            4.0            6.0       0.0               0.0  \n",
      "5         16.0            3.0            6.0       0.0               0.0  \n",
      "6         23.0            4.0            5.0       1.0               1.0  \n",
      "7         30.0            4.0            6.0       0.0               0.0  \n",
      "After scaling: \n",
      "         0         1         2         3    4         5         6         7   \\\n",
      "0  0.015703  1.000000  0.271174  0.129704  0.0  0.014151  1.000000  0.987893   \n",
      "1  0.015703  1.000000  0.434531  0.005376  0.0  0.015713  1.000000  0.987893   \n",
      "2  0.015703  1.000000  0.380832  0.005376  0.0  0.016510  0.507572  0.987893   \n",
      "3  0.015703  0.016295  0.673285  0.005376  0.0  0.101229  1.000000  0.987893   \n",
      "4  0.015703  1.000000  0.019854  0.378360  0.2  0.041136  1.000000  0.000000   \n",
      "\n",
      "         8             9         10        11     12        13    14  \\\n",
      "0  0.995257  1.000000e-01  0.018115  0.007076  0.875  0.297297  0.25   \n",
      "1  0.995257  1.387779e-17  1.000000  0.015713  0.875  0.324324  0.25   \n",
      "2  0.995257  1.387779e-17  1.000000  0.016510  0.875  0.108108  0.00   \n",
      "3  0.995257  1.387779e-17  1.000000  0.101229  0.875  0.297297  0.25   \n",
      "4  0.995257  4.000000e-01  0.018115  0.008227  0.750  0.486486  0.25   \n",
      "\n",
      "         15        16        17  \n",
      "0  0.400000  0.000000  0.000000  \n",
      "1  0.200000  0.000000  0.000000  \n",
      "2  0.200000  0.000000  0.000000  \n",
      "3  0.133333  0.984407  0.333333  \n",
      "4  0.200000  0.000000  0.000000  \n",
      "Adding more rows to training data\n",
      "Row count before:  314\n",
      "Row count after:  322\n",
      "Before scaling: \n",
      "   PassengerId  Survived  Pclass   Age  SibSp  Parch     Fare  Embarked  \\\n",
      "1          2.0       1.0     1.0  38.0    1.0    0.0  71.2833       0.0   \n",
      "2          3.0       1.0     3.0  26.0    0.0    0.0   7.9250       2.0   \n",
      "3          4.0       1.0     1.0  35.0    1.0    0.0  53.1000       2.0   \n",
      "8          9.0       1.0     3.0  27.0    0.0    2.0  11.1333       2.0   \n",
      "9         10.0       1.0     2.0  14.0    1.0    0.0  30.0708       0.0   \n",
      "\n",
      "   Adult_Or_Minor  Senior_Citizen  Family_Size  Alone  Fare_Per_Person  Title  \\\n",
      "1             1.0             1.0          2.0    0.0         35.64165    5.0   \n",
      "2             1.0             1.0          1.0    1.0          7.92500    2.0   \n",
      "3             1.0             1.0          2.0    0.0         26.55000    5.0   \n",
      "8             1.0             1.0          3.0    0.0          3.71110    5.0   \n",
      "9             0.0             1.0          2.0    0.0         15.03540    5.0   \n",
      "\n",
      "   Name_Length  Words_In_Name  Ticket_Length  In_Cabin  Number_Of_Cabins  \n",
      "1         51.0            7.0            8.0       1.0               1.0  \n",
      "2         22.0            3.0           16.0       0.0               0.0  \n",
      "3         44.0            7.0            6.0       1.0               1.0  \n",
      "8         49.0            7.0            6.0       0.0               0.0  \n",
      "9         35.0            5.0            6.0       0.0               0.0  \n",
      "After scaling: \n",
      "    0         1         2      3         4         5         6         7   \\\n",
      "0  1.0  0.002525  0.598394  0.125  0.000000  0.127642  0.000000  1.000000   \n",
      "1  1.0  1.000000  0.405622  0.000  0.000000  0.002324  0.666667  1.000000   \n",
      "2  1.0  0.002525  0.550201  0.125  0.000000  0.091677  0.666667  1.000000   \n",
      "3  1.0  1.000000  0.421687  0.000  0.333333  0.008670  0.666667  1.000000   \n",
      "4  1.0  0.501263  0.212851  0.125  0.000000  0.046127  0.000000  0.002243   \n",
      "\n",
      "    8    9         10        11        12        13        14        15  \\\n",
      "0  0.0  0.1  0.002891  0.067507  0.833333  0.530303  0.363636  0.307692   \n",
      "1  0.0  0.0  1.000000  0.013288  0.333333  0.090909  0.000000  0.923077   \n",
      "2  0.0  0.1  0.002891  0.049722  0.833333  0.424242  0.363636  0.153846   \n",
      "3  0.0  0.2  0.002891  0.005045  0.833333  0.500000  0.363636  0.153846   \n",
      "4  0.0  0.1  0.002891  0.027197  0.833333  0.287879  0.181818  0.153846   \n",
      "\n",
      "         16    17  \n",
      "0  0.997274  0.25  \n",
      "1  0.000000  0.00  \n",
      "2  0.997274  0.25  \n",
      "3  0.000000  0.00  \n",
      "4  0.000000  0.00  \n"
     ]
    }
   ],
   "source": [
    "# Prep training data\n",
    "df_train_male_raw = df_train_raw[df_train_raw.Sex == 'male']\n",
    "df_train_female_raw = df_train_raw[df_train_raw.Sex == 'female']\n",
    "df_train_male = prep_data(df_train_male_raw, augmentation=0.05)\n",
    "df_train_female = prep_data(df_train_female_raw, augmentation=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(635, 17)\n",
      "[ 1.          0.27117366  0.12970367  0.          0.01415106  1.\n",
      "  0.98789346  0.99525702  0.1         0.01811543  0.00707553  0.875\n",
      "  0.2972973   0.25        0.40000001  0.          0.        ]\n",
      "(322, 17)\n",
      "[ 0.0025252   0.59839356  0.125       0.          0.12764232  0.          1.\n",
      "  0.          0.1         0.00289112  0.06750725  0.83333331  0.530303\n",
      "  0.36363637  0.30769232  0.99727422  0.25      ]\n"
     ]
    }
   ],
   "source": [
    "# Construct the X array for males\n",
    "X_train_male = np.array(df_train_male)[:,1:]\n",
    "X_train_male = X_train_male.astype('float32')\n",
    "print(X_train_male.shape)\n",
    "print(X_train_male[0])\n",
    "\n",
    "# Construct the X array for females\n",
    "X_train_female = np.array(df_train_female)[:,1:]\n",
    "X_train_female = X_train_female.astype('float32')\n",
    "print(X_train_female.shape)\n",
    "print(X_train_female[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(635, 2)\n",
      "[[ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]]\n",
      "(322, 2)\n",
      "[[ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "# Extract survived data as predictions\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "y_train_male = np.array(df_train_male)[:,0]\n",
    "y_train_male = y_train_male.astype('int')\n",
    "y_train_male = to_categorical(y_train_male, 2)\n",
    "print(y_train_male.shape)\n",
    "print(y_train_male[0:5])\n",
    "\n",
    "y_train_female = np.array(df_train_female)[:,0]\n",
    "y_train_female = y_train_female.astype('int')\n",
    "y_train_female = to_categorical(y_train_female, 2)\n",
    "print(y_train_female.shape)\n",
    "print(y_train_female[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(418, 11)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      "PassengerId    418 non-null int64\n",
      "Pclass         418 non-null int64\n",
      "Name           418 non-null object\n",
      "Sex            418 non-null object\n",
      "Age            332 non-null float64\n",
      "SibSp          418 non-null int64\n",
      "Parch          418 non-null int64\n",
      "Ticket         418 non-null object\n",
      "Fare           417 non-null float64\n",
      "Cabin          91 non-null object\n",
      "Embarked       418 non-null object\n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# Load test data\n",
    "df_test_raw = pd.read_csv(test_file)\n",
    "print(df_test_raw.shape)\n",
    "df_test_raw.head()\n",
    "df_test_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arun/anaconda/envs/kaggle/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "/Users/arun/anaconda/envs/kaggle/lib/python3.6/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/arun/anaconda/envs/kaggle/lib/python3.6/site-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/arun/anaconda/envs/kaggle/lib/python3.6/site-packages/ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/arun/anaconda/envs/kaggle/lib/python3.6/site-packages/ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/arun/anaconda/envs/kaggle/lib/python3.6/site-packages/ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/arun/anaconda/envs/kaggle/lib/python3.6/site-packages/ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/arun/anaconda/envs/kaggle/lib/python3.6/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/arun/anaconda/envs/kaggle/lib/python3.6/site-packages/ipykernel_launcher.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/arun/anaconda/envs/kaggle/lib/python3.6/site-packages/ipykernel_launcher.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/arun/anaconda/envs/kaggle/lib/python3.6/site-packages/ipykernel_launcher.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/arun/anaconda/envs/kaggle/lib/python3.6/site-packages/ipykernel_launcher.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/arun/anaconda/envs/kaggle/lib/python3.6/site-packages/ipykernel_launcher.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/arun/anaconda/envs/kaggle/lib/python3.6/site-packages/ipykernel_launcher.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/arun/anaconda/envs/kaggle/lib/python3.6/site-packages/ipykernel_launcher.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/arun/anaconda/envs/kaggle/lib/python3.6/site-packages/ipykernel_launcher.py:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/arun/anaconda/envs/kaggle/lib/python3.6/site-packages/ipykernel_launcher.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before scaling: \n",
      "   PassengerId  Pclass   Age  SibSp  Parch     Fare  Embarked  Adult_Or_Minor  \\\n",
      "0          892       3  34.5      0      0   7.8292         1               1   \n",
      "2          894       2  62.0      0      0   9.6875         1               1   \n",
      "3          895       3  27.0      0      0   8.6625         2               1   \n",
      "5          897       3  14.0      0      0   9.2250         2               0   \n",
      "7          899       2  26.0      1      1  29.0000         2               1   \n",
      "\n",
      "   Senior_Citizen  Family_Size  Alone  Fare_Per_Person  Title  Name_Length  \\\n",
      "0               1            1      1         7.829200      3           16   \n",
      "2               1            1      1         9.687500      3           25   \n",
      "3               1            1      1         8.662500      3           16   \n",
      "5               1            1      1         9.225000      3           26   \n",
      "7               1            3      0         9.666667      3           28   \n",
      "\n",
      "   Words_In_Name  Ticket_Length  In_Cabin  Number_Of_Cabins  \n",
      "0              3              6         0                 0  \n",
      "2              4              6         0                 0  \n",
      "3              3              6         0                 0  \n",
      "5              4              4         0                 0  \n",
      "7              4              6         0                 0  \n",
      "After scaling: \n",
      "    0         1      2         3         4    5    6    7    8    9   \\\n",
      "0  1.0  0.512524  0.000  0.000000  0.029840  0.5  1.0  1.0  0.0  1.0   \n",
      "1  0.5  0.925004  0.000  0.000000  0.036922  0.5  1.0  1.0  0.0  1.0   \n",
      "2  1.0  0.400030  0.000  0.000000  0.033016  1.0  1.0  1.0  0.0  1.0   \n",
      "3  1.0  0.205040  0.000  0.000000  0.035160  1.0  0.0  1.0  0.0  1.0   \n",
      "4  0.5  0.385031  0.125  0.111111  0.110529  1.0  1.0  1.0  0.2  0.0   \n",
      "\n",
      "         10    11     12    13        14   15   16  \n",
      "0  0.037017  0.75  0.075  0.00  0.200000  0.0  0.0  \n",
      "1  0.045804  0.75  0.300  0.25  0.200000  0.0  0.0  \n",
      "2  0.040957  0.75  0.075  0.00  0.200000  0.0  0.0  \n",
      "3  0.043617  0.75  0.325  0.25  0.066667  0.0  0.0  \n",
      "4  0.045705  0.75  0.375  0.25  0.200000  0.0  0.0  \n",
      "Before scaling: \n",
      "    PassengerId  Pclass   Age  SibSp  Parch     Fare  Embarked  \\\n",
      "1           893       3  47.0      1      0   7.0000         2   \n",
      "4           896       3  22.0      1      1  12.2875         2   \n",
      "6           898       3  30.0      0      0   7.6292         1   \n",
      "8           900       3  18.0      0      0   7.2292         0   \n",
      "12          904       1  23.0      1      0  82.2667         2   \n",
      "\n",
      "    Adult_Or_Minor  Senior_Citizen  Family_Size  Alone  Fare_Per_Person  \\\n",
      "1                1               1            2      0         3.500000   \n",
      "4                1               1            3      0         4.095833   \n",
      "6                1               1            1      1         7.629200   \n",
      "8                1               1            1      1         7.229200   \n",
      "12               1               1            2      0        41.133350   \n",
      "\n",
      "    Title  Name_Length  Words_In_Name  Ticket_Length  In_Cabin  \\\n",
      "1       2           32              5              6         0   \n",
      "4       2           44              6              7         0   \n",
      "6       1           20              3              6         0   \n",
      "8       2           41              6              4         0   \n",
      "12      2           45              6              5         1   \n",
      "\n",
      "    Number_Of_Cabins  \n",
      "1                  0  \n",
      "4                  0  \n",
      "6                  0  \n",
      "8                  0  \n",
      "12                 1  \n",
      "After scaling: \n",
      "    0         1      2         3         4    5    6    7    8    9   \\\n",
      "0  1.0  0.617566  0.125  0.000000  0.000099  1.0  1.0  1.0  0.1  0.0   \n",
      "1  1.0  0.287881  0.125  0.111111  0.010561  1.0  1.0  1.0  0.2  0.0   \n",
      "2  1.0  0.393380  0.000  0.000000  0.001344  0.5  1.0  1.0  0.0  1.0   \n",
      "3  1.0  0.235131  0.000  0.000000  0.000552  0.0  1.0  1.0  0.0  1.0   \n",
      "4  0.0  0.301068  0.125  0.000000  0.149030  1.0  1.0  1.0  0.1  0.0   \n",
      "\n",
      "         10        11        12   13        14   15    16  \n",
      "0  0.009145  0.666667  0.354167  0.4  0.142857  0.0  0.00  \n",
      "1  0.011426  0.666667  0.604167  0.6  0.214286  0.0  0.00  \n",
      "2  0.024950  0.333333  0.104167  0.0  0.142857  0.0  0.00  \n",
      "3  0.023419  0.666667  0.541667  0.6  0.000000  0.0  0.00  \n",
      "4  0.153188  0.666667  0.625000  0.6  0.071429  1.0  0.25  \n"
     ]
    }
   ],
   "source": [
    "# Prepare the data for testing\n",
    "df_test_male_raw = df_test_raw[df_test_raw.Sex == 'male']\n",
    "df_test_female_raw = df_test_raw[df_test_raw.Sex == 'female']\n",
    "df_test_male = prep_data(df_test_male_raw)\n",
    "df_test_female = prep_data(df_test_female_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(266, 17)\n",
      "[ 1.          0.51252437  0.          0.          0.02983973  0.5         1.\n",
      "  1.          0.          1.          0.03701749  0.75        0.075       0.\n",
      "  0.2         0.          0.        ]\n",
      "(152, 17)\n",
      "[  1.00000000e+00   6.17565632e-01   1.25000000e-01   0.00000000e+00\n",
      "   9.89356122e-05   1.00000000e+00   1.00000000e+00   1.00000000e+00\n",
      "   1.00000001e-01   0.00000000e+00   9.14509129e-03   6.66666687e-01\n",
      "   3.54166657e-01   4.00000006e-01   1.42857149e-01   0.00000000e+00\n",
      "   0.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "# Construct the X array for males\n",
    "X_test_male = np.array(df_test_male)[:,:]\n",
    "X_test_male = X_test_male.astype('float32')\n",
    "print(X_test_male.shape)\n",
    "print(X_test_male[0])\n",
    "\n",
    "# Construct the X array for females\n",
    "X_test_female = np.array(df_test_female)[:,:]\n",
    "X_test_female = X_test_female.astype('float32')\n",
    "print(X_test_female.shape)\n",
    "print(X_test_female[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a training network\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, RepeatVector, Flatten, Activation\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "\n",
    "def build_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(891, activation='relu', input_shape=input_shape))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(445, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(222, activation='relu'))\n",
    "    model.add(Dropout(0.75))\n",
    "    model.add(Dense(2, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "def save_model(model, model_file):\n",
    "    model_json = model.to_json()\n",
    "    with open(model_file, 'w') as json_file:\n",
    "        json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "def train_model(model, model_weights_file, X_train, y_train):\n",
    "    checkpointer = ModelCheckpoint(filepath=model_weights_file, verbose=1, save_best_only=True)\n",
    "    stopper = EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=10, verbose=1, mode='auto')\n",
    "    hist = model.fit(X_train, y_train, epochs=200, batch_size=20, validation_split=0.3,\n",
    "                     callbacks=[checkpointer, stopper], \n",
    "                     verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_45 (Dense)             (None, 891)               16038     \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 891)               0         \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 445)               396940    \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 445)               0         \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 222)               99012     \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 222)               0         \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 2)                 446       \n",
      "=================================================================\n",
      "Total params: 512,436\n",
      "Trainable params: 512,436\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 444 samples, validate on 191 samples\n",
      "Epoch 1/200\n",
      "440/444 [============================>.] - ETA: 0s - loss: 0.5239 - acc: 0.7886Epoch 00000: val_loss improved from inf to 0.39243, saving model to ../output/titanic.model.male.best.hdf5\n",
      "444/444 [==============================] - 1s - loss: 0.5237 - acc: 0.7883 - val_loss: 0.3924 - val_acc: 0.8429\n",
      "Epoch 2/200\n",
      "400/444 [==========================>...] - ETA: 0s - loss: 0.4791 - acc: 0.8075Epoch 00001: val_loss improved from 0.39243 to 0.36931, saving model to ../output/titanic.model.male.best.hdf5\n",
      "444/444 [==============================] - 0s - loss: 0.4884 - acc: 0.8086 - val_loss: 0.3693 - val_acc: 0.8429\n",
      "Epoch 3/200\n",
      "380/444 [========================>.....] - ETA: 0s - loss: 0.4817 - acc: 0.8053Epoch 00002: val_loss did not improve\n",
      "444/444 [==============================] - 0s - loss: 0.4683 - acc: 0.8074 - val_loss: 0.3726 - val_acc: 0.8429\n",
      "Epoch 4/200\n",
      "400/444 [==========================>...] - ETA: 0s - loss: 0.4635 - acc: 0.8075Epoch 00003: val_loss did not improve\n",
      "444/444 [==============================] - 0s - loss: 0.4580 - acc: 0.8108 - val_loss: 0.3774 - val_acc: 0.8482\n",
      "Epoch 5/200\n",
      "400/444 [==========================>...] - ETA: 0s - loss: 0.4897 - acc: 0.7987Epoch 00004: val_loss improved from 0.36931 to 0.36080, saving model to ../output/titanic.model.male.best.hdf5\n",
      "444/444 [==============================] - 0s - loss: 0.4702 - acc: 0.8097 - val_loss: 0.3608 - val_acc: 0.8482\n",
      "Epoch 6/200\n",
      "440/444 [============================>.] - ETA: 0s - loss: 0.4605 - acc: 0.8148Epoch 00005: val_loss did not improve\n",
      "444/444 [==============================] - 0s - loss: 0.4649 - acc: 0.8119 - val_loss: 0.3942 - val_acc: 0.8586\n",
      "Epoch 7/200\n",
      "380/444 [========================>.....] - ETA: 0s - loss: 0.4480 - acc: 0.8132Epoch 00006: val_loss improved from 0.36080 to 0.35128, saving model to ../output/titanic.model.male.best.hdf5\n",
      "444/444 [==============================] - 0s - loss: 0.4549 - acc: 0.8108 - val_loss: 0.3513 - val_acc: 0.8482\n",
      "Epoch 8/200\n",
      "420/444 [===========================>..] - ETA: 0s - loss: 0.4431 - acc: 0.8119Epoch 00007: val_loss did not improve\n",
      "444/444 [==============================] - 0s - loss: 0.4446 - acc: 0.8131 - val_loss: 0.3618 - val_acc: 0.8586\n",
      "Epoch 9/200\n",
      "400/444 [==========================>...] - ETA: 0s - loss: 0.4296 - acc: 0.8262Epoch 00008: val_loss improved from 0.35128 to 0.34057, saving model to ../output/titanic.model.male.best.hdf5\n",
      "444/444 [==============================] - 0s - loss: 0.4424 - acc: 0.8164 - val_loss: 0.3406 - val_acc: 0.8717\n",
      "Epoch 10/200\n",
      "340/444 [=====================>........] - ETA: 0s - loss: 0.4513 - acc: 0.7971Epoch 00009: val_loss did not improve\n",
      "444/444 [==============================] - 0s - loss: 0.4493 - acc: 0.8052 - val_loss: 0.3406 - val_acc: 0.8665\n",
      "Epoch 11/200\n",
      "380/444 [========================>.....] - ETA: 0s - loss: 0.4153 - acc: 0.8434Epoch 00010: val_loss did not improve\n",
      "444/444 [==============================] - 0s - loss: 0.4296 - acc: 0.8345 - val_loss: 0.3636 - val_acc: 0.8770\n",
      "Epoch 12/200\n",
      "380/444 [========================>.....] - ETA: 0s - loss: 0.4106 - acc: 0.8382Epoch 00011: val_loss did not improve\n",
      "444/444 [==============================] - 0s - loss: 0.4314 - acc: 0.8255 - val_loss: 0.3739 - val_acc: 0.8639\n",
      "Epoch 13/200\n",
      "380/444 [========================>.....] - ETA: 0s - loss: 0.4337 - acc: 0.8408Epoch 00012: val_loss did not improve\n",
      "444/444 [==============================] - 0s - loss: 0.4360 - acc: 0.8390 - val_loss: 0.3429 - val_acc: 0.8639\n",
      "Epoch 14/200\n",
      "380/444 [========================>.....] - ETA: 0s - loss: 0.4503 - acc: 0.8303Epoch 00013: val_loss improved from 0.34057 to 0.33153, saving model to ../output/titanic.model.male.best.hdf5\n",
      "444/444 [==============================] - 0s - loss: 0.4428 - acc: 0.8311 - val_loss: 0.3315 - val_acc: 0.8796\n",
      "Epoch 15/200\n",
      "380/444 [========================>.....] - ETA: 0s - loss: 0.4138 - acc: 0.8382Epoch 00014: val_loss did not improve\n",
      "444/444 [==============================] - 0s - loss: 0.4247 - acc: 0.8378 - val_loss: 0.3364 - val_acc: 0.8717\n",
      "Epoch 16/200\n",
      "400/444 [==========================>...] - ETA: 0s - loss: 0.4184 - acc: 0.8338Epoch 00015: val_loss did not improve\n",
      "444/444 [==============================] - 0s - loss: 0.4311 - acc: 0.8277 - val_loss: 0.4093 - val_acc: 0.8403\n",
      "Epoch 17/200\n",
      "400/444 [==========================>...] - ETA: 0s - loss: 0.4573 - acc: 0.8350Epoch 00016: val_loss did not improve\n",
      "444/444 [==============================] - 0s - loss: 0.4632 - acc: 0.8322 - val_loss: 0.3477 - val_acc: 0.8796\n",
      "Epoch 18/200\n",
      "380/444 [========================>.....] - ETA: 0s - loss: 0.4032 - acc: 0.8632Epoch 00017: val_loss improved from 0.33153 to 0.32916, saving model to ../output/titanic.model.male.best.hdf5\n",
      "444/444 [==============================] - 0s - loss: 0.4154 - acc: 0.8604 - val_loss: 0.3292 - val_acc: 0.8796\n",
      "Epoch 19/200\n",
      "400/444 [==========================>...] - ETA: 0s - loss: 0.4620 - acc: 0.8287Epoch 00018: val_loss did not improve\n",
      "444/444 [==============================] - 0s - loss: 0.4564 - acc: 0.8322 - val_loss: 0.3361 - val_acc: 0.8822\n",
      "Epoch 20/200\n",
      "400/444 [==========================>...] - ETA: 0s - loss: 0.4286 - acc: 0.8413Epoch 00019: val_loss did not improve\n",
      "444/444 [==============================] - 0s - loss: 0.4337 - acc: 0.8378 - val_loss: 0.3428 - val_acc: 0.8743\n",
      "Epoch 21/200\n",
      "380/444 [========================>.....] - ETA: 0s - loss: 0.4164 - acc: 0.8500Epoch 00020: val_loss improved from 0.32916 to 0.32811, saving model to ../output/titanic.model.male.best.hdf5\n",
      "444/444 [==============================] - 0s - loss: 0.4343 - acc: 0.8401 - val_loss: 0.3281 - val_acc: 0.8691\n",
      "Epoch 22/200\n",
      "400/444 [==========================>...] - ETA: 0s - loss: 0.4043 - acc: 0.8250Epoch 00021: val_loss improved from 0.32811 to 0.32030, saving model to ../output/titanic.model.male.best.hdf5\n",
      "444/444 [==============================] - 0s - loss: 0.4129 - acc: 0.8221 - val_loss: 0.3203 - val_acc: 0.8848\n",
      "Epoch 23/200\n",
      "420/444 [===========================>..] - ETA: 0s - loss: 0.4019 - acc: 0.8560Epoch 00022: val_loss did not improve\n",
      "444/444 [==============================] - 0s - loss: 0.4087 - acc: 0.8525 - val_loss: 0.3400 - val_acc: 0.8770\n",
      "Epoch 24/200\n",
      "420/444 [===========================>..] - ETA: 0s - loss: 0.4147 - acc: 0.8464Epoch 00023: val_loss did not improve\n",
      "444/444 [==============================] - 0s - loss: 0.4175 - acc: 0.8480 - val_loss: 0.3253 - val_acc: 0.8822\n",
      "Epoch 25/200\n",
      "400/444 [==========================>...] - ETA: 0s - loss: 0.4131 - acc: 0.8563Epoch 00024: val_loss did not improve\n",
      "444/444 [==============================] - 0s - loss: 0.4172 - acc: 0.8491 - val_loss: 0.3717 - val_acc: 0.8796\n",
      "Epoch 26/200\n",
      "440/444 [============================>.] - ETA: 0s - loss: 0.4258 - acc: 0.8466Epoch 00025: val_loss did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "444/444 [==============================] - 0s - loss: 0.4249 - acc: 0.8457 - val_loss: 0.3326 - val_acc: 0.8743\n",
      "Epoch 27/200\n",
      "440/444 [============================>.] - ETA: 0s - loss: 0.4196 - acc: 0.8523Epoch 00026: val_loss did not improve\n",
      "444/444 [==============================] - 0s - loss: 0.4178 - acc: 0.8536 - val_loss: 0.3252 - val_acc: 0.8770\n",
      "Epoch 28/200\n",
      "400/444 [==========================>...] - ETA: 0s - loss: 0.3935 - acc: 0.8462Epoch 00027: val_loss did not improve\n",
      "444/444 [==============================] - 0s - loss: 0.4060 - acc: 0.8390 - val_loss: 0.3286 - val_acc: 0.8796\n",
      "Epoch 29/200\n",
      "440/444 [============================>.] - ETA: 0s - loss: 0.4058 - acc: 0.8511Epoch 00028: val_loss did not improve\n",
      "444/444 [==============================] - 0s - loss: 0.4078 - acc: 0.8502 - val_loss: 0.3504 - val_acc: 0.8796\n",
      "Epoch 30/200\n",
      "420/444 [===========================>..] - ETA: 0s - loss: 0.3936 - acc: 0.8643Epoch 00029: val_loss did not improve\n",
      "444/444 [==============================] - 0s - loss: 0.3983 - acc: 0.8604 - val_loss: 0.3207 - val_acc: 0.8822\n",
      "Epoch 31/200\n",
      "420/444 [===========================>..] - ETA: 0s - loss: 0.3992 - acc: 0.8548Epoch 00030: val_loss did not improve\n",
      "444/444 [==============================] - 0s - loss: 0.3949 - acc: 0.8581 - val_loss: 0.3478 - val_acc: 0.8743\n",
      "Epoch 32/200\n",
      "420/444 [===========================>..] - ETA: 0s - loss: 0.4015 - acc: 0.8536Epoch 00031: val_loss did not improve\n",
      "444/444 [==============================] - 0s - loss: 0.4049 - acc: 0.8502 - val_loss: 0.3621 - val_acc: 0.8691\n",
      "Epoch 33/200\n",
      "420/444 [===========================>..] - ETA: 0s - loss: 0.4001 - acc: 0.8560Epoch 00032: val_loss did not improve\n",
      "444/444 [==============================] - 0s - loss: 0.4012 - acc: 0.8570 - val_loss: 0.3653 - val_acc: 0.8743\n",
      "Epoch 00032: early stopping\n",
      "416/635 [==================>...........] - ETA: 0s\n",
      "Training Accuracy: 0.859842519685\n"
     ]
    }
   ],
   "source": [
    "# Build and train model for males\n",
    "model_male = build_model(input_shape=(X_train_male.shape[1],))\n",
    "save_model(model_male, model_file_male)\n",
    "train_model(model_male, model_weights_file_male, X_train_male, y_train_male)\n",
    "\n",
    "# Load the weights that yielded the best validation accuracy\n",
    "model_male.load_weights(model_weights_file_male)\n",
    "\n",
    "# Evaluate the model on the training set\n",
    "score_male = model_male.evaluate(X_train_male, y_train_male)\n",
    "print(\"\\nTraining Accuracy:\", score_male[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_49 (Dense)             (None, 891)               16038     \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 891)               0         \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 445)               396940    \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 445)               0         \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 222)               99012     \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 222)               0         \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 2)                 446       \n",
      "=================================================================\n",
      "Total params: 512,436\n",
      "Trainable params: 512,436\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 225 samples, validate on 97 samples\n",
      "Epoch 1/200\n",
      "200/225 [=========================>....] - ETA: 0s - loss: 0.6102 - acc: 0.7125Epoch 00000: val_loss improved from inf to 0.58765, saving model to ../output/titanic.model.female.best.hdf5\n",
      "225/225 [==============================] - 1s - loss: 0.6002 - acc: 0.7156 - val_loss: 0.5876 - val_acc: 0.7216\n",
      "Epoch 2/200\n",
      "200/225 [=========================>....] - ETA: 0s - loss: 0.5147 - acc: 0.7725Epoch 00001: val_loss improved from 0.58765 to 0.52506, saving model to ../output/titanic.model.female.best.hdf5\n",
      "225/225 [==============================] - 0s - loss: 0.5525 - acc: 0.7556 - val_loss: 0.5251 - val_acc: 0.7216\n",
      "Epoch 3/200\n",
      "180/225 [=======================>......] - ETA: 0s - loss: 0.5405 - acc: 0.7361Epoch 00002: val_loss improved from 0.52506 to 0.50212, saving model to ../output/titanic.model.female.best.hdf5\n",
      "225/225 [==============================] - 0s - loss: 0.5273 - acc: 0.7556 - val_loss: 0.5021 - val_acc: 0.7216\n",
      "Epoch 4/200\n",
      "220/225 [============================>.] - ETA: 0s - loss: 0.5383 - acc: 0.7477Epoch 00003: val_loss improved from 0.50212 to 0.49055, saving model to ../output/titanic.model.female.best.hdf5\n",
      "225/225 [==============================] - 0s - loss: 0.5318 - acc: 0.7489 - val_loss: 0.4905 - val_acc: 0.7216\n",
      "Epoch 5/200\n",
      "160/225 [====================>.........] - ETA: 0s - loss: 0.4619 - acc: 0.7688Epoch 00004: val_loss improved from 0.49055 to 0.47781, saving model to ../output/titanic.model.female.best.hdf5\n",
      "225/225 [==============================] - 0s - loss: 0.4839 - acc: 0.7600 - val_loss: 0.4778 - val_acc: 0.7216\n",
      "Epoch 6/200\n",
      "180/225 [=======================>......] - ETA: 0s - loss: 0.4492 - acc: 0.7639Epoch 00005: val_loss improved from 0.47781 to 0.46418, saving model to ../output/titanic.model.female.best.hdf5\n",
      "225/225 [==============================] - 0s - loss: 0.4610 - acc: 0.7533 - val_loss: 0.4642 - val_acc: 0.7629\n",
      "Epoch 7/200\n",
      "220/225 [============================>.] - ETA: 0s - loss: 0.4719 - acc: 0.7364Epoch 00006: val_loss did not improve\n",
      "225/225 [==============================] - 0s - loss: 0.4660 - acc: 0.7422 - val_loss: 0.4729 - val_acc: 0.7629\n",
      "Epoch 8/200\n",
      "180/225 [=======================>......] - ETA: 0s - loss: 0.4666 - acc: 0.7361Epoch 00007: val_loss improved from 0.46418 to 0.45962, saving model to ../output/titanic.model.female.best.hdf5\n",
      "225/225 [==============================] - 0s - loss: 0.4824 - acc: 0.7511 - val_loss: 0.4596 - val_acc: 0.7784\n",
      "Epoch 9/200\n",
      "220/225 [============================>.] - ETA: 0s - loss: 0.4653 - acc: 0.7705Epoch 00008: val_loss did not improve\n",
      "225/225 [==============================] - 0s - loss: 0.4655 - acc: 0.7667 - val_loss: 0.4687 - val_acc: 0.7526\n",
      "Epoch 10/200\n",
      "160/225 [====================>.........] - ETA: 0s - loss: 0.4497 - acc: 0.7781Epoch 00009: val_loss improved from 0.45962 to 0.45222, saving model to ../output/titanic.model.female.best.hdf5\n",
      "225/225 [==============================] - 0s - loss: 0.4627 - acc: 0.7622 - val_loss: 0.4522 - val_acc: 0.7732\n",
      "Epoch 11/200\n",
      "180/225 [=======================>......] - ETA: 0s - loss: 0.4219 - acc: 0.7667Epoch 00010: val_loss improved from 0.45222 to 0.44753, saving model to ../output/titanic.model.female.best.hdf5\n",
      "225/225 [==============================] - 0s - loss: 0.4450 - acc: 0.7578 - val_loss: 0.4475 - val_acc: 0.7835\n",
      "Epoch 12/200\n",
      "180/225 [=======================>......] - ETA: 0s - loss: 0.4423 - acc: 0.7917Epoch 00011: val_loss did not improve\n",
      "225/225 [==============================] - 0s - loss: 0.4486 - acc: 0.7733 - val_loss: 0.4557 - val_acc: 0.7732\n",
      "Epoch 13/200\n",
      "160/225 [====================>.........] - ETA: 0s - loss: 0.4805 - acc: 0.7937Epoch 00012: val_loss improved from 0.44753 to 0.43610, saving model to ../output/titanic.model.female.best.hdf5\n",
      "225/225 [==============================] - 0s - loss: 0.4678 - acc: 0.7778 - val_loss: 0.4361 - val_acc: 0.7938\n",
      "Epoch 14/200\n",
      "180/225 [=======================>......] - ETA: 0s - loss: 0.4354 - acc: 0.7778Epoch 00013: val_loss did not improve\n",
      "225/225 [==============================] - 0s - loss: 0.4437 - acc: 0.7889 - val_loss: 0.4512 - val_acc: 0.7732\n",
      "Epoch 15/200\n",
      "220/225 [============================>.] - ETA: 0s - loss: 0.4450 - acc: 0.7977Epoch 00014: val_loss did not improve\n",
      "225/225 [==============================] - 0s - loss: 0.4397 - acc: 0.8000 - val_loss: 0.4384 - val_acc: 0.7938\n",
      "Epoch 16/200\n",
      "160/225 [====================>.........] - ETA: 0s - loss: 0.4674 - acc: 0.7937Epoch 00015: val_loss improved from 0.43610 to 0.43185, saving model to ../output/titanic.model.female.best.hdf5\n",
      "225/225 [==============================] - 0s - loss: 0.4452 - acc: 0.7867 - val_loss: 0.4319 - val_acc: 0.7732\n",
      "Epoch 17/200\n",
      "220/225 [============================>.] - ETA: 0s - loss: 0.4218 - acc: 0.7841Epoch 00016: val_loss improved from 0.43185 to 0.42581, saving model to ../output/titanic.model.female.best.hdf5\n",
      "225/225 [==============================] - 0s - loss: 0.4254 - acc: 0.7778 - val_loss: 0.4258 - val_acc: 0.7835\n",
      "Epoch 18/200\n",
      "220/225 [============================>.] - ETA: 0s - loss: 0.4064 - acc: 0.7886Epoch 00017: val_loss improved from 0.42581 to 0.40879, saving model to ../output/titanic.model.female.best.hdf5\n",
      "225/225 [==============================] - 0s - loss: 0.4247 - acc: 0.7800 - val_loss: 0.4088 - val_acc: 0.7938\n",
      "Epoch 19/200\n",
      "180/225 [=======================>......] - ETA: 0s - loss: 0.4120 - acc: 0.8194Epoch 00018: val_loss did not improve\n",
      "225/225 [==============================] - 0s - loss: 0.4089 - acc: 0.8311 - val_loss: 0.4133 - val_acc: 0.7526\n",
      "Epoch 20/200\n",
      "180/225 [=======================>......] - ETA: 0s - loss: 0.4202 - acc: 0.8083Epoch 00019: val_loss did not improve\n",
      "225/225 [==============================] - 0s - loss: 0.4065 - acc: 0.8178 - val_loss: 0.4461 - val_acc: 0.7680\n",
      "Epoch 21/200\n",
      "180/225 [=======================>......] - ETA: 0s - loss: 0.4221 - acc: 0.8056Epoch 00020: val_loss improved from 0.40879 to 0.39572, saving model to ../output/titanic.model.female.best.hdf5\n",
      "225/225 [==============================] - 0s - loss: 0.4094 - acc: 0.8044 - val_loss: 0.3957 - val_acc: 0.8093\n",
      "Epoch 22/200\n",
      "220/225 [============================>.] - ETA: 0s - loss: 0.3690 - acc: 0.8273Epoch 00021: val_loss did not improve\n",
      "225/225 [==============================] - 0s - loss: 0.3832 - acc: 0.8244 - val_loss: 0.4156 - val_acc: 0.7732\n",
      "Epoch 23/200\n",
      "220/225 [============================>.] - ETA: 0s - loss: 0.3955 - acc: 0.7955Epoch 00022: val_loss did not improve\n",
      "225/225 [==============================] - 0s - loss: 0.3938 - acc: 0.7978 - val_loss: 0.4416 - val_acc: 0.7423\n",
      "Epoch 24/200\n",
      "180/225 [=======================>......] - ETA: 0s - loss: 0.3983 - acc: 0.7889Epoch 00023: val_loss did not improve\n",
      "225/225 [==============================] - 0s - loss: 0.4176 - acc: 0.7889 - val_loss: 0.3983 - val_acc: 0.7784\n",
      "Epoch 25/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220/225 [============================>.] - ETA: 0s - loss: 0.3922 - acc: 0.8114Epoch 00024: val_loss did not improve\n",
      "225/225 [==============================] - 0s - loss: 0.3919 - acc: 0.8111 - val_loss: 0.4028 - val_acc: 0.7784\n",
      "Epoch 26/200\n",
      "160/225 [====================>.........] - ETA: 0s - loss: 0.4355 - acc: 0.7906Epoch 00025: val_loss did not improve\n",
      "225/225 [==============================] - 0s - loss: 0.3962 - acc: 0.8111 - val_loss: 0.4228 - val_acc: 0.7577\n",
      "Epoch 27/200\n",
      "140/225 [=================>............] - ETA: 0s - loss: 0.4075 - acc: 0.7571Epoch 00026: val_loss improved from 0.39572 to 0.37914, saving model to ../output/titanic.model.female.best.hdf5\n",
      "225/225 [==============================] - 0s - loss: 0.4262 - acc: 0.7600 - val_loss: 0.3791 - val_acc: 0.8247\n",
      "Epoch 28/200\n",
      "180/225 [=======================>......] - ETA: 0s - loss: 0.3920 - acc: 0.7806Epoch 00027: val_loss did not improve\n",
      "225/225 [==============================] - 0s - loss: 0.4048 - acc: 0.7911 - val_loss: 0.3872 - val_acc: 0.8196\n",
      "Epoch 29/200\n",
      "180/225 [=======================>......] - ETA: 0s - loss: 0.4113 - acc: 0.7917Epoch 00028: val_loss did not improve\n",
      "225/225 [==============================] - 0s - loss: 0.3995 - acc: 0.8089 - val_loss: 0.4407 - val_acc: 0.7629\n",
      "Epoch 30/200\n",
      "200/225 [=========================>....] - ETA: 0s - loss: 0.4800 - acc: 0.7675Epoch 00029: val_loss did not improve\n",
      "225/225 [==============================] - 0s - loss: 0.4586 - acc: 0.7778 - val_loss: 0.3850 - val_acc: 0.8196\n",
      "Epoch 31/200\n",
      "200/225 [=========================>....] - ETA: 0s - loss: 0.3883 - acc: 0.8000Epoch 00030: val_loss did not improve\n",
      "225/225 [==============================] - 0s - loss: 0.3851 - acc: 0.8089 - val_loss: 0.3870 - val_acc: 0.8247\n",
      "Epoch 32/200\n",
      "180/225 [=======================>......] - ETA: 0s - loss: 0.3994 - acc: 0.8167Epoch 00031: val_loss did not improve\n",
      "225/225 [==============================] - 0s - loss: 0.3838 - acc: 0.8156 - val_loss: 0.3817 - val_acc: 0.8299\n",
      "Epoch 33/200\n",
      "180/225 [=======================>......] - ETA: 0s - loss: 0.4113 - acc: 0.8056Epoch 00032: val_loss did not improve\n",
      "225/225 [==============================] - 0s - loss: 0.3939 - acc: 0.8089 - val_loss: 0.3856 - val_acc: 0.8247\n",
      "Epoch 34/200\n",
      "200/225 [=========================>....] - ETA: 0s - loss: 0.3759 - acc: 0.8200Epoch 00033: val_loss did not improve\n",
      "225/225 [==============================] - 0s - loss: 0.3641 - acc: 0.8267 - val_loss: 0.3808 - val_acc: 0.8144\n",
      "Epoch 35/200\n",
      "200/225 [=========================>....] - ETA: 0s - loss: 0.3640 - acc: 0.8375Epoch 00034: val_loss did not improve\n",
      "225/225 [==============================] - 0s - loss: 0.3701 - acc: 0.8311 - val_loss: 0.3859 - val_acc: 0.7887\n",
      "Epoch 36/200\n",
      "180/225 [=======================>......] - ETA: 0s - loss: 0.3728 - acc: 0.8000Epoch 00035: val_loss did not improve\n",
      "225/225 [==============================] - 0s - loss: 0.3715 - acc: 0.7978 - val_loss: 0.4121 - val_acc: 0.7990\n",
      "Epoch 37/200\n",
      "180/225 [=======================>......] - ETA: 0s - loss: 0.3707 - acc: 0.8139Epoch 00036: val_loss did not improve\n",
      "225/225 [==============================] - 0s - loss: 0.3467 - acc: 0.8311 - val_loss: 0.3920 - val_acc: 0.7835\n",
      "Epoch 38/200\n",
      "180/225 [=======================>......] - ETA: 0s - loss: 0.3828 - acc: 0.7889Epoch 00037: val_loss did not improve\n",
      "225/225 [==============================] - 0s - loss: 0.3566 - acc: 0.8022 - val_loss: 0.3864 - val_acc: 0.8196\n",
      "Epoch 00037: early stopping\n",
      " 32/322 [=>............................] - ETA: 0s\n",
      "Training Accuracy: 0.826086956522\n"
     ]
    }
   ],
   "source": [
    "# Build and train model for males\n",
    "model_female = build_model(input_shape=(X_train_female.shape[1],))\n",
    "save_model(model_female, model_file_female)\n",
    "train_model(model_female, model_weights_file_female, X_train_female, y_train_female)\n",
    "\n",
    "# Load the weights that yielded the best validation accuracy\n",
    "model_female.load_weights(model_weights_file_female)\n",
    "\n",
    "# Evaluate the model on the training set\n",
    "score_female = model_female.evaluate(X_train_female, y_train_female)\n",
    "print(\"\\nTraining Accuracy:\", score_female[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.9213075   0.08650922]\n",
      "[ 0.47310415  0.5250386 ]\n"
     ]
    }
   ],
   "source": [
    "# Predict for test data\n",
    "y_test_male = model_male.predict(X_test_male)\n",
    "print(y_test_male[0])\n",
    "\n",
    "y_test_female = model_female.predict(X_test_female)\n",
    "print(y_test_female[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions\n",
    "with open(pred_file, 'w') as f:\n",
    "    f.write('PassengerId,Survived\\n')\n",
    "    for index, y_hat in enumerate(y_test_male):\n",
    "        prediction = np.argmax(y_hat)\n",
    "        f.write(str(int(df_test_male_raw.iloc[index]['PassengerId'])) + ',' + str(prediction)+'\\n')\n",
    "    for index, y_hat in enumerate(y_test_female):\n",
    "        prediction = np.argmax(y_hat)\n",
    "        f.write(str(int(df_test_female_raw.iloc[index]['PassengerId'])) + ',' + str(prediction)+'\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
