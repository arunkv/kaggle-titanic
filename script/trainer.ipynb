{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training and test data files\n",
    "train_file = '../input/train.csv'\n",
    "test_file = '../input/test.csv'\n",
    "model_file = '../output/titanic.model.json'\n",
    "model_weights_file = '../output/titanic.model.best.hdf5'\n",
    "pred_file = '../output/gender_submission.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load training data\n",
    "df_train = pd.read_csv(train_file)\n",
    "print(df_train.shape)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 2)\n",
      "[[ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]]\n"
     ]
    }
   ],
   "source": [
    "# Extract survived data as predictions: 0 = Died, 1 = Survived\n",
    "from keras.utils.np_utils import to_categorical\n",
    "y_train = to_categorical(df_train[\"Survived\"], 2)\n",
    "df_train.pop('Survived')\n",
    "print(y_train.shape)\n",
    "print(y_train[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the rest of the data for training\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "max_name_len = df_train.Name.map(len).max()    \n",
    "\n",
    "title_list=['Mrs', 'Mr', 'Master', 'Miss', 'Major', 'Rev', 'Dr', 'Ms', 'Mlle',\n",
    "            'Col', 'Capt', 'Mme', 'Countess', 'Don', 'Jonkheer']\n",
    "\n",
    "import string\n",
    "def substrings_in_string(big_string, substrings):\n",
    "    for substring in substrings:\n",
    "        if substring in big_string:\n",
    "            return substring\n",
    "    return np.nan\n",
    "\n",
    "def prep_data(frame):\n",
    "    frame = frame.fillna(0)\n",
    "\n",
    "    # Creating new family_size and fare per person columns \n",
    "    frame['Family_Size'] = frame['SibSp'] + frame['Parch'] + 1\n",
    "\n",
    "    # Convert Sex and Embarked to number\n",
    "    frame['Sex'] = pd.Categorical(frame['Sex']).codes\n",
    "    frame['Embarked'] = pd.Categorical(frame['Embarked']).codes\n",
    "    \n",
    "    # Extract title from name\n",
    "    frame['Title'] = frame['Name'].map(lambda x: substrings_in_string(x, title_list))\n",
    "    frame['Title'] = pd.Categorical(frame['Title']).codes\n",
    "\n",
    "    # Convert Name into characters\n",
    "    frame['Name_Length'] = frame.apply(lambda row: len(row['Name']), axis=1)\n",
    "#    for i in range(0, max_name_len):\n",
    "#        col_name = 'Name' + str(i)\n",
    "#        frame[col_name] = frame['Name'].str[i]\n",
    "#        frame[col_name] = frame.apply(lambda row: ord(' ') if isinstance(row[col_name], float) and math.isnan(row[col_name]) else ord(row[col_name]), axis=1)\n",
    "    frame.pop('Name')\n",
    "\n",
    "    \n",
    "    \n",
    "    # TODO: Ignore Ticket for now\n",
    "    frame.pop('Ticket')\n",
    "    \n",
    "    # Convert Cabin column to whether in cabin\n",
    "    frame['In_Cabin'] = frame.apply(lambda row: 1 if row['Cabin'] != 0 else 0, axis=1)\n",
    "    frame.pop('Cabin')\n",
    "    \n",
    "    print(\"Before scaling: \")\n",
    "    print(frame.head())\n",
    "    \n",
    "    # Scale everything except PassengerId\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    col_list = frame.columns.tolist()\n",
    "    col_list.remove('PassengerId')\n",
    "    frame = frame[col_list]\n",
    "    np_scaled = min_max_scaler.fit_transform(frame)\n",
    "    frame = pd.DataFrame(np_scaled)\n",
    "    \n",
    "    print(\"After scaling: \")\n",
    "    print(frame.head())\n",
    "\n",
    "    return frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before scaling: \n",
      "   PassengerId  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked  \\\n",
      "0            1       3    1  22.0      1      0   7.2500         3   \n",
      "1            2       1    0  38.0      1      0  71.2833         1   \n",
      "2            3       3    0  26.0      0      0   7.9250         3   \n",
      "3            4       1    0  35.0      1      0  53.1000         3   \n",
      "4            5       3    1  35.0      0      0   8.0500         3   \n",
      "\n",
      "   Family_Size  Title  Name_Length  In_Cabin  \n",
      "0            2     11           23         0  \n",
      "1            2     12           51         1  \n",
      "2            1      8           22         0  \n",
      "3            2     12           44         1  \n",
      "4            1     11           24         0  \n",
      "After scaling: \n",
      "    0    1       2      3    4         5         6    7         8         9   \\\n",
      "0  1.0  1.0  0.2750  0.125  0.0  0.014151  1.000000  0.1  0.785714  0.157143   \n",
      "1  0.0  0.0  0.4750  0.125  0.0  0.139136  0.333333  0.1  0.857143  0.557143   \n",
      "2  1.0  0.0  0.3250  0.000  0.0  0.015469  1.000000  0.0  0.571429  0.142857   \n",
      "3  0.0  0.0  0.4375  0.125  0.0  0.103644  1.000000  0.1  0.857143  0.457143   \n",
      "4  1.0  1.0  0.4375  0.000  0.0  0.015713  1.000000  0.0  0.785714  0.171429   \n",
      "\n",
      "    10  \n",
      "0  0.0  \n",
      "1  1.0  \n",
      "2  0.0  \n",
      "3  1.0  \n",
      "4  0.0  \n",
      "(891, 11)\n",
      "[ 1.          1.          0.27500001  0.125       0.          0.01415106\n",
      "  1.          0.1         0.78571427  0.15714286  0.        ]\n"
     ]
    }
   ],
   "source": [
    "# Prepare the rest of the data for training\n",
    "df_train = prep_data(df_train)\n",
    "X_train = np.array(df_train)[:,:]\n",
    "X_train = X_train.astype('float32')\n",
    "print(X_train.shape)\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_98 (Dense)             (None, 512)               6144      \n",
      "_________________________________________________________________\n",
      "dense_99 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_100 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_101 (Dense)            (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_102 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_103 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_104 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_105 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_106 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_107 (Dense)            (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 992,258\n",
      "Trainable params: 992,258\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build a training network\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(X_train.shape[1], )))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/1000\n",
      "710/712 [============================>.] - ETA: 0s - loss: 0.6876 - acc: 0.6056Epoch 00000: val_loss improved from inf to 0.67977, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 3s - loss: 0.6878 - acc: 0.6039 - val_loss: 0.6798 - val_acc: 0.6425\n",
      "Epoch 2/1000\n",
      "710/712 [============================>.] - ETA: 0s - loss: 0.6805 - acc: 0.6085Epoch 00001: val_loss improved from 0.67977 to 0.66927, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 2s - loss: 0.6803 - acc: 0.6096 - val_loss: 0.6693 - val_acc: 0.6425\n",
      "Epoch 3/1000\n",
      "710/712 [============================>.] - ETA: 0s - loss: 0.6733 - acc: 0.6085Epoch 00002: val_loss improved from 0.66927 to 0.66075, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 1s - loss: 0.6730 - acc: 0.6096 - val_loss: 0.6608 - val_acc: 0.6425\n",
      "Epoch 4/1000\n",
      "710/712 [============================>.] - ETA: 0s - loss: 0.6669 - acc: 0.6099Epoch 00003: val_loss improved from 0.66075 to 0.65359, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 1s - loss: 0.6670 - acc: 0.6096 - val_loss: 0.6536 - val_acc: 0.6425\n",
      "Epoch 5/1000\n",
      "690/712 [============================>.] - ETA: 0s - loss: 0.6645 - acc: 0.6087Epoch 00004: val_loss improved from 0.65359 to 0.64635, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 2s - loss: 0.6641 - acc: 0.6096 - val_loss: 0.6463 - val_acc: 0.6425\n",
      "Epoch 6/1000\n",
      "700/712 [============================>.] - ETA: 0s - loss: 0.6597 - acc: 0.6086Epoch 00005: val_loss improved from 0.64635 to 0.63894, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 1s - loss: 0.6593 - acc: 0.6096 - val_loss: 0.6389 - val_acc: 0.6425\n",
      "Epoch 7/1000\n",
      "710/712 [============================>.] - ETA: 0s - loss: 0.6532 - acc: 0.6085Epoch 00006: val_loss improved from 0.63894 to 0.62878, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 2s - loss: 0.6527 - acc: 0.6096 - val_loss: 0.6288 - val_acc: 0.6425\n",
      "Epoch 8/1000\n",
      "690/712 [============================>.] - ETA: 0s - loss: 0.6487 - acc: 0.6072- ETA: 1s - lossEpoch 00007: val_loss improved from 0.62878 to 0.61717, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 2s - loss: 0.6475 - acc: 0.6096 - val_loss: 0.6172 - val_acc: 0.6425\n",
      "Epoch 9/1000\n",
      "690/712 [============================>.] - ETA: 0s - loss: 0.6347 - acc: 0.6072Epoch 00008: val_loss improved from 0.61717 to 0.59996, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 2s - loss: 0.6332 - acc: 0.6096 - val_loss: 0.6000 - val_acc: 0.6425\n",
      "Epoch 10/1000\n",
      "700/712 [============================>.] - ETA: 0s - loss: 0.6204 - acc: 0.6100Epoch 00009: val_loss improved from 0.59996 to 0.57869, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 2s - loss: 0.6208 - acc: 0.6096 - val_loss: 0.5787 - val_acc: 0.6425\n",
      "Epoch 11/1000\n",
      "690/712 [============================>.] - ETA: 0s - loss: 0.5967 - acc: 0.6145Epoch 00010: val_loss improved from 0.57869 to 0.55129, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 2s - loss: 0.5999 - acc: 0.6096 - val_loss: 0.5513 - val_acc: 0.6425\n",
      "Epoch 12/1000\n",
      "690/712 [============================>.] - ETA: 0s - loss: 0.5826 - acc: 0.6043Epoch 00011: val_loss improved from 0.55129 to 0.52878, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 2s - loss: 0.5814 - acc: 0.6081 - val_loss: 0.5288 - val_acc: 0.6425\n",
      "Epoch 13/1000\n",
      "700/712 [============================>.] - ETA: 0s - loss: 0.5609 - acc: 0.6400Epoch 00012: val_loss improved from 0.52878 to 0.51051, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 2s - loss: 0.5604 - acc: 0.6404 - val_loss: 0.5105 - val_acc: 0.8380\n",
      "Epoch 14/1000\n",
      "710/712 [============================>.] - ETA: 0s - loss: 0.5451 - acc: 0.7408Epoch 00013: val_loss improved from 0.51051 to 0.49547, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 2s - loss: 0.5457 - acc: 0.7402 - val_loss: 0.4955 - val_acc: 0.8268\n",
      "Epoch 15/1000\n",
      "690/712 [============================>.] - ETA: 0s - loss: 0.5395 - acc: 0.7841Epoch 00014: val_loss improved from 0.49547 to 0.48503, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 2s - loss: 0.5373 - acc: 0.7851 - val_loss: 0.4850 - val_acc: 0.8156\n",
      "Epoch 16/1000\n",
      "690/712 [============================>.] - ETA: 0s - loss: 0.5356 - acc: 0.7913Epoch 00015: val_loss improved from 0.48503 to 0.47682, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 2s - loss: 0.5348 - acc: 0.7921 - val_loss: 0.4768 - val_acc: 0.8268\n",
      "Epoch 17/1000\n",
      "690/712 [============================>.] - ETA: 0s - loss: 0.5280 - acc: 0.8043Epoch 00016: val_loss improved from 0.47682 to 0.47539, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 1s - loss: 0.5268 - acc: 0.8048 - val_loss: 0.4754 - val_acc: 0.8324\n",
      "Epoch 18/1000\n",
      "710/712 [============================>.] - ETA: 0s - loss: 0.5162 - acc: 0.7887Epoch 00017: val_loss improved from 0.47539 to 0.47095, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 2s - loss: 0.5160 - acc: 0.7879 - val_loss: 0.4709 - val_acc: 0.8380\n",
      "Epoch 19/1000\n",
      "710/712 [============================>.] - ETA: 0s - loss: 0.5079 - acc: 0.7887Epoch 00018: val_loss improved from 0.47095 to 0.45825, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 2s - loss: 0.5069 - acc: 0.7893 - val_loss: 0.4583 - val_acc: 0.8212\n",
      "Epoch 20/1000\n",
      "710/712 [============================>.] - ETA: 0s - loss: 0.5066 - acc: 0.8014Epoch 00019: val_loss improved from 0.45825 to 0.45588, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 2s - loss: 0.5057 - acc: 0.8020 - val_loss: 0.4559 - val_acc: 0.8212\n",
      "Epoch 21/1000\n",
      "710/712 [============================>.] - ETA: 0s - loss: 0.4992 - acc: 0.7930Epoch 00020: val_loss improved from 0.45588 to 0.45528, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 1s - loss: 0.4987 - acc: 0.7935 - val_loss: 0.4553 - val_acc: 0.7933\n",
      "Epoch 22/1000\n",
      "680/712 [===========================>..] - ETA: 0s - loss: 0.4980 - acc: 0.7912Epoch 00021: val_loss improved from 0.45528 to 0.44398, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 2s - loss: 0.4995 - acc: 0.7907 - val_loss: 0.4440 - val_acc: 0.8380\n",
      "Epoch 23/1000\n",
      "690/712 [============================>.] - ETA: 0s - loss: 0.4959 - acc: 0.8116Epoch 00022: val_loss improved from 0.44398 to 0.43423, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 2s - loss: 0.4965 - acc: 0.8118 - val_loss: 0.4342 - val_acc: 0.8492\n",
      "Epoch 24/1000\n",
      "700/712 [============================>.] - ETA: 0s - loss: 0.4879 - acc: 0.7929Epoch 00023: val_loss improved from 0.43423 to 0.42809, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 2s - loss: 0.4859 - acc: 0.7949 - val_loss: 0.4281 - val_acc: 0.8436\n",
      "Epoch 25/1000\n",
      "700/712 [============================>.] - ETA: 0s - loss: 0.4817 - acc: 0.7900Epoch 00024: val_loss did not improve\n",
      "712/712 [==============================] - 1s - loss: 0.4793 - acc: 0.7921 - val_loss: 0.4380 - val_acc: 0.8212\n",
      "Epoch 26/1000\n",
      "710/712 [============================>.] - ETA: 0s - loss: 0.4787 - acc: 0.7944Epoch 00025: val_loss improved from 0.42809 to 0.41677, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 2s - loss: 0.4778 - acc: 0.7949 - val_loss: 0.4168 - val_acc: 0.8492\n",
      "Epoch 27/1000\n",
      "700/712 [============================>.] - ETA: 0s - loss: 0.4742 - acc: 0.7957Epoch 00026: val_loss did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 1s - loss: 0.4717 - acc: 0.7963 - val_loss: 0.5267 - val_acc: 0.7821\n",
      "Epoch 28/1000\n",
      "690/712 [============================>.] - ETA: 0s - loss: 0.4702 - acc: 0.8058Epoch 00027: val_loss improved from 0.41677 to 0.41058, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 1s - loss: 0.4779 - acc: 0.8006 - val_loss: 0.4106 - val_acc: 0.8492\n",
      "Epoch 29/1000\n",
      "710/712 [============================>.] - ETA: 0s - loss: 0.4688 - acc: 0.8113Epoch 00028: val_loss did not improve\n",
      "712/712 [==============================] - 1s - loss: 0.4711 - acc: 0.8104 - val_loss: 0.4538 - val_acc: 0.7989\n",
      "Epoch 30/1000\n",
      "690/712 [============================>.] - ETA: 0s - loss: 0.4665 - acc: 0.8058Epoch 00029: val_loss did not improve\n",
      "712/712 [==============================] - 1s - loss: 0.4674 - acc: 0.8034 - val_loss: 0.4164 - val_acc: 0.8380\n",
      "Epoch 31/1000\n",
      "700/712 [============================>.] - ETA: 0s - loss: 0.4693 - acc: 0.7943Epoch 00030: val_loss did not improve\n",
      "712/712 [==============================] - 1s - loss: 0.4644 - acc: 0.7978 - val_loss: 0.4146 - val_acc: 0.8212\n",
      "Epoch 32/1000\n",
      "700/712 [============================>.] - ETA: 0s - loss: 0.4733 - acc: 0.8000Epoch 00031: val_loss did not improve\n",
      "712/712 [==============================] - 1s - loss: 0.4742 - acc: 0.7992 - val_loss: 0.4316 - val_acc: 0.8045\n",
      "Epoch 33/1000\n",
      "680/712 [===========================>..] - ETA: 0s - loss: 0.4725 - acc: 0.8044Epoch 00032: val_loss did not improve\n",
      "712/712 [==============================] - 1s - loss: 0.4678 - acc: 0.8090 - val_loss: 0.4186 - val_acc: 0.8045\n",
      "Epoch 34/1000\n",
      "680/712 [===========================>..] - ETA: 0s - loss: 0.4590 - acc: 0.8015Epoch 00033: val_loss improved from 0.41058 to 0.39831, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 2s - loss: 0.4597 - acc: 0.8006 - val_loss: 0.3983 - val_acc: 0.8436\n",
      "Epoch 35/1000\n",
      "710/712 [============================>.] - ETA: 0s - loss: 0.4544 - acc: 0.8183Epoch 00034: val_loss improved from 0.39831 to 0.39055, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 1s - loss: 0.4560 - acc: 0.8174 - val_loss: 0.3906 - val_acc: 0.8436\n",
      "Epoch 36/1000\n",
      "690/712 [============================>.] - ETA: 0s - loss: 0.4445 - acc: 0.8188Epoch 00035: val_loss improved from 0.39055 to 0.38981, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 1s - loss: 0.4469 - acc: 0.8188 - val_loss: 0.3898 - val_acc: 0.8324\n",
      "Epoch 37/1000\n",
      "710/712 [============================>.] - ETA: 0s - loss: 0.4477 - acc: 0.8127Epoch 00036: val_loss did not improve\n",
      "712/712 [==============================] - 1s - loss: 0.4491 - acc: 0.8118 - val_loss: 0.4094 - val_acc: 0.8101\n",
      "Epoch 38/1000\n",
      "710/712 [============================>.] - ETA: 0s - loss: 0.4527 - acc: 0.8014Epoch 00037: val_loss did not improve\n",
      "712/712 [==============================] - 1s - loss: 0.4517 - acc: 0.8020 - val_loss: 0.3938 - val_acc: 0.8492\n",
      "Epoch 39/1000\n",
      "690/712 [============================>.] - ETA: 0s - loss: 0.4465 - acc: 0.8043Epoch 00038: val_loss improved from 0.38981 to 0.38803, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 1s - loss: 0.4447 - acc: 0.8048 - val_loss: 0.3880 - val_acc: 0.8268\n",
      "Epoch 40/1000\n",
      "700/712 [============================>.] - ETA: 0s - loss: 0.4423 - acc: 0.8029Epoch 00039: val_loss did not improve\n",
      "712/712 [==============================] - 1s - loss: 0.4451 - acc: 0.8020 - val_loss: 0.3995 - val_acc: 0.8324\n",
      "Epoch 41/1000\n",
      "710/712 [============================>.] - ETA: 0s - loss: 0.4548 - acc: 0.8127Epoch 00040: val_loss did not improve\n",
      "712/712 [==============================] - 1s - loss: 0.4540 - acc: 0.8132 - val_loss: 0.3939 - val_acc: 0.8492\n",
      "Epoch 42/1000\n",
      "690/712 [============================>.] - ETA: 0s - loss: 0.4466 - acc: 0.8087Epoch 00041: val_loss improved from 0.38803 to 0.38214, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 2s - loss: 0.4445 - acc: 0.8104 - val_loss: 0.3821 - val_acc: 0.8380\n",
      "Epoch 43/1000\n",
      "710/712 [============================>.] - ETA: 0s - loss: 0.4407 - acc: 0.8183Epoch 00042: val_loss did not improve\n",
      "712/712 [==============================] - 1s - loss: 0.4423 - acc: 0.8160 - val_loss: 0.5466 - val_acc: 0.8156\n",
      "Epoch 44/1000\n",
      "700/712 [============================>.] - ETA: 0s - loss: 0.4621 - acc: 0.7886Epoch 00043: val_loss did not improve\n",
      "712/712 [==============================] - 1s - loss: 0.4579 - acc: 0.7907 - val_loss: 0.4540 - val_acc: 0.8045\n",
      "Epoch 45/1000\n",
      "710/712 [============================>.] - ETA: 0s - loss: 0.4494 - acc: 0.8197Epoch 00044: val_loss did not improve\n",
      "712/712 [==============================] - 1s - loss: 0.4485 - acc: 0.8202 - val_loss: 0.3847 - val_acc: 0.8268\n",
      "Epoch 46/1000\n",
      "710/712 [============================>.] - ETA: 0s - loss: 0.4369 - acc: 0.8254Epoch 00045: val_loss did not improve\n",
      "712/712 [==============================] - 1s - loss: 0.4380 - acc: 0.8244 - val_loss: 0.4143 - val_acc: 0.8212\n",
      "Epoch 47/1000\n",
      "680/712 [===========================>..] - ETA: 0s - loss: 0.4450 - acc: 0.8088Epoch 00046: val_loss did not improve\n",
      "712/712 [==============================] - 1s - loss: 0.4461 - acc: 0.8104 - val_loss: 0.3923 - val_acc: 0.8212\n",
      "Epoch 48/1000\n",
      "700/712 [============================>.] - ETA: 0s - loss: 0.4388 - acc: 0.8143Epoch 00047: val_loss improved from 0.38214 to 0.38055, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 1s - loss: 0.4361 - acc: 0.8160 - val_loss: 0.3805 - val_acc: 0.8268\n",
      "Epoch 49/1000\n",
      "700/712 [============================>.] - ETA: 0s - loss: 0.4335 - acc: 0.8114Epoch 00048: val_loss did not improve\n",
      "712/712 [==============================] - 1s - loss: 0.4366 - acc: 0.8090 - val_loss: 0.4060 - val_acc: 0.8101\n",
      "Epoch 50/1000\n",
      "680/712 [===========================>..] - ETA: 0s - loss: 0.4326 - acc: 0.8250Epoch 00049: val_loss did not improve\n",
      "712/712 [==============================] - 1s - loss: 0.4437 - acc: 0.8188 - val_loss: 0.3913 - val_acc: 0.8492\n",
      "Epoch 51/1000\n",
      "710/712 [============================>.] - ETA: 0s - loss: 0.4456 - acc: 0.8056Epoch 00050: val_loss improved from 0.38055 to 0.37362, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 2s - loss: 0.4451 - acc: 0.8062 - val_loss: 0.3736 - val_acc: 0.8380\n",
      "Epoch 52/1000\n",
      "700/712 [============================>.] - ETA: 0s - loss: 0.4386 - acc: 0.8171Epoch 00051: val_loss did not improve\n",
      "712/712 [==============================] - 1s - loss: 0.4377 - acc: 0.8188 - val_loss: 0.3850 - val_acc: 0.8324\n",
      "Epoch 53/1000\n",
      "710/712 [============================>.] - ETA: 0s - loss: 0.4374 - acc: 0.8225Epoch 00052: val_loss did not improve\n",
      "712/712 [==============================] - 1s - loss: 0.4366 - acc: 0.8230 - val_loss: 0.3745 - val_acc: 0.8380\n",
      "Epoch 54/1000\n",
      "690/712 [============================>.] - ETA: 0s - loss: 0.4377 - acc: 0.8217Epoch 00053: val_loss did not improve\n",
      "712/712 [==============================] - 1s - loss: 0.4354 - acc: 0.8230 - val_loss: 0.3753 - val_acc: 0.8268\n",
      "Epoch 55/1000\n",
      "710/712 [============================>.] - ETA: 0s - loss: 0.4356 - acc: 0.8225Epoch 00054: val_loss did not improve\n",
      "712/712 [==============================] - 1s - loss: 0.4349 - acc: 0.8230 - val_loss: 0.3798 - val_acc: 0.8492\n",
      "Epoch 56/1000\n",
      "700/712 [============================>.] - ETA: 0s - loss: 0.4332 - acc: 0.8186Epoch 00055: val_loss did not improve\n",
      "712/712 [==============================] - 1s - loss: 0.4330 - acc: 0.8188 - val_loss: 0.3758 - val_acc: 0.8268\n",
      "Epoch 57/1000\n",
      "690/712 [============================>.] - ETA: 0s - loss: 0.4408 - acc: 0.8130Epoch 00056: val_loss did not improve\n",
      "712/712 [==============================] - 1s - loss: 0.4416 - acc: 0.8132 - val_loss: 0.3743 - val_acc: 0.8380\n",
      "Epoch 58/1000\n",
      "690/712 [============================>.] - ETA: 0s - loss: 0.4199 - acc: 0.8217Epoch 00057: val_loss did not improve\n",
      "712/712 [==============================] - 1s - loss: 0.4199 - acc: 0.8230 - val_loss: 0.3745 - val_acc: 0.8324\n",
      "Epoch 59/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "690/712 [============================>.] - ETA: 0s - loss: 0.4374 - acc: 0.8217Epoch 00058: val_loss did not improve\n",
      "712/712 [==============================] - 1s - loss: 0.4337 - acc: 0.8230 - val_loss: 0.5405 - val_acc: 0.7933\n",
      "Epoch 60/1000\n",
      "690/712 [============================>.] - ETA: 0s - loss: 0.4323 - acc: 0.8203Epoch 00059: val_loss did not improve\n",
      "712/712 [==============================] - 1s - loss: 0.4334 - acc: 0.8188 - val_loss: 0.3916 - val_acc: 0.8492\n",
      "Epoch 61/1000\n",
      "700/712 [============================>.] - ETA: 0s - loss: 0.4324 - acc: 0.8129Epoch 00060: val_loss improved from 0.37362 to 0.37322, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 3s - loss: 0.4299 - acc: 0.8146 - val_loss: 0.3732 - val_acc: 0.8268\n",
      "Epoch 62/1000\n",
      "700/712 [============================>.] - ETA: 0s - loss: 0.4219 - acc: 0.8171Epoch 00061: val_loss improved from 0.37322 to 0.37056, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 3s - loss: 0.4224 - acc: 0.8174 - val_loss: 0.3706 - val_acc: 0.8380\n",
      "Epoch 63/1000\n",
      "710/712 [============================>.] - ETA: 0s - loss: 0.4170 - acc: 0.8239Epoch 00062: val_loss did not improve\n",
      "712/712 [==============================] - 2s - loss: 0.4161 - acc: 0.8244 - val_loss: 0.3806 - val_acc: 0.8212\n",
      "Epoch 64/1000\n",
      "700/712 [============================>.] - ETA: 0s - loss: 0.4099 - acc: 0.8300Epoch 00063: val_loss did not improve\n",
      "712/712 [==============================] - 1s - loss: 0.4147 - acc: 0.8258 - val_loss: 0.3740 - val_acc: 0.8268\n",
      "Epoch 65/1000\n",
      "690/712 [============================>.] - ETA: 0s - loss: 0.4249 - acc: 0.8087Epoch 00064: val_loss improved from 0.37056 to 0.36988, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 3s - loss: 0.4192 - acc: 0.8132 - val_loss: 0.3699 - val_acc: 0.8492\n",
      "Epoch 66/1000\n",
      "710/712 [============================>.] - ETA: 0s - loss: 0.4321 - acc: 0.8225Epoch 00065: val_loss did not improve\n",
      "712/712 [==============================] - 1s - loss: 0.4311 - acc: 0.8230 - val_loss: 0.3973 - val_acc: 0.8212\n",
      "Epoch 67/1000\n",
      "700/712 [============================>.] - ETA: 0s - loss: 0.4204 - acc: 0.8271Epoch 00066: val_loss improved from 0.36988 to 0.36676, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 3s - loss: 0.4204 - acc: 0.8272 - val_loss: 0.3668 - val_acc: 0.8324\n",
      "Epoch 68/1000\n",
      "710/712 [============================>.] - ETA: 0s - loss: 0.4165 - acc: 0.8225Epoch 00067: val_loss improved from 0.36676 to 0.36490, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 2s - loss: 0.4157 - acc: 0.8230 - val_loss: 0.3649 - val_acc: 0.8436\n",
      "Epoch 69/1000\n",
      "700/712 [============================>.] - ETA: 0s - loss: 0.4180 - acc: 0.8257Epoch 00068: val_loss did not improve\n",
      "712/712 [==============================] - 2s - loss: 0.4166 - acc: 0.8244 - val_loss: 0.3997 - val_acc: 0.8492\n",
      "Epoch 70/1000\n",
      "690/712 [============================>.] - ETA: 0s - loss: 0.4210 - acc: 0.8232- ETA: 0s - loss: 0.4176 - Epoch 00069: val_loss did not improve\n",
      "712/712 [==============================] - 2s - loss: 0.4193 - acc: 0.8244 - val_loss: 0.4142 - val_acc: 0.8045\n",
      "Epoch 71/1000\n",
      "710/712 [============================>.] - ETA: 0s - loss: 0.4146 - acc: 0.8380Epoch 00070: val_loss did not improve\n",
      "712/712 [==============================] - 2s - loss: 0.4153 - acc: 0.8371 - val_loss: 0.4198 - val_acc: 0.8324\n",
      "Epoch 72/1000\n",
      "690/712 [============================>.] - ETA: 0s - loss: 0.4104 - acc: 0.8319Epoch 00071: val_loss did not improve\n",
      "712/712 [==============================] - 2s - loss: 0.4047 - acc: 0.8357 - val_loss: 0.3960 - val_acc: 0.8268\n",
      "Epoch 73/1000\n",
      "700/712 [============================>.] - ETA: 0s - loss: 0.4101 - acc: 0.8386Epoch 00072: val_loss improved from 0.36490 to 0.36061, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 4s - loss: 0.4131 - acc: 0.8357 - val_loss: 0.3606 - val_acc: 0.8436\n",
      "Epoch 74/1000\n",
      "700/712 [============================>.] - ETA: 0s - loss: 0.4100 - acc: 0.8286Epoch 00073: val_loss did not improve\n",
      "712/712 [==============================] - 2s - loss: 0.4085 - acc: 0.8301 - val_loss: 0.3631 - val_acc: 0.8324\n",
      "Epoch 75/1000\n",
      "700/712 [============================>.] - ETA: 0s - loss: 0.4040 - acc: 0.8314Epoch 00074: val_loss did not improve\n",
      "712/712 [==============================] - 2s - loss: 0.4047 - acc: 0.8329 - val_loss: 0.3745 - val_acc: 0.8492\n",
      "Epoch 76/1000\n",
      "710/712 [============================>.] - ETA: 0s - loss: 0.4164 - acc: 0.8296Epoch 00075: val_loss did not improve\n",
      "712/712 [==============================] - 2s - loss: 0.4165 - acc: 0.8287 - val_loss: 0.3621 - val_acc: 0.8380\n",
      "Epoch 77/1000\n",
      "700/712 [============================>.] - ETA: 0s - loss: 0.4037 - acc: 0.8357Epoch 00076: val_loss did not improve\n",
      "712/712 [==============================] - 2s - loss: 0.4064 - acc: 0.8343 - val_loss: 0.3633 - val_acc: 0.8324\n",
      "Epoch 78/1000\n",
      "700/712 [============================>.] - ETA: 0s - loss: 0.4235 - acc: 0.8257Epoch 00077: val_loss did not improve\n",
      "712/712 [==============================] - 2s - loss: 0.4239 - acc: 0.8244 - val_loss: 0.3826 - val_acc: 0.8380\n",
      "Epoch 79/1000\n",
      "700/712 [============================>.] - ETA: 0s - loss: 0.4183 - acc: 0.8257Epoch 00078: val_loss did not improve\n",
      "712/712 [==============================] - 2s - loss: 0.4174 - acc: 0.8258 - val_loss: 0.3661 - val_acc: 0.8547\n",
      "Epoch 80/1000\n",
      "700/712 [============================>.] - ETA: 0s - loss: 0.4154 - acc: 0.8257Epoch 00079: val_loss did not improve\n",
      "712/712 [==============================] - 2s - loss: 0.4171 - acc: 0.8244 - val_loss: 0.4080 - val_acc: 0.8156\n",
      "Epoch 81/1000\n",
      "710/712 [============================>.] - ETA: 0s - loss: 0.4191 - acc: 0.8338- ETA: 2s - loEpoch 00080: val_loss did not improve\n",
      "712/712 [==============================] - 2s - loss: 0.4184 - acc: 0.8343 - val_loss: 0.3679 - val_acc: 0.8324\n",
      "Epoch 82/1000\n",
      "690/712 [============================>.] - ETA: 0s - loss: 0.4092 - acc: 0.8319- ETA: 0s - loss: 0.3948 - aEpoch 00081: val_loss did not improve\n",
      "712/712 [==============================] - 2s - loss: 0.4064 - acc: 0.8343 - val_loss: 0.3684 - val_acc: 0.8324\n",
      "Epoch 83/1000\n",
      "710/712 [============================>.] - ETA: 0s - loss: 0.4132 - acc: 0.8225Epoch 00082: val_loss did not improve\n",
      "712/712 [==============================] - 2s - loss: 0.4124 - acc: 0.8230 - val_loss: 0.3629 - val_acc: 0.8380\n",
      "Epoch 84/1000\n",
      "710/712 [============================>.] - ETA: 0s - loss: 0.3973 - acc: 0.8437Epoch 00083: val_loss did not improve\n",
      "712/712 [==============================] - 2s - loss: 0.3965 - acc: 0.8441 - val_loss: 0.3726 - val_acc: 0.8324\n",
      "Epoch 00083: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "checkpointer = ModelCheckpoint(filepath=model_weights_file, verbose=1, save_best_only=True)\n",
    "stopper = EarlyStopping(monitor='val_loss', min_delta=1e-5, patience=10, verbose=1, mode='auto')\n",
    "hist = model.fit(X_train, y_train, epochs=1000, batch_size=10, validation_split=0.2, \n",
    "                 callbacks=[checkpointer, stopper], \n",
    "                 verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "704/891 [======================>.......] - ETA: 0s\n",
      "Training Accuracy: 0.837261504129\n"
     ]
    }
   ],
   "source": [
    "# Load the weights that yielded the best validation accuracy\n",
    "model.load_weights(model_weights_file)\n",
    "\n",
    "# Evaluate the model on the training set\n",
    "score = model.evaluate(X_train, y_train)\n",
    "print(\"\\nTraining Accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(418, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load test data\n",
    "df_test_raw = pd.read_csv(test_file)\n",
    "print(df_test_raw.shape)\n",
    "df_test_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before scaling: \n",
      "   PassengerId  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked  \\\n",
      "0          892       3    1  34.5      0      0   7.8292         1   \n",
      "1          893       3    0  47.0      1      0   7.0000         2   \n",
      "2          894       2    1  62.0      0      0   9.6875         1   \n",
      "3          895       3    1  27.0      0      0   8.6625         2   \n",
      "4          896       3    0  22.0      1      1  12.2875         2   \n",
      "\n",
      "   Family_Size  Title  Name_Length  In_Cabin  \n",
      "0            1      5           16         0  \n",
      "1            2      6           32         0  \n",
      "2            1      5           25         0  \n",
      "3            1      5           16         0  \n",
      "4            3      6           44         0  \n",
      "After scaling: \n",
      "    0    1         2      3         4         5    6    7      8     9    10\n",
      "0  1.0  1.0  0.453947  0.000  0.000000  0.015282  0.5  0.0  0.625  0.06  0.0\n",
      "1  1.0  0.0  0.618421  0.125  0.000000  0.013663  1.0  0.1  0.750  0.38  0.0\n",
      "2  0.5  1.0  0.815789  0.000  0.000000  0.018909  0.5  0.0  0.625  0.24  0.0\n",
      "3  1.0  1.0  0.355263  0.000  0.000000  0.016908  1.0  0.0  0.625  0.06  0.0\n",
      "4  1.0  0.0  0.289474  0.125  0.111111  0.023984  1.0  0.2  0.750  0.62  0.0\n",
      "(418, 11)\n",
      "[ 1.          1.          0.45394737  0.          0.          0.01528158\n",
      "  0.5         0.          0.625       0.06        0.        ]\n"
     ]
    }
   ],
   "source": [
    "# Prepare the data for testing\n",
    "df_test = prep_data(df_test_raw)\n",
    "X_test = np.array(df_test)[:,:]\n",
    "X_test = X_test.astype('float32')\n",
    "print(X_test.shape)\n",
    "print(X_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.88535404  0.10344614]\n"
     ]
    }
   ],
   "source": [
    "# Predict for test data\n",
    "y_test = model.predict(X_test)\n",
    "print(y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save predictions\n",
    "with open(pred_file, 'w') as f:\n",
    "    f.write('PassengerId,Survived\\n')\n",
    "    for index, y_hat in enumerate(y_test):\n",
    "        prediction = np.argmax(y_hat)\n",
    "        f.write(str(df_test_raw.iloc[index]['PassengerId']) + ',' + str(prediction)+'\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
