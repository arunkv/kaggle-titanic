{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training and test data files\n",
    "train_file = '../input/train.csv'\n",
    "test_file = '../input/test.csv'\n",
    "model_file = '../output/titanic.model.json'\n",
    "model_weights_file = '../output/titanic.model.best.hdf5'\n",
    "pred_file = '../output/gender_submission.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load training data\n",
    "df_train = pd.read_csv(train_file)\n",
    "print(df_train.shape)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 2)\n",
      "[[ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]]\n"
     ]
    }
   ],
   "source": [
    "# Extract survived data as predictions: 0 = Died, 1 = Survived\n",
    "from keras.utils.np_utils import to_categorical\n",
    "y_train = to_categorical(df_train[\"Survived\"], 2)\n",
    "df_train.pop('Survived')\n",
    "print(y_train.shape)\n",
    "print(y_train[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prepare the rest of the data for training\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "max_name_len = df_train.Name.map(len).max()    \n",
    "\n",
    "def prep_data(frame):\n",
    "    frame = frame.fillna(0)\n",
    "\n",
    "    # Creating new family_size and fare per person columns \n",
    "    frame['Family_Size'] = frame['SibSp'] + frame['Parch'] + 1\n",
    "    frame['Fare_Per_Person'] = frame['Fare']/frame['Family_Size']\n",
    "\n",
    "    # Convert Sex and Embarked to number\n",
    "    frame['Sex'] = pd.Categorical(frame['Sex']).codes\n",
    "    frame['Embarked'] = pd.Categorical(frame['Embarked']).codes\n",
    "    \n",
    "    # Convert name\n",
    "    for i in range(0, max_name_len):\n",
    "        col_name = 'Name' + str(i)\n",
    "        frame[col_name] = frame['Name'].str[i]\n",
    "        frame[col_name] = frame.apply(lambda row: ord(' ') if isinstance(row[col_name], float) and math.isnan(row[col_name]) else ord(row[col_name]), axis=1)\n",
    "    frame.pop('Name')\n",
    "    \n",
    "    # TODO: Ignore Ticket for now\n",
    "    frame.pop('Ticket')\n",
    "    \n",
    "    # Convert Cabin column to whether in cabin\n",
    "    frame['In_Cabin'] = frame.apply(lambda row: 1 if row['Cabin'] != 0 else 0, axis=1)\n",
    "    frame.pop('Cabin')\n",
    "    \n",
    "    print(\"Before scaling: \")\n",
    "    print(frame.head())\n",
    "    \n",
    "    # Scale everything except PassengerId\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    col_list = frame.columns.tolist()\n",
    "    col_list.remove('PassengerId')\n",
    "    frame = frame[col_list]\n",
    "    np_scaled = min_max_scaler.fit_transform(frame)\n",
    "    frame = pd.DataFrame(np_scaled)\n",
    "    \n",
    "    print(\"After scaling: \")\n",
    "    print(frame.head())\n",
    "\n",
    "    return frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before scaling: \n",
      "   PassengerId  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked  \\\n",
      "0            1       3    1  22.0      1      0   7.2500         3   \n",
      "1            2       1    0  38.0      1      0  71.2833         1   \n",
      "2            3       3    0  26.0      0      0   7.9250         3   \n",
      "3            4       1    0  35.0      1      0  53.1000         3   \n",
      "4            5       3    1  35.0      0      0   8.0500         3   \n",
      "\n",
      "   Family_Size  Fare_Per_Person    ...     Name73  Name74  Name75  Name76  \\\n",
      "0            2          3.62500    ...         32      32      32      32   \n",
      "1            2         35.64165    ...         32      32      32      32   \n",
      "2            1          7.92500    ...         32      32      32      32   \n",
      "3            2         26.55000    ...         32      32      32      32   \n",
      "4            1          8.05000    ...         32      32      32      32   \n",
      "\n",
      "   Name77  Name78  Name79  Name80  Name81  In_Cabin  \n",
      "0      32      32      32      32      32         0  \n",
      "1      32      32      32      32      32         1  \n",
      "2      32      32      32      32      32         0  \n",
      "3      32      32      32      32      32         1  \n",
      "4      32      32      32      32      32         0  \n",
      "\n",
      "[5 rows x 93 columns]\n",
      "After scaling: \n",
      "    0    1       2      3    4         5         6    7         8         9   \\\n",
      "0  1.0  1.0  0.2750  0.125  0.0  0.014151  1.000000  0.1  0.007076  0.018868   \n",
      "1  0.0  0.0  0.4750  0.125  0.0  0.139136  0.333333  0.1  0.069568  0.037736   \n",
      "2  1.0  0.0  0.3250  0.000  0.0  0.015469  1.000000  0.0  0.015469  0.132075   \n",
      "3  0.0  0.0  0.4375  0.125  0.0  0.103644  1.000000  0.1  0.051822  0.094340   \n",
      "4  1.0  1.0  0.4375  0.000  0.0  0.015713  1.000000  0.0  0.015713  0.000000   \n",
      "\n",
      "  ...    82   83   84   85   86   87   88   89   90   91  \n",
      "0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "1 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  \n",
      "2 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "3 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  \n",
      "4 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "\n",
      "[5 rows x 92 columns]\n",
      "(891, 92)\n",
      "[ 1.          1.          0.27500001  0.125       0.          0.01415106\n",
      "  1.          0.1         0.00707553  0.01886792  0.91463417  0.72222221\n",
      "  0.94444442  0.86666667  0.75555557  0.13483146  0.          0.50561798\n",
      "  0.95348835  0.15730338  0.          0.54022986  0.9775281   0.76666665\n",
      "  0.87640452  0.          0.44444445  0.72222221  0.91111112  0.91111112\n",
      "  0.81111109  0.93258429  0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "# Prepare the rest of the data for training\n",
    "df_train = prep_data(df_train)\n",
    "X_train = np.array(df_train)[:,:]\n",
    "X_train = X_train.astype('float32')\n",
    "print(X_train.shape)\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_64 (Dense)             (None, 891)               82863     \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 891)               0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 891)               0         \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 512)               456704    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 803,249\n",
      "Trainable params: 803,249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build a training network\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(X_train.shape[0], activation='relu', input_shape=(X_train.shape[1], )))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LeakyReLU())\n",
    "model.add(Dense(512))\n",
    "model.add(LeakyReLU())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512))\n",
    "model.add(LeakyReLU())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "sgd = SGD(lr=1e-2, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/1000\n",
      "670/712 [===========================>..] - ETA: 0s - loss: 0.6765 - acc: 0.6119Epoch 00000: val_loss improved from inf to 0.64863, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 1s - loss: 0.6745 - acc: 0.6166 - val_loss: 0.6486 - val_acc: 0.6425\n",
      "Epoch 2/1000\n",
      "710/712 [============================>.] - ETA: 0s - loss: 0.6575 - acc: 0.6070Epoch 00001: val_loss improved from 0.64863 to 0.62321, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.6571 - acc: 0.6081 - val_loss: 0.6232 - val_acc: 0.6425\n",
      "Epoch 3/1000\n",
      "630/712 [=========================>....] - ETA: 0s - loss: 0.6387 - acc: 0.6317Epoch 00002: val_loss improved from 0.62321 to 0.59923, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.6378 - acc: 0.6306 - val_loss: 0.5992 - val_acc: 0.6425\n",
      "Epoch 4/1000\n",
      "620/712 [=========================>....] - ETA: 0s - loss: 0.6180 - acc: 0.6484Epoch 00003: val_loss improved from 0.59923 to 0.57964, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.6224 - acc: 0.6447 - val_loss: 0.5796 - val_acc: 0.7430\n",
      "Epoch 5/1000\n",
      "620/712 [=========================>....] - ETA: 0s - loss: 0.6045 - acc: 0.6823Epoch 00004: val_loss improved from 0.57964 to 0.54907, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.6039 - acc: 0.6812 - val_loss: 0.5491 - val_acc: 0.7765\n",
      "Epoch 6/1000\n",
      "630/712 [=========================>....] - ETA: 0s - loss: 0.5918 - acc: 0.6762Epoch 00005: val_loss improved from 0.54907 to 0.52675, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.5895 - acc: 0.6826 - val_loss: 0.5268 - val_acc: 0.7709\n",
      "Epoch 7/1000\n",
      "630/712 [=========================>....] - ETA: 0s - loss: 0.5540 - acc: 0.7333Epoch 00006: val_loss improved from 0.52675 to 0.49422, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.5646 - acc: 0.7205 - val_loss: 0.4942 - val_acc: 0.7821\n",
      "Epoch 8/1000\n",
      "640/712 [=========================>....] - ETA: 0s - loss: 0.5533 - acc: 0.7219Epoch 00007: val_loss improved from 0.49422 to 0.47536, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.5493 - acc: 0.7247 - val_loss: 0.4754 - val_acc: 0.7821\n",
      "Epoch 9/1000\n",
      "630/712 [=========================>....] - ETA: 0s - loss: 0.5294 - acc: 0.7460Epoch 00008: val_loss improved from 0.47536 to 0.46384, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.5272 - acc: 0.7486 - val_loss: 0.4638 - val_acc: 0.7933\n",
      "Epoch 10/1000\n",
      "640/712 [=========================>....] - ETA: 0s - loss: 0.5221 - acc: 0.7531Epoch 00009: val_loss improved from 0.46384 to 0.45523, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.5263 - acc: 0.7514 - val_loss: 0.4552 - val_acc: 0.7821\n",
      "Epoch 11/1000\n",
      "620/712 [=========================>....] - ETA: 0s - loss: 0.5174 - acc: 0.7629Epoch 00010: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.5168 - acc: 0.7669 - val_loss: 0.4641 - val_acc: 0.7877\n",
      "Epoch 12/1000\n",
      "630/712 [=========================>....] - ETA: 0s - loss: 0.5067 - acc: 0.7714Epoch 00011: val_loss improved from 0.45523 to 0.44382, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.5078 - acc: 0.7697 - val_loss: 0.4438 - val_acc: 0.7933\n",
      "Epoch 13/1000\n",
      "640/712 [=========================>....] - ETA: 0s - loss: 0.5035 - acc: 0.7719Epoch 00012: val_loss improved from 0.44382 to 0.43785, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.5142 - acc: 0.7626 - val_loss: 0.4378 - val_acc: 0.7877\n",
      "Epoch 14/1000\n",
      "660/712 [==========================>...] - ETA: 0s - loss: 0.4988 - acc: 0.7727Epoch 00013: val_loss improved from 0.43785 to 0.43063, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.4935 - acc: 0.7767 - val_loss: 0.4306 - val_acc: 0.7877\n",
      "Epoch 15/1000\n",
      "710/712 [============================>.] - ETA: 0s - loss: 0.4946 - acc: 0.7873Epoch 00014: val_loss improved from 0.43063 to 0.42694, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.4942 - acc: 0.7879 - val_loss: 0.4269 - val_acc: 0.7933\n",
      "Epoch 16/1000\n",
      "610/712 [========================>.....] - ETA: 0s - loss: 0.4787 - acc: 0.7738Epoch 00015: val_loss improved from 0.42694 to 0.42592, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.4854 - acc: 0.7725 - val_loss: 0.4259 - val_acc: 0.7933\n",
      "Epoch 17/1000\n",
      "630/712 [=========================>....] - ETA: 0s - loss: 0.4875 - acc: 0.7857Epoch 00016: val_loss improved from 0.42592 to 0.42354, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.4816 - acc: 0.7879 - val_loss: 0.4235 - val_acc: 0.7933\n",
      "Epoch 18/1000\n",
      "650/712 [==========================>...] - ETA: 0s - loss: 0.4849 - acc: 0.7738Epoch 00017: val_loss improved from 0.42354 to 0.41628, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.4819 - acc: 0.7795 - val_loss: 0.4163 - val_acc: 0.8045\n",
      "Epoch 19/1000\n",
      "630/712 [=========================>....] - ETA: 0s - loss: 0.4712 - acc: 0.7746Epoch 00018: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4712 - acc: 0.7781 - val_loss: 0.4177 - val_acc: 0.7989\n",
      "Epoch 20/1000\n",
      "630/712 [=========================>....] - ETA: 0s - loss: 0.4585 - acc: 0.7984Epoch 00019: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4582 - acc: 0.7992 - val_loss: 0.4164 - val_acc: 0.7933\n",
      "Epoch 21/1000\n",
      "650/712 [==========================>...] - ETA: 0s - loss: 0.4795 - acc: 0.8015Epoch 00020: val_loss improved from 0.41628 to 0.41306, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.4734 - acc: 0.8020 - val_loss: 0.4131 - val_acc: 0.8045\n",
      "Epoch 22/1000\n",
      "630/712 [=========================>....] - ETA: 0s - loss: 0.4588 - acc: 0.7873Epoch 00021: val_loss improved from 0.41306 to 0.41097, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.4554 - acc: 0.7921 - val_loss: 0.4110 - val_acc: 0.8156\n",
      "Epoch 23/1000\n",
      "630/712 [=========================>....] - ETA: 0s - loss: 0.4715 - acc: 0.7857Epoch 00022: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4695 - acc: 0.7879 - val_loss: 0.4133 - val_acc: 0.8156\n",
      "Epoch 24/1000\n",
      "630/712 [=========================>....] - ETA: 0s - loss: 0.4427 - acc: 0.7937Epoch 00023: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4579 - acc: 0.7823 - val_loss: 0.4136 - val_acc: 0.8101\n",
      "Epoch 25/1000\n",
      "630/712 [=========================>....] - ETA: 0s - loss: 0.4647 - acc: 0.7857Epoch 00024: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4680 - acc: 0.7851 - val_loss: 0.4166 - val_acc: 0.8212\n",
      "Epoch 26/1000\n",
      "630/712 [=========================>....] - ETA: 0s - loss: 0.4449 - acc: 0.8016Epoch 00025: val_loss improved from 0.41097 to 0.40997, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.4496 - acc: 0.7949 - val_loss: 0.4100 - val_acc: 0.8156\n",
      "Epoch 27/1000\n",
      "710/712 [============================>.] - ETA: 0s - loss: 0.4342 - acc: 0.8056Epoch 00026: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4360 - acc: 0.8048 - val_loss: 0.4247 - val_acc: 0.8045\n",
      "Epoch 28/1000\n",
      "620/712 [=========================>....] - ETA: 0s - loss: 0.4538 - acc: 0.8161Epoch 00027: val_loss improved from 0.40997 to 0.40819, saving model to ../output/titanic.model.best.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s - loss: 0.4498 - acc: 0.8146 - val_loss: 0.4082 - val_acc: 0.8212\n",
      "Epoch 29/1000\n",
      "670/712 [===========================>..] - ETA: 0s - loss: 0.4521 - acc: 0.8030Epoch 00028: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4526 - acc: 0.8034 - val_loss: 0.4131 - val_acc: 0.8045\n",
      "Epoch 30/1000\n",
      "650/712 [==========================>...] - ETA: 0s - loss: 0.4486 - acc: 0.8108Epoch 00029: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4471 - acc: 0.8132 - val_loss: 0.4103 - val_acc: 0.7989\n",
      "Epoch 31/1000\n",
      "620/712 [=========================>....] - ETA: 0s - loss: 0.4578 - acc: 0.8016Epoch 00030: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4547 - acc: 0.7992 - val_loss: 0.4085 - val_acc: 0.8212\n",
      "Epoch 32/1000\n",
      "670/712 [===========================>..] - ETA: 0s - loss: 0.4365 - acc: 0.8134Epoch 00031: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4407 - acc: 0.8104 - val_loss: 0.4089 - val_acc: 0.8156\n",
      "Epoch 33/1000\n",
      "640/712 [=========================>....] - ETA: 0s - loss: 0.4219 - acc: 0.8156Epoch 00032: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4336 - acc: 0.8062 - val_loss: 0.4087 - val_acc: 0.8156\n",
      "Epoch 34/1000\n",
      "670/712 [===========================>..] - ETA: 0s - loss: 0.4389 - acc: 0.8149Epoch 00033: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4342 - acc: 0.8160 - val_loss: 0.4103 - val_acc: 0.8101\n",
      "Epoch 35/1000\n",
      "670/712 [===========================>..] - ETA: 0s - loss: 0.4312 - acc: 0.8179Epoch 00034: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4368 - acc: 0.8118 - val_loss: 0.4095 - val_acc: 0.8156\n",
      "Epoch 36/1000\n",
      "640/712 [=========================>....] - ETA: 0s - loss: 0.4286 - acc: 0.8078Epoch 00035: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4265 - acc: 0.8090 - val_loss: 0.4093 - val_acc: 0.8101\n",
      "Epoch 37/1000\n",
      "670/712 [===========================>..] - ETA: 0s - loss: 0.4256 - acc: 0.8224Epoch 00036: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4280 - acc: 0.8216 - val_loss: 0.4097 - val_acc: 0.8156\n",
      "Epoch 38/1000\n",
      "670/712 [===========================>..] - ETA: 0s - loss: 0.4332 - acc: 0.8015Epoch 00037: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4439 - acc: 0.7907 - val_loss: 0.4099 - val_acc: 0.8212\n",
      "Epoch 39/1000\n",
      "620/712 [=========================>....] - ETA: 0s - loss: 0.4309 - acc: 0.8274Epoch 00038: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4353 - acc: 0.8202 - val_loss: 0.4117 - val_acc: 0.8101\n",
      "Epoch 00038: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "checkpointer = ModelCheckpoint(filepath=model_weights_file, verbose=1, save_best_only=True)\n",
    "stopper = EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=10, verbose=1, mode='auto')\n",
    "hist = model.fit(X_train, y_train, epochs=1000, batch_size=10, validation_split=0.2, \n",
    "                 callbacks=[checkpointer, stopper], \n",
    "                 verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "736/891 [=======================>......] - ETA: 0s\n",
      " Training Accuracy: 0.819304152838\n"
     ]
    }
   ],
   "source": [
    "# Load the weights that yielded the best validation accuracy\n",
    "model.load_weights(model_weights_file)\n",
    "\n",
    "# Evaluate the model on the training set\n",
    "score = model.evaluate(X_train, y_train)\n",
    "print(\"\\n Training Accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(418, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load test data\n",
    "df_test_raw = pd.read_csv(test_file)\n",
    "print(df_test_raw.shape)\n",
    "df_test_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before scaling: \n",
      "   PassengerId  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked  \\\n",
      "0          892       3    1  34.5      0      0   7.8292         1   \n",
      "1          893       3    0  47.0      1      0   7.0000         2   \n",
      "2          894       2    1  62.0      0      0   9.6875         1   \n",
      "3          895       3    1  27.0      0      0   8.6625         2   \n",
      "4          896       3    0  22.0      1      1  12.2875         2   \n",
      "\n",
      "   Family_Size  Fare_Per_Person    ...     Name73  Name74  Name75  Name76  \\\n",
      "0            1         7.829200    ...         32      32      32      32   \n",
      "1            2         3.500000    ...         32      32      32      32   \n",
      "2            1         9.687500    ...         32      32      32      32   \n",
      "3            1         8.662500    ...         32      32      32      32   \n",
      "4            3         4.095833    ...         32      32      32      32   \n",
      "\n",
      "   Name77  Name78  Name79  Name80  Name81  In_Cabin  \n",
      "0      32      32      32      32      32         0  \n",
      "1      32      32      32      32      32         0  \n",
      "2      32      32      32      32      32         0  \n",
      "3      32      32      32      32      32         0  \n",
      "4      32      32      32      32      32         0  \n",
      "\n",
      "[5 rows x 93 columns]\n",
      "After scaling: \n",
      "    0    1         2      3         4         5    6    7         8   \\\n",
      "0  1.0  1.0  0.453947  0.000  0.000000  0.015282  0.5  0.0  0.029840   \n",
      "1  1.0  0.0  0.618421  0.125  0.000000  0.013663  1.0  0.1  0.013340   \n",
      "2  0.5  1.0  0.815789  0.000  0.000000  0.018909  0.5  0.0  0.036922   \n",
      "3  1.0  1.0  0.355263  0.000  0.000000  0.016908  1.0  0.0  0.033016   \n",
      "4  1.0  0.0  0.289474  0.125  0.111111  0.023984  1.0  0.2  0.015611   \n",
      "\n",
      "         9  ...    82   83   84   85   86   87   88   89   90   91  \n",
      "0  0.188679 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "1  0.415094 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2  0.226415 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "3  0.415094 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "4  0.132075 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "\n",
      "[5 rows x 92 columns]\n",
      "(418, 92)\n",
      "[ 1.          1.          0.45394737  0.          0.          0.01528158\n",
      "  0.5         0.          0.02983973  0.18867925  0.75609756  0.85393256\n",
      "  0.84444445  0.98888886  0.13333334  0.          0.5         0.94252872\n",
      "  0.15555556  0.          0.49411765  0.74712646  0.89534885  0.77528089\n",
      "  0.9222222   0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "# Prepare the data for testing\n",
    "df_test = prep_data(df_test_raw)\n",
    "X_test = np.array(df_test)[:,:]\n",
    "X_test = X_test.astype('float32')\n",
    "print(X_test.shape)\n",
    "print(X_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.68717349  0.09487092]\n"
     ]
    }
   ],
   "source": [
    "# Predict for test data\n",
    "y_test = model.predict(X_test)\n",
    "print(y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save predictions\n",
    "with open(pred_file, 'w') as f:\n",
    "    f.write('PassengerId,Survived\\n')\n",
    "    for index, y_hat in enumerate(y_test):\n",
    "        prediction = np.argmax(y_hat)\n",
    "        f.write(str(df_test_raw.iloc[index]['PassengerId']) + ',' + str(prediction)+'\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
