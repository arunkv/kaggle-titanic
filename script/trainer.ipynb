{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training and test data files\n",
    "train_file = '../input/train.csv'\n",
    "test_file = '../input/test.csv'\n",
    "model_file = '../output/titanic.model.json'\n",
    "model_weights_file = '../output/titanic.model.best.hdf5'\n",
    "pred_file = '../output/gender_submission.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load training data\n",
    "df_train = pd.read_csv(train_file)\n",
    "print(df_train.shape)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 2)\n",
      "[[ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]]\n"
     ]
    }
   ],
   "source": [
    "# Extract survived data as predictions: 0 = Died, 1 = Survived\n",
    "from keras.utils.np_utils import to_categorical\n",
    "y_train = to_categorical(df_train[\"Survived\"], 2)\n",
    "df_train.pop('Survived')\n",
    "print(y_train.shape)\n",
    "print(y_train[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prepare the rest of the data for training\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "max_name_len = df_train.Name.map(len).max()\n",
    "max_ticket_len = df_train.Ticket.map(len).max()\n",
    "\n",
    "title_list=['Mrs', 'Mr', 'Master', 'Miss', 'Major', 'Rev', 'Dr', 'Ms', 'Mlle',\n",
    "            'Col', 'Capt', 'Mme', 'Countess', 'Don', 'Jonkheer']\n",
    "\n",
    "import string\n",
    "def substrings_in_string(big_string, substrings):\n",
    "    for substring in substrings:\n",
    "        if substring in big_string:\n",
    "            return substring\n",
    "    return np.nan\n",
    "\n",
    "def prep_data(frame):\n",
    "    # Creating new family_size and fare per person columns \n",
    "    frame['Family_Size'] = frame['SibSp'] + frame['Parch'] + 1\n",
    "\n",
    "    # Convert Sex and Embarked to number\n",
    "    frame['Sex'] = pd.Categorical(frame['Sex']).codes\n",
    "    frame['Embarked'] = pd.Categorical(frame['Embarked']).codes\n",
    "    \n",
    "    # Extract title from name\n",
    "    frame['Title'] = frame['Name'].map(lambda x: substrings_in_string(x, title_list))\n",
    "    frame['Title'] = pd.Categorical(frame['Title']).codes\n",
    "\n",
    "    # Convert Name into characters\n",
    "    frame['Name_Length'] = frame.apply(lambda row: len(row['Name']), axis=1)\n",
    "    for i in range(0, max_name_len):\n",
    "        col_name = 'Name' + str(i)\n",
    "        frame[col_name] = frame['Name'].str[i]\n",
    "        frame[col_name] = frame.apply(lambda row: 0 if isinstance(row[col_name], float) and math.isnan(row[col_name]) else ord(row[col_name]), axis=1)\n",
    "    frame.pop('Name')    \n",
    "    \n",
    "    # Convert Ticket into characters\n",
    "    frame['Ticket_Length'] = frame.apply(lambda row: len(row['Ticket']), axis=1)\n",
    "    for i in range(0, max_ticket_len):\n",
    "        col_name = 'Ticket' + str(i)\n",
    "        frame[col_name] = frame['Ticket'].str[i]\n",
    "        frame[col_name] = frame.apply(lambda row: 0 if isinstance(row[col_name], float) and math.isnan(row[col_name]) else ord(row[col_name]), axis=1)\n",
    "    frame.pop('Ticket')    \n",
    "    \n",
    "    # Convert Cabin column to whether in cabin\n",
    "    frame['In_Cabin'] = frame.apply(lambda row: 1 if row['Cabin'] != 0 else 0, axis=1)\n",
    "    frame.pop('Cabin')\n",
    "    \n",
    "    # Change any remaining N/As to 0\n",
    "    frame = frame.fillna(0)\n",
    "\n",
    "    print(\"Before scaling: \")\n",
    "    print(frame.head())\n",
    "    \n",
    "    # Scale everything except PassengerId\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    col_list = frame.columns.tolist()\n",
    "    col_list.remove('PassengerId')\n",
    "    frame = frame[col_list]\n",
    "    np_scaled = min_max_scaler.fit_transform(frame)\n",
    "    frame = pd.DataFrame(np_scaled)\n",
    "    \n",
    "    print(\"After scaling: \")\n",
    "    print(frame.head())\n",
    "\n",
    "    return frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before scaling: \n",
      "   PassengerId  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked  \\\n",
      "0            1       3    1  22.0      1      0   7.2500         2   \n",
      "1            2       1    0  38.0      1      0  71.2833         0   \n",
      "2            3       3    0  26.0      0      0   7.9250         2   \n",
      "3            4       1    0  35.0      1      0  53.1000         2   \n",
      "4            5       3    1  35.0      0      0   8.0500         2   \n",
      "\n",
      "   Family_Size  Title    ...     Ticket9  Ticket10  Ticket11  Ticket12  \\\n",
      "0            2     11    ...           0         0         0         0   \n",
      "1            2     12    ...           0         0         0         0   \n",
      "2            1      8    ...          51        49        48        49   \n",
      "3            2     12    ...           0         0         0         0   \n",
      "4            1     11    ...           0         0         0         0   \n",
      "\n",
      "   Ticket13  Ticket14  Ticket15  Ticket16  Ticket17  In_Cabin  \n",
      "0         0         0         0         0         0         1  \n",
      "1         0         0         0         0         0         1  \n",
      "2        50        56        50         0         0         1  \n",
      "3         0         0         0         0         0         1  \n",
      "4         0         0         0         0         0         1  \n",
      "\n",
      "[5 rows x 113 columns]\n",
      "After scaling: \n",
      "   0    1       2      3    4         5         6    7         8         9    \\\n",
      "0  1.0  1.0  0.2750  0.125  0.0  0.014151  1.000000  0.1  0.785714  0.157143   \n",
      "1  0.0  0.0  0.4750  0.125  0.0  0.139136  0.333333  0.1  0.857143  0.557143   \n",
      "2  1.0  0.0  0.3250  0.000  0.0  0.015469  1.000000  0.0  0.571429  0.142857   \n",
      "3  0.0  0.0  0.4375  0.125  0.0  0.103644  1.000000  0.1  0.857143  0.457143   \n",
      "4  1.0  1.0  0.4375  0.000  0.0  0.015713  1.000000  0.0  0.785714  0.171429   \n",
      "\n",
      "  ...        102       103       104       105       106       107       108  \\\n",
      "0 ...   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "1 ...   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "2 ...   0.472222  0.485149  0.842105  0.859649  0.877193  0.982456  0.877193   \n",
      "3 ...   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "4 ...   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "\n",
      "   109  110  111  \n",
      "0  0.0  0.0  0.0  \n",
      "1  0.0  0.0  0.0  \n",
      "2  0.0  0.0  0.0  \n",
      "3  0.0  0.0  0.0  \n",
      "4  0.0  0.0  0.0  \n",
      "\n",
      "[5 rows x 112 columns]\n",
      "(891, 112)\n",
      "[ 1.          1.          0.27500001  0.125       0.          0.01415106\n",
      "  1.          0.1         0.78571427  0.15714286  0.01886792  0.91463417\n",
      "  0.72222221  0.94444442  0.86666667  0.75555557  0.13483146  0.\n",
      "  0.50561798  0.95348835  0.15730338  0.          0.66386557  0.9834711\n",
      "  0.82786888  0.90909094  0.26229507  0.59016395  0.79508197  0.93442625\n",
      "  0.93442625  0.86065573  0.95041323  0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.40000001  0.42105263  0.23076923  0.38181818  0.40000001  0.51546389\n",
      "  0.42982456  0.46666667  0.47826087  0.42608696  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "# Prepare the rest of the data for training\n",
    "df_train = prep_data(df_train)\n",
    "X_train = np.array(df_train)[:,:]\n",
    "X_train = X_train.astype('float32')\n",
    "print(X_train.shape)\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a training network\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, RepeatVector, Flatten, Activation\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "\n",
    "def create_model(nodes = 512, layers = 2, optimizer='sgd'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(nodes, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "    for i in range(1, layers):\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(nodes, activation='relu'))\n",
    "    model.add(Dense(2, activation='sigmoid'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the model\n",
    "#model_json = model.to_json()\n",
    "#with open(model_file, 'w') as json_file:\n",
    "#    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 378 candidates, totalling 1134 fits\n",
      "[CV] layers=1, nodes=32, optimizer=SGD ...............................\n",
      "[CV] layers=1, nodes=32, optimizer=SGD ...............................\n",
      "[CV] layers=1, nodes=32, optimizer=SGD ...............................\n",
      "[CV] layers=1, nodes=32, optimizer=RMSprop ...........................\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-194-952dd1ee0585>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mparam_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mgrid_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda/envs/kaggle/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    943\u001b[0m             \u001b[0mtrain\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtest\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m         \"\"\"\n\u001b[0;32m--> 945\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/kaggle/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, groups, parameter_iterable)\u001b[0m\n\u001b[1;32m    562\u001b[0m                                   \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m--> 564\u001b[0;31m           \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m           for train, test in cv_iter)\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/kaggle/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    766\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/kaggle/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    717\u001b[0m                     \u001b[0mensure_ready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                     \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabort_everything\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/kaggle/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    680\u001b[0m                 \u001b[0;31m# check if timeout supported in backend future implementation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m'timeout'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgetfullargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    683\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/kaggle/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/kaggle/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/kaggle/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/kaggle/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Grid search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n",
    "\n",
    "# Define the grid search parameters\n",
    "nodes = range(32, X_train.shape[0], 32)\n",
    "layers = range(1, 3)\n",
    "optimizers = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "param_grid = dict(nodes=nodes, layers=layers, optimizer=optimizers)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, verbose=2)\n",
    "grid_result = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the best parameters\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 668 samples, validate on 223 samples\n",
      "Epoch 1/1000\n",
      "660/668 [============================>.] - ETA: 0s - loss: 0.6851 - acc: 0.5773Epoch 00000: val_loss improved from inf to 0.66549, saving model to ../output/titanic.model.best.hdf5\n",
      "668/668 [==============================] - 1s - loss: 0.6846 - acc: 0.5793 - val_loss: 0.6655 - val_acc: 0.6368\n",
      "Epoch 2/1000\n",
      "640/668 [===========================>..] - ETA: 0s - loss: 0.6630 - acc: 0.6203Epoch 00001: val_loss improved from 0.66549 to 0.64650, saving model to ../output/titanic.model.best.hdf5\n",
      "668/668 [==============================] - 0s - loss: 0.6631 - acc: 0.6168 - val_loss: 0.6465 - val_acc: 0.6323\n",
      "Epoch 3/1000\n",
      "500/668 [=====================>........] - ETA: 0s - loss: 0.6544 - acc: 0.6240Epoch 00002: val_loss improved from 0.64650 to 0.63177, saving model to ../output/titanic.model.best.hdf5\n",
      "668/668 [==============================] - 0s - loss: 0.6508 - acc: 0.6228 - val_loss: 0.6318 - val_acc: 0.6323\n",
      "Epoch 4/1000\n",
      "520/668 [======================>.......] - ETA: 0s - loss: 0.6452 - acc: 0.6096Epoch 00003: val_loss improved from 0.63177 to 0.61733, saving model to ../output/titanic.model.best.hdf5\n",
      "668/668 [==============================] - 0s - loss: 0.6387 - acc: 0.6257 - val_loss: 0.6173 - val_acc: 0.6368\n",
      "Epoch 5/1000\n",
      "640/668 [===========================>..] - ETA: 0s - loss: 0.6229 - acc: 0.6422Epoch 00004: val_loss improved from 0.61733 to 0.60577, saving model to ../output/titanic.model.best.hdf5\n",
      "668/668 [==============================] - 0s - loss: 0.6258 - acc: 0.6377 - val_loss: 0.6058 - val_acc: 0.7085\n",
      "Epoch 6/1000\n",
      "640/668 [===========================>..] - ETA: 0s - loss: 0.6181 - acc: 0.6453Epoch 00005: val_loss improved from 0.60577 to 0.59330, saving model to ../output/titanic.model.best.hdf5\n",
      "668/668 [==============================] - 0s - loss: 0.6163 - acc: 0.6512 - val_loss: 0.5933 - val_acc: 0.7265\n",
      "Epoch 7/1000\n",
      "660/668 [============================>.] - ETA: 0s - loss: 0.6007 - acc: 0.6667Epoch 00006: val_loss improved from 0.59330 to 0.58165, saving model to ../output/titanic.model.best.hdf5\n",
      "668/668 [==============================] - 0s - loss: 0.6022 - acc: 0.6662 - val_loss: 0.5817 - val_acc: 0.7489\n",
      "Epoch 8/1000\n",
      "560/668 [========================>.....] - ETA: 0s - loss: 0.5917 - acc: 0.6911Epoch 00007: val_loss improved from 0.58165 to 0.56947, saving model to ../output/titanic.model.best.hdf5\n",
      "668/668 [==============================] - 0s - loss: 0.5943 - acc: 0.6841 - val_loss: 0.5695 - val_acc: 0.7399\n",
      "Epoch 9/1000\n",
      "540/668 [=======================>......] - ETA: 0s - loss: 0.5756 - acc: 0.7037Epoch 00008: val_loss improved from 0.56947 to 0.56109, saving model to ../output/titanic.model.best.hdf5\n",
      "668/668 [==============================] - 0s - loss: 0.5800 - acc: 0.6991 - val_loss: 0.5611 - val_acc: 0.7489\n",
      "Epoch 10/1000\n",
      "660/668 [============================>.] - ETA: 0s - loss: 0.5686 - acc: 0.7227Epoch 00009: val_loss improved from 0.56109 to 0.54817, saving model to ../output/titanic.model.best.hdf5\n",
      "668/668 [==============================] - 0s - loss: 0.5684 - acc: 0.7216 - val_loss: 0.5482 - val_acc: 0.7534\n",
      "Epoch 11/1000\n",
      "520/668 [======================>.......] - ETA: 0s - loss: 0.5695 - acc: 0.7192Epoch 00010: val_loss improved from 0.54817 to 0.53435, saving model to ../output/titanic.model.best.hdf5\n",
      "668/668 [==============================] - 0s - loss: 0.5565 - acc: 0.7246 - val_loss: 0.5343 - val_acc: 0.7489\n",
      "Epoch 12/1000\n",
      "580/668 [=========================>....] - ETA: 0s - loss: 0.5542 - acc: 0.7207Epoch 00011: val_loss improved from 0.53435 to 0.52877, saving model to ../output/titanic.model.best.hdf5\n",
      "668/668 [==============================] - 0s - loss: 0.5578 - acc: 0.7186 - val_loss: 0.5288 - val_acc: 0.7578\n",
      "Epoch 13/1000\n",
      "660/668 [============================>.] - ETA: 0s - loss: 0.5403 - acc: 0.7470Epoch 00012: val_loss improved from 0.52877 to 0.51758, saving model to ../output/titanic.model.best.hdf5\n",
      "668/668 [==============================] - 0s - loss: 0.5395 - acc: 0.7485 - val_loss: 0.5176 - val_acc: 0.7489\n",
      "Epoch 14/1000\n",
      "640/668 [===========================>..] - ETA: 0s - loss: 0.5375 - acc: 0.7500Epoch 00013: val_loss improved from 0.51758 to 0.51118, saving model to ../output/titanic.model.best.hdf5\n",
      "668/668 [==============================] - 0s - loss: 0.5393 - acc: 0.7440 - val_loss: 0.5112 - val_acc: 0.7623\n",
      "Epoch 15/1000\n",
      "600/668 [=========================>....] - ETA: 0s - loss: 0.5208 - acc: 0.7583Epoch 00014: val_loss improved from 0.51118 to 0.50443, saving model to ../output/titanic.model.best.hdf5\n",
      "668/668 [==============================] - 0s - loss: 0.5289 - acc: 0.7500 - val_loss: 0.5044 - val_acc: 0.7623\n",
      "Epoch 16/1000\n",
      "600/668 [=========================>....] - ETA: 0s - loss: 0.5177 - acc: 0.7550Epoch 00015: val_loss improved from 0.50443 to 0.49962, saving model to ../output/titanic.model.best.hdf5\n",
      "668/668 [==============================] - 0s - loss: 0.5259 - acc: 0.7530 - val_loss: 0.4996 - val_acc: 0.7668\n",
      "Epoch 17/1000\n",
      "620/668 [==========================>...] - ETA: 0s - loss: 0.5167 - acc: 0.7516Epoch 00016: val_loss improved from 0.49962 to 0.49191, saving model to ../output/titanic.model.best.hdf5\n",
      "668/668 [==============================] - 0s - loss: 0.5185 - acc: 0.7515 - val_loss: 0.4919 - val_acc: 0.7758\n",
      "Epoch 18/1000\n",
      "560/668 [========================>.....] - ETA: 0s - loss: 0.5129 - acc: 0.7696Epoch 00017: val_loss improved from 0.49191 to 0.48476, saving model to ../output/titanic.model.best.hdf5\n",
      "668/668 [==============================] - 0s - loss: 0.5027 - acc: 0.7754 - val_loss: 0.4848 - val_acc: 0.7803\n",
      "Epoch 19/1000\n",
      "540/668 [=======================>......] - ETA: 0s - loss: 0.4878 - acc: 0.7796- ETA: 0s - loss: 0.4774 - acc: 0.81 - ETA: 0s - loss: 0.4969 - acc: 0.782Epoch 00018: val_loss improved from 0.48476 to 0.48226, saving model to ../output/titanic.model.best.hdf5\n",
      "668/668 [==============================] - 0s - loss: 0.5039 - acc: 0.7650 - val_loss: 0.4823 - val_acc: 0.7713\n",
      "Epoch 20/1000\n",
      "660/668 [============================>.] - ETA: 0s - loss: 0.4998 - acc: 0.7788Epoch 00019: val_loss improved from 0.48226 to 0.47555, saving model to ../output/titanic.model.best.hdf5\n",
      "668/668 [==============================] - 0s - loss: 0.4976 - acc: 0.7814 - val_loss: 0.4755 - val_acc: 0.7803\n",
      "Epoch 21/1000\n",
      "620/668 [==========================>...] - ETA: 0s - loss: 0.5039 - acc: 0.7790Epoch 00020: val_loss improved from 0.47555 to 0.47047, saving model to ../output/titanic.model.best.hdf5\n",
      "668/668 [==============================] - 0s - loss: 0.4979 - acc: 0.7829 - val_loss: 0.4705 - val_acc: 0.7848\n",
      "Epoch 22/1000\n",
      "560/668 [========================>.....] - ETA: 0s - loss: 0.5123 - acc: 0.7482Epoch 00021: val_loss improved from 0.47047 to 0.46645, saving model to ../output/titanic.model.best.hdf5\n",
      "668/668 [==============================] - 0s - loss: 0.4980 - acc: 0.7605 - val_loss: 0.4664 - val_acc: 0.7848\n",
      "Epoch 23/1000\n",
      "660/668 [============================>.] - ETA: 0s - loss: 0.4846 - acc: 0.7864Epoch 00022: val_loss improved from 0.46645 to 0.46273, saving model to ../output/titanic.model.best.hdf5\n",
      "668/668 [==============================] - 0s - loss: 0.4861 - acc: 0.7859 - val_loss: 0.4627 - val_acc: 0.7937\n",
      "Epoch 24/1000\n",
      "660/668 [============================>.] - ETA: 0s - loss: 0.4805 - acc: 0.7833Epoch 00023: val_loss improved from 0.46273 to 0.45886, saving model to ../output/titanic.model.best.hdf5\n",
      "668/668 [==============================] - 0s - loss: 0.4818 - acc: 0.7814 - val_loss: 0.4589 - val_acc: 0.7937\n",
      "Epoch 25/1000\n",
      "600/668 [=========================>....] - ETA: 0s - loss: 0.4853 - acc: 0.7867Epoch 00024: val_loss improved from 0.45886 to 0.45876, saving model to ../output/titanic.model.best.hdf5\n",
      "668/668 [==============================] - 0s - loss: 0.4841 - acc: 0.7844 - val_loss: 0.4588 - val_acc: 0.7937\n",
      "Epoch 26/1000\n",
      "660/668 [============================>.] - ETA: 0s - loss: 0.4791 - acc: 0.7833Epoch 00025: val_loss improved from 0.45876 to 0.45267, saving model to ../output/titanic.model.best.hdf5\n",
      "668/668 [==============================] - 0s - loss: 0.4815 - acc: 0.7829 - val_loss: 0.4527 - val_acc: 0.8027\n",
      "Epoch 27/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "580/668 [=========================>....] - ETA: 0s - loss: 0.4723 - acc: 0.7810Epoch 00026: val_loss improved from 0.45267 to 0.44881, saving model to ../output/titanic.model.best.hdf5\n",
      "668/668 [==============================] - 0s - loss: 0.4694 - acc: 0.7799 - val_loss: 0.4488 - val_acc: 0.7937\n",
      "Epoch 28/1000\n",
      "560/668 [========================>.....] - ETA: 0s - loss: 0.4774 - acc: 0.7964Epoch 00027: val_loss improved from 0.44881 to 0.44638, saving model to ../output/titanic.model.best.hdf5\n",
      "668/668 [==============================] - 0s - loss: 0.4679 - acc: 0.8024 - val_loss: 0.4464 - val_acc: 0.7982\n",
      "Epoch 29/1000\n",
      "600/668 [=========================>....] - ETA: 0s - loss: 0.4803 - acc: 0.7800Epoch 00028: val_loss improved from 0.44638 to 0.44385, saving model to ../output/titanic.model.best.hdf5\n",
      "668/668 [==============================] - 0s - loss: 0.4790 - acc: 0.7814 - val_loss: 0.4438 - val_acc: 0.7982\n",
      "Epoch 30/1000\n",
      "540/668 [=======================>......] - ETA: 0s - loss: 0.4657 - acc: 0.8019Epoch 00029: val_loss improved from 0.44385 to 0.44196, saving model to ../output/titanic.model.best.hdf5\n",
      "668/668 [==============================] - 0s - loss: 0.4615 - acc: 0.7979 - val_loss: 0.4420 - val_acc: 0.8027\n",
      "Epoch 31/1000\n",
      "520/668 [======================>.......] - ETA: 0s - loss: 0.4525 - acc: 0.7846Epoch 00030: val_loss did not improve\n",
      "668/668 [==============================] - 0s - loss: 0.4594 - acc: 0.7814 - val_loss: 0.4502 - val_acc: 0.7982\n",
      "Epoch 32/1000\n",
      "540/668 [=======================>......] - ETA: 0s - loss: 0.4594 - acc: 0.8037Epoch 00031: val_loss improved from 0.44196 to 0.43858, saving model to ../output/titanic.model.best.hdf5\n",
      "668/668 [==============================] - 0s - loss: 0.4621 - acc: 0.7994 - val_loss: 0.4386 - val_acc: 0.8072\n",
      "Epoch 33/1000\n",
      "520/668 [======================>.......] - ETA: 0s - loss: 0.4866 - acc: 0.7808Epoch 00032: val_loss improved from 0.43858 to 0.43819, saving model to ../output/titanic.model.best.hdf5\n",
      "668/668 [==============================] - 0s - loss: 0.4692 - acc: 0.7904 - val_loss: 0.4382 - val_acc: 0.8072\n",
      "Epoch 34/1000\n",
      "500/668 [=====================>........] - ETA: 0s - loss: 0.4642 - acc: 0.7860Epoch 00033: val_loss improved from 0.43819 to 0.43495, saving model to ../output/titanic.model.best.hdf5\n",
      "668/668 [==============================] - 0s - loss: 0.4526 - acc: 0.7934 - val_loss: 0.4350 - val_acc: 0.8027\n",
      "Epoch 35/1000\n",
      "500/668 [=====================>........] - ETA: 0s - loss: 0.4390 - acc: 0.7960Epoch 00034: val_loss improved from 0.43495 to 0.43473, saving model to ../output/titanic.model.best.hdf5\n",
      "668/668 [==============================] - 0s - loss: 0.4537 - acc: 0.7859 - val_loss: 0.4347 - val_acc: 0.8072\n",
      "Epoch 36/1000\n",
      "660/668 [============================>.] - ETA: 0s - loss: 0.4516 - acc: 0.8015Epoch 00035: val_loss improved from 0.43473 to 0.43394, saving model to ../output/titanic.model.best.hdf5\n",
      "668/668 [==============================] - 0s - loss: 0.4485 - acc: 0.8039 - val_loss: 0.4339 - val_acc: 0.8072\n",
      "Epoch 37/1000\n",
      "660/668 [============================>.] - ETA: 0s - loss: 0.4585 - acc: 0.7939Epoch 00036: val_loss did not improve\n",
      "668/668 [==============================] - 0s - loss: 0.4616 - acc: 0.7919 - val_loss: 0.4373 - val_acc: 0.8117\n",
      "Epoch 38/1000\n",
      "500/668 [=====================>........] - ETA: 0s - loss: 0.4352 - acc: 0.8180Epoch 00037: val_loss improved from 0.43394 to 0.43309, saving model to ../output/titanic.model.best.hdf5\n",
      "668/668 [==============================] - 0s - loss: 0.4397 - acc: 0.8084 - val_loss: 0.4331 - val_acc: 0.8072\n",
      "Epoch 39/1000\n",
      "540/668 [=======================>......] - ETA: 0s - loss: 0.4443 - acc: 0.8037Epoch 00038: val_loss did not improve\n",
      "668/668 [==============================] - 0s - loss: 0.4451 - acc: 0.8039 - val_loss: 0.4342 - val_acc: 0.8117\n",
      "Epoch 40/1000\n",
      "540/668 [=======================>......] - ETA: 0s - loss: 0.4273 - acc: 0.8130Epoch 00039: val_loss improved from 0.43309 to 0.42819, saving model to ../output/titanic.model.best.hdf5\n",
      "668/668 [==============================] - 0s - loss: 0.4514 - acc: 0.8024 - val_loss: 0.4282 - val_acc: 0.8027\n",
      "Epoch 41/1000\n",
      "640/668 [===========================>..] - ETA: 0s - loss: 0.4382 - acc: 0.8031Epoch 00040: val_loss did not improve\n",
      "668/668 [==============================] - 0s - loss: 0.4344 - acc: 0.8039 - val_loss: 0.4359 - val_acc: 0.8161\n",
      "Epoch 42/1000\n",
      "520/668 [======================>.......] - ETA: 0s - loss: 0.4627 - acc: 0.7923Epoch 00041: val_loss improved from 0.42819 to 0.42729, saving model to ../output/titanic.model.best.hdf5\n",
      "668/668 [==============================] - 0s - loss: 0.4456 - acc: 0.8009 - val_loss: 0.4273 - val_acc: 0.8117\n",
      "Epoch 43/1000\n",
      "660/668 [============================>.] - ETA: 0s - loss: 0.4325 - acc: 0.8182Epoch 00042: val_loss did not improve\n",
      "668/668 [==============================] - 0s - loss: 0.4353 - acc: 0.8174 - val_loss: 0.4307 - val_acc: 0.8117\n",
      "Epoch 44/1000\n",
      "600/668 [=========================>....] - ETA: 0s - loss: 0.4448 - acc: 0.8117Epoch 00043: val_loss improved from 0.42729 to 0.42571, saving model to ../output/titanic.model.best.hdf5\n",
      "668/668 [==============================] - 0s - loss: 0.4383 - acc: 0.8144 - val_loss: 0.4257 - val_acc: 0.8117\n",
      "Epoch 45/1000\n",
      "640/668 [===========================>..] - ETA: 0s - loss: 0.4228 - acc: 0.8125Epoch 00044: val_loss did not improve\n",
      "668/668 [==============================] - 0s - loss: 0.4245 - acc: 0.8129 - val_loss: 0.4263 - val_acc: 0.8117\n",
      "Epoch 46/1000\n",
      "640/668 [===========================>..] - ETA: 0s - loss: 0.4462 - acc: 0.7953Epoch 00045: val_loss did not improve\n",
      "668/668 [==============================] - 0s - loss: 0.4395 - acc: 0.7994 - val_loss: 0.4269 - val_acc: 0.8117\n",
      "Epoch 47/1000\n",
      "600/668 [=========================>....] - ETA: 0s - loss: 0.4437 - acc: 0.8167Epoch 00046: val_loss improved from 0.42571 to 0.42357, saving model to ../output/titanic.model.best.hdf5\n",
      "668/668 [==============================] - 0s - loss: 0.4414 - acc: 0.8159 - val_loss: 0.4236 - val_acc: 0.8117\n",
      "Epoch 48/1000\n",
      "660/668 [============================>.] - ETA: 0s - loss: 0.4375 - acc: 0.8106Epoch 00047: val_loss improved from 0.42357 to 0.42269, saving model to ../output/titanic.model.best.hdf5\n",
      "668/668 [==============================] - 0s - loss: 0.4390 - acc: 0.8084 - val_loss: 0.4227 - val_acc: 0.8117\n",
      "Epoch 49/1000\n",
      "580/668 [=========================>....] - ETA: 0s - loss: 0.4333 - acc: 0.8155Epoch 00048: val_loss did not improve\n",
      "668/668 [==============================] - 0s - loss: 0.4311 - acc: 0.8129 - val_loss: 0.4289 - val_acc: 0.7937\n",
      "Epoch 50/1000\n",
      "520/668 [======================>.......] - ETA: 0s - loss: 0.4216 - acc: 0.8154Epoch 00049: val_loss improved from 0.42269 to 0.42191, saving model to ../output/titanic.model.best.hdf5\n",
      "668/668 [==============================] - 0s - loss: 0.4387 - acc: 0.8054 - val_loss: 0.4219 - val_acc: 0.8117\n",
      "Epoch 51/1000\n",
      "660/668 [============================>.] - ETA: 0s - loss: 0.4387 - acc: 0.8061Epoch 00050: val_loss did not improve\n",
      "668/668 [==============================] - 0s - loss: 0.4367 - acc: 0.8084 - val_loss: 0.4271 - val_acc: 0.8027\n",
      "Epoch 52/1000\n",
      "620/668 [==========================>...] - ETA: 0s - loss: 0.4325 - acc: 0.8177Epoch 00051: val_loss did not improve\n",
      "668/668 [==============================] - 0s - loss: 0.4319 - acc: 0.8144 - val_loss: 0.4312 - val_acc: 0.8206\n",
      "Epoch 53/1000\n",
      "660/668 [============================>.] - ETA: 0s - loss: 0.4423 - acc: 0.7970Epoch 00052: val_loss did not improve\n",
      "668/668 [==============================] - 0s - loss: 0.4399 - acc: 0.7994 - val_loss: 0.4225 - val_acc: 0.8161\n",
      "Epoch 54/1000\n",
      "600/668 [=========================>....] - ETA: 0s - loss: 0.4287 - acc: 0.8283Epoch 00053: val_loss did not improve\n",
      "668/668 [==============================] - 0s - loss: 0.4327 - acc: 0.8219 - val_loss: 0.4232 - val_acc: 0.8161\n",
      "Epoch 55/1000\n",
      "520/668 [======================>.......] - ETA: 0s - loss: 0.4387 - acc: 0.8192Epoch 00054: val_loss improved from 0.42191 to 0.42175, saving model to ../output/titanic.model.best.hdf5\n",
      "668/668 [==============================] - 0s - loss: 0.4342 - acc: 0.8174 - val_loss: 0.4218 - val_acc: 0.8117\n",
      "Epoch 56/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/668 [=========================>....] - ETA: 0s - loss: 0.4367 - acc: 0.8100Epoch 00055: val_loss improved from 0.42175 to 0.42110, saving model to ../output/titanic.model.best.hdf5\n",
      "668/668 [==============================] - 0s - loss: 0.4318 - acc: 0.8159 - val_loss: 0.4211 - val_acc: 0.8117\n",
      "Epoch 57/1000\n",
      "500/668 [=====================>........] - ETA: 0s - loss: 0.4017 - acc: 0.8200Epoch 00056: val_loss improved from 0.42110 to 0.41989, saving model to ../output/titanic.model.best.hdf5\n",
      "668/668 [==============================] - 0s - loss: 0.4183 - acc: 0.8129 - val_loss: 0.4199 - val_acc: 0.8117\n",
      "Epoch 58/1000\n",
      "540/668 [=======================>......] - ETA: 0s - loss: 0.4216 - acc: 0.8167Epoch 00057: val_loss did not improve\n",
      "668/668 [==============================] - 0s - loss: 0.4170 - acc: 0.8234 - val_loss: 0.4291 - val_acc: 0.8027\n",
      "Epoch 59/1000\n",
      "520/668 [======================>.......] - ETA: 0s - loss: 0.4111 - acc: 0.8250Epoch 00058: val_loss improved from 0.41989 to 0.41938, saving model to ../output/titanic.model.best.hdf5\n",
      "668/668 [==============================] - 0s - loss: 0.4236 - acc: 0.8174 - val_loss: 0.4194 - val_acc: 0.8117\n",
      "Epoch 60/1000\n",
      "520/668 [======================>.......] - ETA: 0s - loss: 0.4107 - acc: 0.8269Epoch 00059: val_loss did not improve\n",
      "668/668 [==============================] - 0s - loss: 0.4181 - acc: 0.8189 - val_loss: 0.4198 - val_acc: 0.8161\n",
      "Epoch 61/1000\n",
      "660/668 [============================>.] - ETA: 0s - loss: 0.4361 - acc: 0.8152Epoch 00060: val_loss did not improve\n",
      "668/668 [==============================] - 0s - loss: 0.4346 - acc: 0.8159 - val_loss: 0.4243 - val_acc: 0.8072\n",
      "Epoch 62/1000\n",
      "520/668 [======================>.......] - ETA: 0s - loss: 0.4070 - acc: 0.8231Epoch 00061: val_loss did not improve\n",
      "668/668 [==============================] - 0s - loss: 0.4260 - acc: 0.8099 - val_loss: 0.4205 - val_acc: 0.8161\n",
      "Epoch 63/1000\n",
      "500/668 [=====================>........] - ETA: 0s - loss: 0.4284 - acc: 0.7960Epoch 00062: val_loss improved from 0.41938 to 0.41820, saving model to ../output/titanic.model.best.hdf5\n",
      "668/668 [==============================] - 0s - loss: 0.4105 - acc: 0.8114 - val_loss: 0.4182 - val_acc: 0.8072\n",
      "Epoch 64/1000\n",
      "520/668 [======================>.......] - ETA: 0s - loss: 0.3956 - acc: 0.8269Epoch 00063: val_loss improved from 0.41820 to 0.41777, saving model to ../output/titanic.model.best.hdf5\n",
      "668/668 [==============================] - 0s - loss: 0.4182 - acc: 0.8144 - val_loss: 0.4178 - val_acc: 0.8161\n",
      "Epoch 65/1000\n",
      "520/668 [======================>.......] - ETA: 0s - loss: 0.3839 - acc: 0.8288Epoch 00064: val_loss improved from 0.41777 to 0.41672, saving model to ../output/titanic.model.best.hdf5\n",
      "668/668 [==============================] - 0s - loss: 0.4100 - acc: 0.8144 - val_loss: 0.4167 - val_acc: 0.8072\n",
      "Epoch 66/1000\n",
      "580/668 [=========================>....] - ETA: 0s - loss: 0.4093 - acc: 0.8207Epoch 00065: val_loss improved from 0.41672 to 0.41649, saving model to ../output/titanic.model.best.hdf5\n",
      "668/668 [==============================] - 0s - loss: 0.4072 - acc: 0.8234 - val_loss: 0.4165 - val_acc: 0.8117\n",
      "Epoch 67/1000\n",
      "660/668 [============================>.] - ETA: 0s - loss: 0.4138 - acc: 0.8152Epoch 00066: val_loss did not improve\n",
      "668/668 [==============================] - 0s - loss: 0.4134 - acc: 0.8144 - val_loss: 0.4227 - val_acc: 0.8206\n",
      "Epoch 68/1000\n",
      "640/668 [===========================>..] - ETA: 0s - loss: 0.4192 - acc: 0.8203Epoch 00067: val_loss did not improve\n",
      "668/668 [==============================] - 0s - loss: 0.4159 - acc: 0.8219 - val_loss: 0.4245 - val_acc: 0.8072\n",
      "Epoch 69/1000\n",
      "520/668 [======================>.......] - ETA: 0s - loss: 0.3864 - acc: 0.8308Epoch 00068: val_loss did not improve\n",
      "668/668 [==============================] - 0s - loss: 0.4045 - acc: 0.8204 - val_loss: 0.4187 - val_acc: 0.8117\n",
      "Epoch 70/1000\n",
      "520/668 [======================>.......] - ETA: 0s - loss: 0.4112 - acc: 0.8192Epoch 00069: val_loss did not improve\n",
      "668/668 [==============================] - 0s - loss: 0.4042 - acc: 0.8263 - val_loss: 0.4198 - val_acc: 0.8161\n",
      "Epoch 71/1000\n",
      "600/668 [=========================>....] - ETA: 0s - loss: 0.4103 - acc: 0.8217Epoch 00070: val_loss did not improve\n",
      "668/668 [==============================] - 0s - loss: 0.4131 - acc: 0.8234 - val_loss: 0.4177 - val_acc: 0.8117\n",
      "Epoch 72/1000\n",
      "540/668 [=======================>......] - ETA: 0s - loss: 0.4171 - acc: 0.8130Epoch 00071: val_loss improved from 0.41649 to 0.41555, saving model to ../output/titanic.model.best.hdf5\n",
      "668/668 [==============================] - 0s - loss: 0.4161 - acc: 0.8084 - val_loss: 0.4156 - val_acc: 0.8117\n",
      "Epoch 73/1000\n",
      "640/668 [===========================>..] - ETA: 0s - loss: 0.4030 - acc: 0.8313Epoch 00072: val_loss did not improve\n",
      "668/668 [==============================] - 0s - loss: 0.4052 - acc: 0.8323 - val_loss: 0.4158 - val_acc: 0.8117\n",
      "Epoch 74/1000\n",
      "580/668 [=========================>....] - ETA: 0s - loss: 0.4076 - acc: 0.8207Epoch 00073: val_loss improved from 0.41555 to 0.41531, saving model to ../output/titanic.model.best.hdf5\n",
      "668/668 [==============================] - 0s - loss: 0.4113 - acc: 0.8159 - val_loss: 0.4153 - val_acc: 0.8161\n",
      "Epoch 75/1000\n",
      "580/668 [=========================>....] - ETA: 0s - loss: 0.4058 - acc: 0.8069Epoch 00074: val_loss did not improve\n",
      "668/668 [==============================] - 0s - loss: 0.4052 - acc: 0.8144 - val_loss: 0.4169 - val_acc: 0.8117\n",
      "Epoch 76/1000\n",
      "500/668 [=====================>........] - ETA: 0s - loss: 0.4053 - acc: 0.8300Epoch 00075: val_loss improved from 0.41531 to 0.41399, saving model to ../output/titanic.model.best.hdf5\n",
      "668/668 [==============================] - 0s - loss: 0.4072 - acc: 0.8278 - val_loss: 0.4140 - val_acc: 0.8206\n",
      "Epoch 77/1000\n",
      "540/668 [=======================>......] - ETA: 0s - loss: 0.4095 - acc: 0.8000Epoch 00076: val_loss did not improve\n",
      "668/668 [==============================] - 0s - loss: 0.4075 - acc: 0.8054 - val_loss: 0.4158 - val_acc: 0.8117\n",
      "Epoch 78/1000\n",
      "660/668 [============================>.] - ETA: 0s - loss: 0.4065 - acc: 0.8227Epoch 00077: val_loss did not improve\n",
      "668/668 [==============================] - 0s - loss: 0.4070 - acc: 0.8204 - val_loss: 0.4207 - val_acc: 0.8161\n",
      "Epoch 79/1000\n",
      "600/668 [=========================>....] - ETA: 0s - loss: 0.3930 - acc: 0.8317Epoch 00078: val_loss did not improve\n",
      "668/668 [==============================] - 0s - loss: 0.4073 - acc: 0.8204 - val_loss: 0.4145 - val_acc: 0.8206\n",
      "Epoch 80/1000\n",
      "580/668 [=========================>....] - ETA: 0s - loss: 0.4056 - acc: 0.8241Epoch 00079: val_loss did not improve\n",
      "668/668 [==============================] - 0s - loss: 0.3956 - acc: 0.8308 - val_loss: 0.4244 - val_acc: 0.8117\n",
      "Epoch 81/1000\n",
      "560/668 [========================>.....] - ETA: 0s - loss: 0.3955 - acc: 0.8393Epoch 00080: val_loss improved from 0.41399 to 0.41377, saving model to ../output/titanic.model.best.hdf5\n",
      "668/668 [==============================] - 0s - loss: 0.3989 - acc: 0.8353 - val_loss: 0.4138 - val_acc: 0.8117\n",
      "Epoch 82/1000\n",
      "580/668 [=========================>....] - ETA: 0s - loss: 0.3976 - acc: 0.8293Epoch 00081: val_loss did not improve\n",
      "668/668 [==============================] - 0s - loss: 0.4025 - acc: 0.8293 - val_loss: 0.4140 - val_acc: 0.8206\n",
      "Epoch 83/1000\n",
      "580/668 [=========================>....] - ETA: 0s - loss: 0.3921 - acc: 0.8224Epoch 00082: val_loss did not improve\n",
      "668/668 [==============================] - 0s - loss: 0.3993 - acc: 0.8204 - val_loss: 0.4177 - val_acc: 0.8161\n",
      "Epoch 84/1000\n",
      "620/668 [==========================>...] - ETA: 0s - loss: 0.3911 - acc: 0.8226Epoch 00083: val_loss improved from 0.41377 to 0.41328, saving model to ../output/titanic.model.best.hdf5\n",
      "668/668 [==============================] - 0s - loss: 0.3928 - acc: 0.8234 - val_loss: 0.4133 - val_acc: 0.8161\n",
      "Epoch 85/1000\n",
      "640/668 [===========================>..] - ETA: 0s - loss: 0.4006 - acc: 0.8203Epoch 00084: val_loss did not improve\n",
      "668/668 [==============================] - 0s - loss: 0.3981 - acc: 0.8234 - val_loss: 0.4171 - val_acc: 0.8206\n",
      "Epoch 86/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640/668 [===========================>..] - ETA: 0s - loss: 0.3940 - acc: 0.8391Epoch 00085: val_loss did not improve\n",
      "668/668 [==============================] - 0s - loss: 0.4024 - acc: 0.8383 - val_loss: 0.4146 - val_acc: 0.8206\n",
      "Epoch 87/1000\n",
      "500/668 [=====================>........] - ETA: 0s - loss: 0.4110 - acc: 0.8160Epoch 00086: val_loss improved from 0.41328 to 0.41305, saving model to ../output/titanic.model.best.hdf5\n",
      "668/668 [==============================] - 0s - loss: 0.3955 - acc: 0.8249 - val_loss: 0.4131 - val_acc: 0.8206\n",
      "Epoch 88/1000\n",
      "500/668 [=====================>........] - ETA: 0s - loss: 0.3734 - acc: 0.8340Epoch 00087: val_loss improved from 0.41305 to 0.41258, saving model to ../output/titanic.model.best.hdf5\n",
      "668/668 [==============================] - 0s - loss: 0.3839 - acc: 0.8323 - val_loss: 0.4126 - val_acc: 0.8161\n",
      "Epoch 89/1000\n",
      "540/668 [=======================>......] - ETA: 0s - loss: 0.3963 - acc: 0.8389Epoch 00088: val_loss did not improve\n",
      "668/668 [==============================] - 0s - loss: 0.3903 - acc: 0.8413 - val_loss: 0.4139 - val_acc: 0.8251\n",
      "Epoch 90/1000\n",
      "660/668 [============================>.] - ETA: 0s - loss: 0.3909 - acc: 0.8288Epoch 00089: val_loss did not improve\n",
      "668/668 [==============================] - 0s - loss: 0.3972 - acc: 0.8263 - val_loss: 0.4376 - val_acc: 0.8027\n",
      "Epoch 91/1000\n",
      "520/668 [======================>.......] - ETA: 0s - loss: 0.4045 - acc: 0.8250Epoch 00090: val_loss did not improve\n",
      "668/668 [==============================] - 0s - loss: 0.4008 - acc: 0.8234 - val_loss: 0.4197 - val_acc: 0.8206\n",
      "Epoch 92/1000\n",
      "560/668 [========================>.....] - ETA: 0s - loss: 0.3750 - acc: 0.8536Epoch 00091: val_loss did not improve\n",
      "668/668 [==============================] - 0s - loss: 0.3907 - acc: 0.8443 - val_loss: 0.4167 - val_acc: 0.8251\n",
      "Epoch 93/1000\n",
      "500/668 [=====================>........] - ETA: 0s - loss: 0.3607 - acc: 0.8620Epoch 00092: val_loss did not improve\n",
      "668/668 [==============================] - 0s - loss: 0.3872 - acc: 0.8503 - val_loss: 0.4136 - val_acc: 0.8117\n",
      "Epoch 94/1000\n",
      "540/668 [=======================>......] - ETA: 0s - loss: 0.3944 - acc: 0.8426Epoch 00093: val_loss did not improve\n",
      "668/668 [==============================] - 0s - loss: 0.3912 - acc: 0.8383 - val_loss: 0.4131 - val_acc: 0.8117\n",
      "Epoch 95/1000\n",
      "500/668 [=====================>........] - ETA: 0s - loss: 0.3849 - acc: 0.8220Epoch 00094: val_loss did not improve\n",
      "668/668 [==============================] - 0s - loss: 0.3900 - acc: 0.8234 - val_loss: 0.4136 - val_acc: 0.8161\n",
      "Epoch 96/1000\n",
      "500/668 [=====================>........] - ETA: 0s - loss: 0.3707 - acc: 0.8360Epoch 00095: val_loss did not improve\n",
      "668/668 [==============================] - 0s - loss: 0.3751 - acc: 0.8368 - val_loss: 0.4219 - val_acc: 0.8161\n",
      "Epoch 97/1000\n",
      "500/668 [=====================>........] - ETA: 0s - loss: 0.4039 - acc: 0.8180Epoch 00096: val_loss did not improve\n",
      "668/668 [==============================] - 0s - loss: 0.3882 - acc: 0.8323 - val_loss: 0.4147 - val_acc: 0.8251\n",
      "Epoch 98/1000\n",
      "520/668 [======================>.......] - ETA: 0s - loss: 0.4071 - acc: 0.8250Epoch 00097: val_loss did not improve\n",
      "668/668 [==============================] - 0s - loss: 0.3862 - acc: 0.8398 - val_loss: 0.4151 - val_acc: 0.8251\n",
      "Epoch 99/1000\n",
      "660/668 [============================>.] - ETA: 0s - loss: 0.3849 - acc: 0.8348Epoch 00098: val_loss did not improve\n",
      "668/668 [==============================] - 0s - loss: 0.3835 - acc: 0.8353 - val_loss: 0.4162 - val_acc: 0.8251\n",
      "Epoch 100/1000\n",
      "580/668 [=========================>....] - ETA: 0s - loss: 0.3657 - acc: 0.8328Epoch 00099: val_loss did not improve\n",
      "668/668 [==============================] - 0s - loss: 0.3837 - acc: 0.8234 - val_loss: 0.4141 - val_acc: 0.8206\n",
      "Epoch 101/1000\n",
      "660/668 [============================>.] - ETA: 0s - loss: 0.3766 - acc: 0.8242Epoch 00100: val_loss did not improve\n",
      "668/668 [==============================] - 0s - loss: 0.3748 - acc: 0.8249 - val_loss: 0.4189 - val_acc: 0.8206\n",
      "Epoch 102/1000\n",
      "660/668 [============================>.] - ETA: 0s - loss: 0.3882 - acc: 0.8455Epoch 00101: val_loss improved from 0.41258 to 0.41161, saving model to ../output/titanic.model.best.hdf5\n",
      "668/668 [==============================] - 0s - loss: 0.3874 - acc: 0.8458 - val_loss: 0.4116 - val_acc: 0.8251\n",
      "Epoch 103/1000\n",
      "660/668 [============================>.] - ETA: 0s - loss: 0.3852 - acc: 0.8409Epoch 00102: val_loss did not improve\n",
      "668/668 [==============================] - 0s - loss: 0.3833 - acc: 0.8428 - val_loss: 0.4118 - val_acc: 0.8117\n",
      "Epoch 104/1000\n",
      "560/668 [========================>.....] - ETA: 0s - loss: 0.3817 - acc: 0.8375Epoch 00103: val_loss improved from 0.41161 to 0.41147, saving model to ../output/titanic.model.best.hdf5\n",
      "668/668 [==============================] - 0s - loss: 0.3847 - acc: 0.8353 - val_loss: 0.4115 - val_acc: 0.8251\n",
      "Epoch 105/1000\n",
      "620/668 [==========================>...] - ETA: 0s - loss: 0.3851 - acc: 0.8387Epoch 00104: val_loss did not improve\n",
      "668/668 [==============================] - 0s - loss: 0.3770 - acc: 0.8443 - val_loss: 0.4173 - val_acc: 0.8251\n",
      "Epoch 106/1000\n",
      "640/668 [===========================>..] - ETA: 0s - loss: 0.3733 - acc: 0.8469Epoch 00105: val_loss did not improve\n",
      "668/668 [==============================] - 0s - loss: 0.3770 - acc: 0.8458 - val_loss: 0.4252 - val_acc: 0.8072\n",
      "Epoch 107/1000\n",
      "660/668 [============================>.] - ETA: 0s - loss: 0.3774 - acc: 0.8439Epoch 00106: val_loss did not improve\n",
      "668/668 [==============================] - 0s - loss: 0.3745 - acc: 0.8458 - val_loss: 0.4128 - val_acc: 0.8251\n",
      "Epoch 108/1000\n",
      "540/668 [=======================>......] - ETA: 0s - loss: 0.3536 - acc: 0.8593Epoch 00107: val_loss improved from 0.41147 to 0.41100, saving model to ../output/titanic.model.best.hdf5\n",
      "668/668 [==============================] - 0s - loss: 0.3674 - acc: 0.8488 - val_loss: 0.4110 - val_acc: 0.8206\n",
      "Epoch 109/1000\n",
      "580/668 [=========================>....] - ETA: 0s - loss: 0.3730 - acc: 0.8483Epoch 00108: val_loss did not improve\n",
      "668/668 [==============================] - 0s - loss: 0.3728 - acc: 0.8473 - val_loss: 0.4120 - val_acc: 0.8206\n",
      "Epoch 110/1000\n",
      "620/668 [==========================>...] - ETA: 0s - loss: 0.3810 - acc: 0.8419Epoch 00109: val_loss did not improve\n",
      "668/668 [==============================] - 0s - loss: 0.3753 - acc: 0.8443 - val_loss: 0.4146 - val_acc: 0.8251\n",
      "Epoch 111/1000\n",
      "660/668 [============================>.] - ETA: 0s - loss: 0.3667 - acc: 0.8515Epoch 00110: val_loss improved from 0.41100 to 0.41006, saving model to ../output/titanic.model.best.hdf5\n",
      "668/668 [==============================] - 0s - loss: 0.3648 - acc: 0.8533 - val_loss: 0.4101 - val_acc: 0.8251\n",
      "Epoch 112/1000\n",
      "660/668 [============================>.] - ETA: 0s - loss: 0.3713 - acc: 0.8348Epoch 00111: val_loss did not improve\n",
      "668/668 [==============================] - 0s - loss: 0.3684 - acc: 0.8368 - val_loss: 0.4110 - val_acc: 0.8161\n",
      "Epoch 113/1000\n",
      "520/668 [======================>.......] - ETA: 0s - loss: 0.3686 - acc: 0.8327Epoch 00112: val_loss improved from 0.41006 to 0.41004, saving model to ../output/titanic.model.best.hdf5\n",
      "668/668 [==============================] - 0s - loss: 0.3708 - acc: 0.8353 - val_loss: 0.4100 - val_acc: 0.8251\n",
      "Epoch 114/1000\n",
      "660/668 [============================>.] - ETA: 0s - loss: 0.3672 - acc: 0.8515Epoch 00113: val_loss did not improve\n",
      "668/668 [==============================] - 0s - loss: 0.3655 - acc: 0.8518 - val_loss: 0.4145 - val_acc: 0.8206\n",
      "Epoch 115/1000\n",
      "560/668 [========================>.....] - ETA: 0s - loss: 0.3544 - acc: 0.8571Epoch 00114: val_loss did not improve\n",
      "668/668 [==============================] - 0s - loss: 0.3598 - acc: 0.8518 - val_loss: 0.4153 - val_acc: 0.8206\n",
      "Epoch 116/1000\n",
      "560/668 [========================>.....] - ETA: 0s - loss: 0.3890 - acc: 0.8375Epoch 00115: val_loss did not improve\n",
      "668/668 [==============================] - 0s - loss: 0.3732 - acc: 0.8518 - val_loss: 0.4116 - val_acc: 0.8206\n",
      "Epoch 117/1000\n",
      "580/668 [=========================>....] - ETA: 0s - loss: 0.3660 - acc: 0.8379Epoch 00116: val_loss did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "668/668 [==============================] - 0s - loss: 0.3575 - acc: 0.8413 - val_loss: 0.4278 - val_acc: 0.8161\n",
      "Epoch 118/1000\n",
      "620/668 [==========================>...] - ETA: 0s - loss: 0.3476 - acc: 0.8532Epoch 00117: val_loss did not improve\n",
      "668/668 [==============================] - 0s - loss: 0.3622 - acc: 0.8443 - val_loss: 0.4221 - val_acc: 0.8161\n",
      "Epoch 119/1000\n",
      "500/668 [=====================>........] - ETA: 0s - loss: 0.3689 - acc: 0.8340Epoch 00118: val_loss did not improve\n",
      "668/668 [==============================] - 0s - loss: 0.3641 - acc: 0.8338 - val_loss: 0.4235 - val_acc: 0.8161\n",
      "Epoch 120/1000\n",
      "500/668 [=====================>........] - ETA: 0s - loss: 0.3648 - acc: 0.8720Epoch 00119: val_loss did not improve\n",
      "668/668 [==============================] - 0s - loss: 0.3616 - acc: 0.8593 - val_loss: 0.4107 - val_acc: 0.8206\n",
      "Epoch 121/1000\n",
      "520/668 [======================>.......] - ETA: 0s - loss: 0.3652 - acc: 0.8538Epoch 00120: val_loss improved from 0.41004 to 0.40941, saving model to ../output/titanic.model.best.hdf5\n",
      "668/668 [==============================] - 0s - loss: 0.3659 - acc: 0.8503 - val_loss: 0.4094 - val_acc: 0.8251\n",
      "Epoch 122/1000\n",
      "580/668 [=========================>....] - ETA: 0s - loss: 0.3499 - acc: 0.8621Epoch 00121: val_loss did not improve\n",
      "668/668 [==============================] - 0s - loss: 0.3559 - acc: 0.8608 - val_loss: 0.4115 - val_acc: 0.8206\n",
      "Epoch 123/1000\n",
      "580/668 [=========================>....] - ETA: 0s - loss: 0.3627 - acc: 0.8431Epoch 00122: val_loss did not improve\n",
      "668/668 [==============================] - 0s - loss: 0.3593 - acc: 0.8488 - val_loss: 0.4137 - val_acc: 0.8161\n",
      "Epoch 124/1000\n",
      "600/668 [=========================>....] - ETA: 0s - loss: 0.3513 - acc: 0.8617Epoch 00123: val_loss did not improve\n",
      "668/668 [==============================] - 0s - loss: 0.3496 - acc: 0.8623 - val_loss: 0.4154 - val_acc: 0.8161\n",
      "Epoch 125/1000\n",
      "600/668 [=========================>....] - ETA: 0s - loss: 0.3588 - acc: 0.8517Epoch 00124: val_loss did not improve\n",
      "668/668 [==============================] - 0s - loss: 0.3537 - acc: 0.8563 - val_loss: 0.4112 - val_acc: 0.8206\n",
      "Epoch 126/1000\n",
      "500/668 [=====================>........] - ETA: 0s - loss: 0.3632 - acc: 0.8340Epoch 00125: val_loss did not improve\n",
      "668/668 [==============================] - 0s - loss: 0.3671 - acc: 0.8383 - val_loss: 0.4103 - val_acc: 0.8251\n",
      "Epoch 127/1000\n",
      "560/668 [========================>.....] - ETA: 0s - loss: 0.3474 - acc: 0.8589Epoch 00126: val_loss did not improve\n",
      "668/668 [==============================] - 0s - loss: 0.3476 - acc: 0.8563 - val_loss: 0.4116 - val_acc: 0.8251\n",
      "Epoch 128/1000\n",
      "620/668 [==========================>...] - ETA: 0s - loss: 0.3536 - acc: 0.8597Epoch 00127: val_loss did not improve\n",
      "668/668 [==============================] - 0s - loss: 0.3494 - acc: 0.8623 - val_loss: 0.4107 - val_acc: 0.8251\n",
      "Epoch 129/1000\n",
      "580/668 [=========================>....] - ETA: 0s - loss: 0.3456 - acc: 0.8552Epoch 00128: val_loss did not improve\n",
      "668/668 [==============================] - 0s - loss: 0.3431 - acc: 0.8593 - val_loss: 0.4152 - val_acc: 0.8161\n",
      "Epoch 130/1000\n",
      "540/668 [=======================>......] - ETA: 0s - loss: 0.3523 - acc: 0.8537Epoch 00129: val_loss did not improve\n",
      "668/668 [==============================] - 0s - loss: 0.3516 - acc: 0.8548 - val_loss: 0.4127 - val_acc: 0.8206\n",
      "Epoch 131/1000\n",
      "640/668 [===========================>..] - ETA: 0s - loss: 0.3380 - acc: 0.8547Epoch 00130: val_loss did not improve\n",
      "668/668 [==============================] - 0s - loss: 0.3415 - acc: 0.8533 - val_loss: 0.4439 - val_acc: 0.7892\n",
      "Epoch 132/1000\n",
      "500/668 [=====================>........] - ETA: 0s - loss: 0.3583 - acc: 0.8620Epoch 00131: val_loss did not improve\n",
      "668/668 [==============================] - 0s - loss: 0.3587 - acc: 0.8608 - val_loss: 0.4104 - val_acc: 0.8206\n",
      "Epoch 133/1000\n",
      "620/668 [==========================>...] - ETA: 0s - loss: 0.3453 - acc: 0.8581Epoch 00132: val_loss did not improve\n",
      "668/668 [==============================] - 0s - loss: 0.3421 - acc: 0.8563 - val_loss: 0.4219 - val_acc: 0.8117\n",
      "Epoch 134/1000\n",
      "520/668 [======================>.......] - ETA: 0s - loss: 0.3323 - acc: 0.8654Epoch 00133: val_loss did not improve\n",
      "668/668 [==============================] - 0s - loss: 0.3471 - acc: 0.8638 - val_loss: 0.4201 - val_acc: 0.8161\n",
      "Epoch 135/1000\n",
      "600/668 [=========================>....] - ETA: 0s - loss: 0.3661 - acc: 0.8417Epoch 00134: val_loss did not improve\n",
      "668/668 [==============================] - 0s - loss: 0.3524 - acc: 0.8533 - val_loss: 0.4111 - val_acc: 0.8161\n",
      "Epoch 136/1000\n",
      "660/668 [============================>.] - ETA: 0s - loss: 0.3612 - acc: 0.8455Epoch 00135: val_loss did not improve\n",
      "668/668 [==============================] - 0s - loss: 0.3602 - acc: 0.8458 - val_loss: 0.4114 - val_acc: 0.8251\n",
      "Epoch 137/1000\n",
      "500/668 [=====================>........] - ETA: 0s - loss: 0.3319 - acc: 0.8660Epoch 00136: val_loss did not improve\n",
      "668/668 [==============================] - 0s - loss: 0.3479 - acc: 0.8638 - val_loss: 0.4106 - val_acc: 0.8251\n",
      "Epoch 138/1000\n",
      "660/668 [============================>.] - ETA: 0s - loss: 0.3422 - acc: 0.8470Epoch 00137: val_loss did not improve\n",
      "668/668 [==============================] - 0s - loss: 0.3457 - acc: 0.8458 - val_loss: 0.4162 - val_acc: 0.8206\n",
      "Epoch 139/1000\n",
      "600/668 [=========================>....] - ETA: 0s - loss: 0.3402 - acc: 0.8717Epoch 00138: val_loss did not improve\n",
      "668/668 [==============================] - 0s - loss: 0.3385 - acc: 0.8743 - val_loss: 0.4323 - val_acc: 0.8206\n",
      "Epoch 140/1000\n",
      "560/668 [========================>.....] - ETA: 0s - loss: 0.3531 - acc: 0.8500Epoch 00139: val_loss did not improve\n",
      "668/668 [==============================] - 0s - loss: 0.3424 - acc: 0.8578 - val_loss: 0.4102 - val_acc: 0.8251\n",
      "Epoch 141/1000\n",
      "600/668 [=========================>....] - ETA: 0s - loss: 0.3387 - acc: 0.8667Epoch 00140: val_loss did not improve\n",
      "668/668 [==============================] - 0s - loss: 0.3325 - acc: 0.8713 - val_loss: 0.4114 - val_acc: 0.8206\n",
      "Epoch 142/1000\n",
      "640/668 [===========================>..] - ETA: 0s - loss: 0.3437 - acc: 0.8656Epoch 00141: val_loss did not improve\n",
      "668/668 [==============================] - 0s - loss: 0.3364 - acc: 0.8698 - val_loss: 0.4100 - val_acc: 0.8296\n",
      "Epoch 143/1000\n",
      "520/668 [======================>.......] - ETA: 0s - loss: 0.3457 - acc: 0.8673Epoch 00142: val_loss did not improve\n",
      "668/668 [==============================] - 0s - loss: 0.3343 - acc: 0.8668 - val_loss: 0.4111 - val_acc: 0.8251\n",
      "Epoch 144/1000\n",
      "660/668 [============================>.] - ETA: 0s - loss: 0.3342 - acc: 0.8652Epoch 00143: val_loss did not improve\n",
      "668/668 [==============================] - 0s - loss: 0.3338 - acc: 0.8653 - val_loss: 0.4193 - val_acc: 0.8296\n",
      "Epoch 145/1000\n",
      "660/668 [============================>.] - ETA: 0s - loss: 0.3393 - acc: 0.8576Epoch 00144: val_loss did not improve\n",
      "668/668 [==============================] - 0s - loss: 0.3372 - acc: 0.8593 - val_loss: 0.4100 - val_acc: 0.8206\n",
      "Epoch 146/1000\n",
      "660/668 [============================>.] - ETA: 0s - loss: 0.3328 - acc: 0.8697Epoch 00145: val_loss improved from 0.40941 to 0.40939, saving model to ../output/titanic.model.best.hdf5\n",
      "668/668 [==============================] - 0s - loss: 0.3311 - acc: 0.8713 - val_loss: 0.4094 - val_acc: 0.8251\n",
      "Epoch 147/1000\n",
      "640/668 [===========================>..] - ETA: 0s - loss: 0.3165 - acc: 0.8703Epoch 00146: val_loss did not improve\n",
      "668/668 [==============================] - 0s - loss: 0.3231 - acc: 0.8683 - val_loss: 0.4151 - val_acc: 0.8251\n",
      "Epoch 00146: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "#checkpointer = ModelCheckpoint(filepath=model_weights_file, verbose=1, save_best_only=True)\n",
    "#stopper = EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=25, verbose=1, mode='auto')\n",
    "#hist = model.fit(X_train, y_train, epochs=1000, batch_size=20, validation_split=0.25, \n",
    "#                 callbacks=[checkpointer, stopper], \n",
    "#                 verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "672/891 [=====================>........] - ETA: 0s\n",
      "Training Accuracy: 0.867564535101\n"
     ]
    }
   ],
   "source": [
    "# Load the weights that yielded the best validation accuracy\n",
    "model.load_weights(model_weights_file)\n",
    "\n",
    "# Evaluate the model on the training set\n",
    "score = model.evaluate(X_train, y_train)\n",
    "print(\"\\nTraining Accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(418, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load test data\n",
    "df_test_raw = pd.read_csv(test_file)\n",
    "print(df_test_raw.shape)\n",
    "df_test_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before scaling: \n",
      "   PassengerId  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked  \\\n",
      "0          892       3    1  34.5      0      0   7.8292         1   \n",
      "1          893       3    0  47.0      1      0   7.0000         2   \n",
      "2          894       2    1  62.0      0      0   9.6875         1   \n",
      "3          895       3    1  27.0      0      0   8.6625         2   \n",
      "4          896       3    0  22.0      1      1  12.2875         2   \n",
      "\n",
      "   Family_Size  Title    ...     Ticket9  Ticket10  Ticket11  Ticket12  \\\n",
      "0            1      5    ...           0         0         0         0   \n",
      "1            2      6    ...           0         0         0         0   \n",
      "2            1      5    ...           0         0         0         0   \n",
      "3            1      5    ...           0         0         0         0   \n",
      "4            3      6    ...           0         0         0         0   \n",
      "\n",
      "   Ticket13  Ticket14  Ticket15  Ticket16  Ticket17  In_Cabin  \n",
      "0         0         0         0         0         0         1  \n",
      "1         0         0         0         0         0         1  \n",
      "2         0         0         0         0         0         1  \n",
      "3         0         0         0         0         0         1  \n",
      "4         0         0         0         0         0         1  \n",
      "\n",
      "[5 rows x 113 columns]\n",
      "After scaling: \n",
      "   0    1         2      3         4         5    6    7      8     9   ...   \\\n",
      "0  1.0  1.0  0.453947  0.000  0.000000  0.015282  0.5  0.0  0.625  0.06 ...    \n",
      "1  1.0  0.0  0.618421  0.125  0.000000  0.013663  1.0  0.1  0.750  0.38 ...    \n",
      "2  0.5  1.0  0.815789  0.000  0.000000  0.018909  0.5  0.0  0.625  0.24 ...    \n",
      "3  1.0  1.0  0.355263  0.000  0.000000  0.016908  1.0  0.0  0.625  0.06 ...    \n",
      "4  1.0  0.0  0.289474  0.125  0.111111  0.023984  1.0  0.2  0.750  0.62 ...    \n",
      "\n",
      "   102  103  104  105  106  107  108  109  110  111  \n",
      "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "\n",
      "[5 rows x 112 columns]\n",
      "(418, 112)\n",
      "[ 1.          1.          0.45394737  0.          0.          0.01528158\n",
      "  0.5         0.          0.625       0.06        0.18867925  0.75609756\n",
      "  0.85393256  0.84444445  0.98888886  0.13333334  0.          0.5\n",
      "  0.94252872  0.15555556  0.          0.49411765  0.74712646  0.92372882\n",
      "  0.83471072  0.94262296  0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.2\n",
      "  0.05263158  0.36538461  0.30769232  0.71249998  0.50515461  0.42982456\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "# Prepare the data for testing\n",
    "df_test = prep_data(df_test_raw)\n",
    "X_test = np.array(df_test)[:,:]\n",
    "X_test = X_test.astype('float32')\n",
    "print(X_test.shape)\n",
    "print(X_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.28025097  0.05451864]\n"
     ]
    }
   ],
   "source": [
    "# Predict for test data\n",
    "y_test = model.predict(X_test)\n",
    "print(y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save predictions\n",
    "with open(pred_file, 'w') as f:\n",
    "    f.write('PassengerId,Survived\\n')\n",
    "    for index, y_hat in enumerate(y_test):\n",
    "        prediction = np.argmax(y_hat)\n",
    "        f.write(str(int(df_test_raw.iloc[index]['PassengerId'])) + ',' + str(prediction)+'\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
