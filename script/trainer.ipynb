{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training and test data files\n",
    "train_file = '../input/train.csv'\n",
    "test_file = '../input/test.csv'\n",
    "model_file = '../output/titanic.model.json'\n",
    "model_weights_file = '../output/titanic.model.best.hdf5'\n",
    "pred_file = '../output/gender_submission.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 12)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load training data\n",
    "df_train_raw = pd.read_csv(train_file)\n",
    "print(df_train_raw.shape)\n",
    "df_train_raw.info()\n",
    "df_train_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prepare the data for training and testing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "max_name_len = df_train_raw.Name.map(len).max()\n",
    "max_ticket_len = df_train_raw.Ticket.map(len).max()\n",
    "\n",
    "title_list=['Mrs', 'Mr', 'Master', 'Miss', 'Major', 'Rev', 'Dr', 'Ms', 'Mlle',\n",
    "            'Col', 'Capt', 'Mme', 'Countess', 'Don', 'Jonkheer']\n",
    "\n",
    "import string\n",
    "def substrings_in_string(big_string, substrings):\n",
    "    for substring in substrings:\n",
    "        if substring in big_string:\n",
    "            return substring\n",
    "    return np.nan\n",
    "\n",
    "def prep_data(frame, mode='test'):\n",
    "    # Fill missing Age data with median \n",
    "    frame['Age'] = frame['Age'].fillna(frame['Age'].median())\n",
    "    \n",
    "    # Generate data about whether adult or minor\n",
    "    frame['Adult_Or_Minor'] = frame.apply(lambda row: 0 if row['Age'] < 18 else 1, axis=1)\n",
    "\n",
    "    # Generate data about whether senior citizen\n",
    "    frame['Senior_Citizen'] = frame.apply(lambda row: 0 if row['Age'] > 65 else 1, axis=1)\n",
    "\n",
    "    # Fill missing Fare data with median\n",
    "    frame['Fare'] = frame['Fare'].fillna(frame['Fare'].median())\n",
    "    \n",
    "    # Creating new family_size and fare per person columns \n",
    "    frame['Family_Size'] = frame['SibSp'] + frame['Parch'] + 1\n",
    "    frame['Alone'] = frame.apply(lambda row: 1 if row['Family_Size'] == 1 else 0, axis=1)\n",
    "    frame['Fare_Per_Person'] = frame['Fare']/frame['Family_Size']\n",
    "\n",
    "    # Convert Sex to number\n",
    "    frame['Sex'] = pd.Categorical(frame['Sex']).codes\n",
    "\n",
    "    # Generate data for missing Embarked and convert to number\n",
    "    frame['Embarked'] = frame['Embarked'].fillna('S')\n",
    "    frame['Embarked'] = pd.Categorical(frame['Embarked']).codes\n",
    "    \n",
    "    # Extract title from name\n",
    "    frame['Title'] = frame['Name'].map(lambda x: substrings_in_string(x, title_list))\n",
    "    frame['Title'] = pd.Categorical(frame['Title']).codes\n",
    "\n",
    "    # Convert Name into characters\n",
    "    frame['Name_Length'] = frame.apply(lambda row: len(row['Name']), axis=1)\n",
    "    frame['Words_In_Name'] = frame.apply(lambda row: len(row['Name'].split()), axis=1)    \n",
    "    for i in range(0, max_name_len):\n",
    "        col_name = 'Name' + str(i)\n",
    "        frame[col_name] = frame['Name'].str[i]\n",
    "        frame[col_name] = frame.apply(lambda row: 0 if isinstance(row[col_name], float) and math.isnan(row[col_name]) else ord(row[col_name]), axis=1)\n",
    "    frame.pop('Name')    \n",
    "    \n",
    "    # Convert Ticket into characters\n",
    "    frame['Ticket_Length'] = frame.apply(lambda row: len(row['Ticket']), axis=1)\n",
    "    for i in range(0, max_ticket_len):\n",
    "        col_name = 'Ticket' + str(i)\n",
    "        frame[col_name] = frame['Ticket'].str[i]\n",
    "        frame[col_name] = frame.apply(lambda row: 0 if isinstance(row[col_name], float) and math.isnan(row[col_name]) else ord(row[col_name]), axis=1)\n",
    "    frame.pop('Ticket')    \n",
    "    \n",
    "    # Convert Cabin column to whether in cabin\n",
    "    frame['Cabin'] = frame['Cabin'].fillna('')\n",
    "    frame['In_Cabin'] = frame.apply(lambda row: 1 if row['Cabin'] != '' else 0, axis=1)\n",
    "    frame['Number_Of_Cabins'] = frame.apply(lambda row: len(row['Cabin'].split()), axis=1)    \n",
    "    frame.pop('Cabin')\n",
    "    \n",
    "    frame.fillna(0, axis=1)\n",
    "    \n",
    "    # Introduce rows with some noise\n",
    "    if (mode == 'augment'):\n",
    "        print('Adding more rows to training data')\n",
    "        row_count = frame.shape[0]\n",
    "        print('Row count before: ', row_count)\n",
    "        col_std = np.std(frame) \n",
    "        for i in range(0, row_count):\n",
    "            row1 = pd.Series(frame.iloc[i])\n",
    "            row2 = pd.Series(frame.iloc[i])\n",
    "            col_list = frame.columns.tolist()\n",
    "            col_list.remove('PassengerId')\n",
    "            col_list.remove('Survived')\n",
    "            for col in frame.columns.tolist():\n",
    "                row1[col] = row1[col] + col_std[col]\n",
    "                row2[col] = row2[col] - col_std[col]\n",
    "            if np.random.random_sample() < 0.33:\n",
    "                frame = frame.append(row1)\n",
    "            if np.random.random_sample() > 0.66:\n",
    "                frame = frame.append(row2)\n",
    "        row_count = frame.shape[0]\n",
    "        print('Row count after: ', row_count)\n",
    "    \n",
    "    \n",
    "    print(\"Before scaling: \")\n",
    "    print(frame.head())\n",
    "    \n",
    "    # Scale everything except PassengerId\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    col_list = frame.columns.tolist()\n",
    "    col_list.remove('PassengerId')\n",
    "    frame = frame[col_list]\n",
    "    np_scaled = min_max_scaler.fit_transform(frame)\n",
    "    frame = pd.DataFrame(np_scaled)\n",
    "    \n",
    "    print(\"After scaling: \")\n",
    "    print(frame.head())\n",
    "\n",
    "    return frame\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before scaling: \n",
      "   PassengerId  Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked  \\\n",
      "0            1         0       3    1  22.0      1      0   7.2500         2   \n",
      "1            2         1       1    0  38.0      1      0  71.2833         0   \n",
      "2            3         1       3    0  26.0      0      0   7.9250         2   \n",
      "3            4         1       1    0  35.0      1      0  53.1000         2   \n",
      "4            5         0       3    1  35.0      0      0   8.0500         2   \n",
      "\n",
      "   Adult_Or_Minor        ...         Ticket10  Ticket11  Ticket12  Ticket13  \\\n",
      "0               1        ...                0         0         0         0   \n",
      "1               1        ...                0         0         0         0   \n",
      "2               1        ...               49        48        49        50   \n",
      "3               1        ...                0         0         0         0   \n",
      "4               1        ...                0         0         0         0   \n",
      "\n",
      "   Ticket14  Ticket15  Ticket16  Ticket17  In_Cabin  Number_Of_Cabins  \n",
      "0         0         0         0         0         0                 0  \n",
      "1         0         0         0         0         1                 1  \n",
      "2        56        50         0         0         0                 0  \n",
      "3         0         0         0         0         1                 1  \n",
      "4         0         0         0         0         0                 0  \n",
      "\n",
      "[5 rows x 120 columns]\n",
      "After scaling: \n",
      "   0    1    2         3      4    5         6    7    8    9    ...   \\\n",
      "0  0.0  1.0  1.0  0.271174  0.125  0.0  0.014151  1.0  1.0  1.0  ...    \n",
      "1  1.0  0.0  0.0  0.472229  0.125  0.0  0.139136  0.0  1.0  1.0  ...    \n",
      "2  1.0  1.0  0.0  0.321438  0.000  0.0  0.015469  1.0  1.0  1.0  ...    \n",
      "3  1.0  0.0  0.0  0.434531  0.125  0.0  0.103644  1.0  1.0  1.0  ...    \n",
      "4  0.0  1.0  1.0  0.434531  0.000  0.0  0.015713  1.0  1.0  1.0  ...    \n",
      "\n",
      "        109       110       111       112       113       114  115  116  117  \\\n",
      "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.0  0.0  0.0   \n",
      "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.0  0.0  1.0   \n",
      "2  0.485149  0.842105  0.859649  0.877193  0.982456  0.877193  0.0  0.0  0.0   \n",
      "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.0  0.0  1.0   \n",
      "4  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.0  0.0  0.0   \n",
      "\n",
      "    118  \n",
      "0  0.00  \n",
      "1  0.25  \n",
      "2  0.00  \n",
      "3  0.25  \n",
      "4  0.00  \n",
      "\n",
      "[5 rows x 119 columns]\n",
      "(891, 118)\n",
      "[ 1.          1.          0.27117366  0.125       0.          0.01415106\n",
      "  1.          1.          1.          0.1         0.          0.00707553\n",
      "  0.78571427  0.15714286  0.09090909  0.01886792  0.91463417  0.72222221\n",
      "  0.94444442  0.86666667  0.75555557  0.13483146  0.          0.50561798\n",
      "  0.95348835  0.15730338  0.          0.66386557  0.9834711   0.82786888\n",
      "  0.90909094  0.26229507  0.59016395  0.79508197  0.93442625  0.93442625\n",
      "  0.86065573  0.95041323  0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.40000001\n",
      "  0.42105263  0.23076923  0.38181818  0.40000001  0.51546389  0.42982456\n",
      "  0.46666667  0.47826087  0.42608696  0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "# Prep training data\n",
    "df_train = prep_data(df_train_raw, mode='train')\n",
    "\n",
    "# Construct the X array\n",
    "X_train = np.array(df_train)[:,1:]\n",
    "X_train = X_train.astype('float32')\n",
    "print(X_train.shape)\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 2)\n",
      "[[ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]]\n"
     ]
    }
   ],
   "source": [
    "# Extract survived data as predictions\n",
    "from keras.utils.np_utils import to_categorical\n",
    "y_train = np.array(df_train)[:,0]\n",
    "y_train = to_categorical(y_train, 2)\n",
    "print(y_train.shape)\n",
    "print(y_train[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 891)               106029    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 891)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 445)               396940    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 445)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 892       \n",
      "=================================================================\n",
      "Total params: 503,861\n",
      "Trainable params: 503,861\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build a training network\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, RepeatVector, Flatten, Activation\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(891, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(445, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model_json = model.to_json()\n",
    "with open(model_file, 'w') as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 623 samples, validate on 268 samples\n",
      "Epoch 1/100\n",
      "440/623 [====================>.........] - ETA: 0s - loss: 0.6900 - acc: 0.5330Epoch 00000: val_loss improved from inf to 0.64919, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.6834 - acc: 0.5602 - val_loss: 0.6492 - val_acc: 0.6567\n",
      "Epoch 2/100\n",
      "460/623 [=====================>........] - ETA: 0s - loss: 0.6676 - acc: 0.6293Epoch 00001: val_loss improved from 0.64919 to 0.62879, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.6597 - acc: 0.6380 - val_loss: 0.6288 - val_acc: 0.6549\n",
      "Epoch 3/100\n",
      "460/623 [=====================>........] - ETA: 0s - loss: 0.6515 - acc: 0.6337Epoch 00002: val_loss improved from 0.62879 to 0.61317, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.6478 - acc: 0.6324 - val_loss: 0.6132 - val_acc: 0.6828\n",
      "Epoch 4/100\n",
      "440/623 [====================>.........] - ETA: 0s - loss: 0.6501 - acc: 0.6216Epoch 00003: val_loss improved from 0.61317 to 0.60226, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.6423 - acc: 0.6388 - val_loss: 0.6023 - val_acc: 0.7183\n",
      "Epoch 5/100\n",
      "440/623 [====================>.........] - ETA: 0s - loss: 0.6236 - acc: 0.6739Epoch 00004: val_loss improved from 0.60226 to 0.59024, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.6229 - acc: 0.6750 - val_loss: 0.5902 - val_acc: 0.7257\n",
      "Epoch 6/100\n",
      "620/623 [============================>.] - ETA: 0s - loss: 0.6177 - acc: 0.6637Epoch 00005: val_loss improved from 0.59024 to 0.57934, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.6179 - acc: 0.6629 - val_loss: 0.5793 - val_acc: 0.7444\n",
      "Epoch 7/100\n",
      "620/623 [============================>.] - ETA: 0s - loss: 0.6042 - acc: 0.6879Epoch 00006: val_loss improved from 0.57934 to 0.56727, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.6047 - acc: 0.6862 - val_loss: 0.5673 - val_acc: 0.7407\n",
      "Epoch 8/100\n",
      "460/623 [=====================>........] - ETA: 0s - loss: 0.5852 - acc: 0.7000Epoch 00007: val_loss improved from 0.56727 to 0.56173, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.5925 - acc: 0.6918 - val_loss: 0.5617 - val_acc: 0.7537\n",
      "Epoch 9/100\n",
      "480/623 [======================>.......] - ETA: 0s - loss: 0.5846 - acc: 0.7104Epoch 00008: val_loss improved from 0.56173 to 0.54651, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.5883 - acc: 0.7063 - val_loss: 0.5465 - val_acc: 0.7407\n",
      "Epoch 10/100\n",
      "500/623 [=======================>......] - ETA: 0s - loss: 0.5779 - acc: 0.6950Epoch 00009: val_loss improved from 0.54651 to 0.53730, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.5752 - acc: 0.7055 - val_loss: 0.5373 - val_acc: 0.7481\n",
      "Epoch 11/100\n",
      "460/623 [=====================>........] - ETA: 0s - loss: 0.5682 - acc: 0.7217Epoch 00010: val_loss improved from 0.53730 to 0.52858, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.5666 - acc: 0.7175 - val_loss: 0.5286 - val_acc: 0.7519\n",
      "Epoch 12/100\n",
      "480/623 [======================>.......] - ETA: 0s - loss: 0.5576 - acc: 0.7344Epoch 00011: val_loss improved from 0.52858 to 0.51975, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.5563 - acc: 0.7303 - val_loss: 0.5197 - val_acc: 0.7519\n",
      "Epoch 13/100\n",
      "460/623 [=====================>........] - ETA: 0s - loss: 0.5597 - acc: 0.7272Epoch 00012: val_loss improved from 0.51975 to 0.51423, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.5591 - acc: 0.7255 - val_loss: 0.5142 - val_acc: 0.7519\n",
      "Epoch 14/100\n",
      "460/623 [=====================>........] - ETA: 0s - loss: 0.5432 - acc: 0.7424Epoch 00013: val_loss improved from 0.51423 to 0.50929, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.5484 - acc: 0.7303 - val_loss: 0.5093 - val_acc: 0.7575\n",
      "Epoch 15/100\n",
      "460/623 [=====================>........] - ETA: 0s - loss: 0.5523 - acc: 0.7293Epoch 00014: val_loss improved from 0.50929 to 0.50225, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.5451 - acc: 0.7368 - val_loss: 0.5022 - val_acc: 0.7575\n",
      "Epoch 16/100\n",
      "500/623 [=======================>......] - ETA: 0s - loss: 0.5217 - acc: 0.7390Epoch 00015: val_loss improved from 0.50225 to 0.49898, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.5366 - acc: 0.7239 - val_loss: 0.4990 - val_acc: 0.7649\n",
      "Epoch 17/100\n",
      "500/623 [=======================>......] - ETA: 0s - loss: 0.5210 - acc: 0.7620Epoch 00016: val_loss improved from 0.49898 to 0.49319, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.5291 - acc: 0.7544 - val_loss: 0.4932 - val_acc: 0.7649\n",
      "Epoch 18/100\n",
      "480/623 [======================>.......] - ETA: 0s - loss: 0.5286 - acc: 0.7427Epoch 00017: val_loss improved from 0.49319 to 0.48610, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.5347 - acc: 0.7392 - val_loss: 0.4861 - val_acc: 0.7612\n",
      "Epoch 19/100\n",
      "500/623 [=======================>......] - ETA: 0s - loss: 0.5250 - acc: 0.7480Epoch 00018: val_loss improved from 0.48610 to 0.48230, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.5206 - acc: 0.7584 - val_loss: 0.4823 - val_acc: 0.7649\n",
      "Epoch 20/100\n",
      "480/623 [======================>.......] - ETA: 0s - loss: 0.5152 - acc: 0.7573Epoch 00019: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.5172 - acc: 0.7496 - val_loss: 0.4884 - val_acc: 0.7743\n",
      "Epoch 21/100\n",
      "480/623 [======================>.......] - ETA: 0s - loss: 0.4899 - acc: 0.7917Epoch 00020: val_loss improved from 0.48230 to 0.48161, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.5199 - acc: 0.7689 - val_loss: 0.4816 - val_acc: 0.7799\n",
      "Epoch 22/100\n",
      "480/623 [======================>.......] - ETA: 0s - loss: 0.5293 - acc: 0.7563Epoch 00021: val_loss improved from 0.48161 to 0.47023, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.5169 - acc: 0.7673 - val_loss: 0.4702 - val_acc: 0.7575\n",
      "Epoch 23/100\n",
      "480/623 [======================>.......] - ETA: 0s - loss: 0.5107 - acc: 0.7583Epoch 00022: val_loss improved from 0.47023 to 0.46641, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.5034 - acc: 0.7657 - val_loss: 0.4664 - val_acc: 0.7556\n",
      "Epoch 24/100\n",
      "620/623 [============================>.] - ETA: 0s - loss: 0.5086 - acc: 0.7669Epoch 00023: val_loss improved from 0.46641 to 0.46288, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.5083 - acc: 0.7665 - val_loss: 0.4629 - val_acc: 0.7668\n",
      "Epoch 25/100\n",
      "480/623 [======================>.......] - ETA: 0s - loss: 0.5069 - acc: 0.7552Epoch 00024: val_loss improved from 0.46288 to 0.46233, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.5055 - acc: 0.7673 - val_loss: 0.4623 - val_acc: 0.7892\n",
      "Epoch 26/100\n",
      "480/623 [======================>.......] - ETA: 0s - loss: 0.4916 - acc: 0.7740Epoch 00025: val_loss improved from 0.46233 to 0.46140, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.5037 - acc: 0.7616 - val_loss: 0.4614 - val_acc: 0.7948\n",
      "Epoch 27/100\n",
      "460/623 [=====================>........] - ETA: 0s - loss: 0.4892 - acc: 0.7793Epoch 00026: val_loss improved from 0.46140 to 0.45588, saving model to ../output/titanic.model.best.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "623/623 [==============================] - 0s - loss: 0.4953 - acc: 0.7777 - val_loss: 0.4559 - val_acc: 0.7948\n",
      "Epoch 28/100\n",
      "480/623 [======================>.......] - ETA: 0s - loss: 0.4940 - acc: 0.7667Epoch 00027: val_loss improved from 0.45588 to 0.45140, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.4915 - acc: 0.7753 - val_loss: 0.4514 - val_acc: 0.7929\n",
      "Epoch 29/100\n",
      "500/623 [=======================>......] - ETA: 0s - loss: 0.4916 - acc: 0.7680Epoch 00028: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4897 - acc: 0.7737 - val_loss: 0.4566 - val_acc: 0.7799\n",
      "Epoch 30/100\n",
      "460/623 [=====================>........] - ETA: 0s - loss: 0.4756 - acc: 0.8054Epoch 00029: val_loss improved from 0.45140 to 0.44838, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.4833 - acc: 0.7945 - val_loss: 0.4484 - val_acc: 0.7836\n",
      "Epoch 31/100\n",
      "480/623 [======================>.......] - ETA: 0s - loss: 0.4891 - acc: 0.7708Epoch 00030: val_loss improved from 0.44838 to 0.44302, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.4797 - acc: 0.7793 - val_loss: 0.4430 - val_acc: 0.8004\n",
      "Epoch 32/100\n",
      "500/623 [=======================>......] - ETA: 0s - loss: 0.4833 - acc: 0.7740Epoch 00031: val_loss improved from 0.44302 to 0.44082, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.4898 - acc: 0.7769 - val_loss: 0.4408 - val_acc: 0.8097\n",
      "Epoch 33/100\n",
      "460/623 [=====================>........] - ETA: 0s - loss: 0.5182 - acc: 0.7772Epoch 00032: val_loss improved from 0.44082 to 0.44009, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.4926 - acc: 0.7897 - val_loss: 0.4401 - val_acc: 0.7985\n",
      "Epoch 34/100\n",
      "440/623 [====================>.........] - ETA: 0s - loss: 0.4742 - acc: 0.7909Epoch 00033: val_loss improved from 0.44009 to 0.43663, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.4710 - acc: 0.7889 - val_loss: 0.4366 - val_acc: 0.8134\n",
      "Epoch 35/100\n",
      "480/623 [======================>.......] - ETA: 0s - loss: 0.4884 - acc: 0.7792Epoch 00034: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4841 - acc: 0.7817 - val_loss: 0.4391 - val_acc: 0.7873\n",
      "Epoch 36/100\n",
      "500/623 [=======================>......] - ETA: 0s - loss: 0.4713 - acc: 0.8000Epoch 00035: val_loss improved from 0.43663 to 0.43371, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.4762 - acc: 0.7945 - val_loss: 0.4337 - val_acc: 0.8134\n",
      "Epoch 37/100\n",
      "480/623 [======================>.......] - ETA: 0s - loss: 0.4726 - acc: 0.7844Epoch 00036: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4790 - acc: 0.7825 - val_loss: 0.4402 - val_acc: 0.7854\n",
      "Epoch 38/100\n",
      "440/623 [====================>.........] - ETA: 0s - loss: 0.4666 - acc: 0.7898Epoch 00037: val_loss improved from 0.43371 to 0.43086, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.4763 - acc: 0.7865 - val_loss: 0.4309 - val_acc: 0.8116\n",
      "Epoch 39/100\n",
      "460/623 [=====================>........] - ETA: 0s - loss: 0.4607 - acc: 0.7880Epoch 00038: val_loss improved from 0.43086 to 0.42919, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.4667 - acc: 0.7817 - val_loss: 0.4292 - val_acc: 0.8153\n",
      "Epoch 40/100\n",
      "440/623 [====================>.........] - ETA: 0s - loss: 0.4761 - acc: 0.7966Epoch 00039: val_loss improved from 0.42919 to 0.42768, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.4692 - acc: 0.7978 - val_loss: 0.4277 - val_acc: 0.8060\n",
      "Epoch 41/100\n",
      "500/623 [=======================>......] - ETA: 0s - loss: 0.4504 - acc: 0.8050Epoch 00040: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4688 - acc: 0.7865 - val_loss: 0.4280 - val_acc: 0.8116\n",
      "Epoch 42/100\n",
      "480/623 [======================>.......] - ETA: 0s - loss: 0.4647 - acc: 0.7958Epoch 00041: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4610 - acc: 0.7986 - val_loss: 0.4311 - val_acc: 0.7985\n",
      "Epoch 43/100\n",
      "500/623 [=======================>......] - ETA: 0s - loss: 0.4659 - acc: 0.7920Epoch 00042: val_loss improved from 0.42768 to 0.42504, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.4579 - acc: 0.7978 - val_loss: 0.4250 - val_acc: 0.8153\n",
      "Epoch 44/100\n",
      "460/623 [=====================>........] - ETA: 0s - loss: 0.4263 - acc: 0.8196Epoch 00043: val_loss improved from 0.42504 to 0.42496, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.4634 - acc: 0.7994 - val_loss: 0.4250 - val_acc: 0.7966\n",
      "Epoch 45/100\n",
      "500/623 [=======================>......] - ETA: 0s - loss: 0.4620 - acc: 0.7870Epoch 00044: val_loss improved from 0.42496 to 0.42470, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.4590 - acc: 0.7921 - val_loss: 0.4247 - val_acc: 0.8172\n",
      "Epoch 46/100\n",
      "500/623 [=======================>......] - ETA: 0s - loss: 0.4530 - acc: 0.8070Epoch 00045: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4632 - acc: 0.7970 - val_loss: 0.4277 - val_acc: 0.7929\n",
      "Epoch 47/100\n",
      "480/623 [======================>.......] - ETA: 0s - loss: 0.4536 - acc: 0.7927Epoch 00046: val_loss improved from 0.42470 to 0.42129, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.4487 - acc: 0.8026 - val_loss: 0.4213 - val_acc: 0.8078\n",
      "Epoch 48/100\n",
      "460/623 [=====================>........] - ETA: 0s - loss: 0.4626 - acc: 0.7935Epoch 00047: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4558 - acc: 0.8026 - val_loss: 0.4276 - val_acc: 0.7929\n",
      "Epoch 49/100\n",
      "460/623 [=====================>........] - ETA: 0s - loss: 0.4765 - acc: 0.7826Epoch 00048: val_loss improved from 0.42129 to 0.42031, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.4660 - acc: 0.7913 - val_loss: 0.4203 - val_acc: 0.7948\n",
      "Epoch 50/100\n",
      "440/623 [====================>.........] - ETA: 0s - loss: 0.4556 - acc: 0.8011Epoch 00049: val_loss improved from 0.42031 to 0.41884, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.4457 - acc: 0.8058 - val_loss: 0.4188 - val_acc: 0.8060\n",
      "Epoch 51/100\n",
      "460/623 [=====================>........] - ETA: 0s - loss: 0.4608 - acc: 0.8011Epoch 00050: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4502 - acc: 0.8066 - val_loss: 0.4190 - val_acc: 0.7966\n",
      "Epoch 52/100\n",
      "480/623 [======================>.......] - ETA: 0s - loss: 0.4689 - acc: 0.7813Epoch 00051: val_loss improved from 0.41884 to 0.41613, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.4474 - acc: 0.8026 - val_loss: 0.4161 - val_acc: 0.8004\n",
      "Epoch 53/100\n",
      "620/623 [============================>.] - ETA: 0s - loss: 0.4650 - acc: 0.7968Epoch 00052: val_loss improved from 0.41613 to 0.41554, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.4639 - acc: 0.7978 - val_loss: 0.4155 - val_acc: 0.7966\n",
      "Epoch 54/100\n",
      "600/623 [===========================>..] - ETA: 0s - loss: 0.4441 - acc: 0.7933Epoch 00053: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4447 - acc: 0.7945 - val_loss: 0.4187 - val_acc: 0.8153\n",
      "Epoch 55/100\n",
      "600/623 [===========================>..] - ETA: 0s - loss: 0.4490 - acc: 0.8042Epoch 00054: val_loss improved from 0.41554 to 0.41505, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.4509 - acc: 0.8002 - val_loss: 0.4150 - val_acc: 0.7966\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "440/623 [====================>.........] - ETA: 0s - loss: 0.4720 - acc: 0.7784Epoch 00055: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4477 - acc: 0.7897 - val_loss: 0.4161 - val_acc: 0.8041\n",
      "Epoch 57/100\n",
      "440/623 [====================>.........] - ETA: 0s - loss: 0.4312 - acc: 0.8205Epoch 00056: val_loss improved from 0.41505 to 0.41359, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.4328 - acc: 0.8162 - val_loss: 0.4136 - val_acc: 0.7985\n",
      "Epoch 58/100\n",
      "620/623 [============================>.] - ETA: 0s - loss: 0.4374 - acc: 0.8048Epoch 00057: val_loss improved from 0.41359 to 0.41249, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.4385 - acc: 0.8042 - val_loss: 0.4125 - val_acc: 0.7966\n",
      "Epoch 59/100\n",
      "440/623 [====================>.........] - ETA: 0s - loss: 0.4284 - acc: 0.8170Epoch 00058: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4428 - acc: 0.8066 - val_loss: 0.4132 - val_acc: 0.8041\n",
      "Epoch 60/100\n",
      "460/623 [=====================>........] - ETA: 0s - loss: 0.4541 - acc: 0.8011Epoch 00059: val_loss improved from 0.41249 to 0.41230, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.4360 - acc: 0.8122 - val_loss: 0.4123 - val_acc: 0.7966\n",
      "Epoch 61/100\n",
      "460/623 [=====================>........] - ETA: 0s - loss: 0.4347 - acc: 0.8109Epoch 00060: val_loss improved from 0.41230 to 0.41201, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.4425 - acc: 0.8018 - val_loss: 0.4120 - val_acc: 0.7966\n",
      "Epoch 62/100\n",
      "480/623 [======================>.......] - ETA: 0s - loss: 0.4408 - acc: 0.8094Epoch 00061: val_loss improved from 0.41201 to 0.41160, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.4552 - acc: 0.7961 - val_loss: 0.4116 - val_acc: 0.8022\n",
      "Epoch 63/100\n",
      "480/623 [======================>.......] - ETA: 0s - loss: 0.4219 - acc: 0.8073Epoch 00062: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4376 - acc: 0.7953 - val_loss: 0.4131 - val_acc: 0.8041\n",
      "Epoch 64/100\n",
      "500/623 [=======================>......] - ETA: 0s - loss: 0.4356 - acc: 0.8150Epoch 00063: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4405 - acc: 0.8090 - val_loss: 0.4218 - val_acc: 0.8172\n",
      "Epoch 65/100\n",
      "480/623 [======================>.......] - ETA: 0s - loss: 0.4524 - acc: 0.8010Epoch 00064: val_loss improved from 0.41160 to 0.41083, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.4344 - acc: 0.8122 - val_loss: 0.4108 - val_acc: 0.8041\n",
      "Epoch 66/100\n",
      "500/623 [=======================>......] - ETA: 0s - loss: 0.4302 - acc: 0.8160Epoch 00065: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4423 - acc: 0.8122 - val_loss: 0.4112 - val_acc: 0.8041\n",
      "Epoch 67/100\n",
      "500/623 [=======================>......] - ETA: 0s - loss: 0.4266 - acc: 0.8160Epoch 00066: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4445 - acc: 0.8018 - val_loss: 0.4119 - val_acc: 0.8060\n",
      "Epoch 68/100\n",
      "440/623 [====================>.........] - ETA: 0s - loss: 0.4583 - acc: 0.7864Epoch 00067: val_loss improved from 0.41083 to 0.41052, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.4413 - acc: 0.8034 - val_loss: 0.4105 - val_acc: 0.8004\n",
      "Epoch 69/100\n",
      "440/623 [====================>.........] - ETA: 0s - loss: 0.4399 - acc: 0.8148Epoch 00068: val_loss improved from 0.41052 to 0.41043, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.4390 - acc: 0.8146 - val_loss: 0.4104 - val_acc: 0.8060\n",
      "Epoch 70/100\n",
      "480/623 [======================>.......] - ETA: 0s - loss: 0.4441 - acc: 0.8094Epoch 00069: val_loss improved from 0.41043 to 0.40980, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.4363 - acc: 0.8074 - val_loss: 0.4098 - val_acc: 0.8022\n",
      "Epoch 71/100\n",
      "440/623 [====================>.........] - ETA: 0s - loss: 0.4164 - acc: 0.8148Epoch 00070: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4341 - acc: 0.8090 - val_loss: 0.4279 - val_acc: 0.8153\n",
      "Epoch 72/100\n",
      "480/623 [======================>.......] - ETA: 0s - loss: 0.4313 - acc: 0.8083Epoch 00071: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4399 - acc: 0.8018 - val_loss: 0.4112 - val_acc: 0.8078\n",
      "Epoch 73/100\n",
      "500/623 [=======================>......] - ETA: 0s - loss: 0.4274 - acc: 0.8080Epoch 00072: val_loss improved from 0.40980 to 0.40889, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.4287 - acc: 0.8050 - val_loss: 0.4089 - val_acc: 0.8078\n",
      "Epoch 74/100\n",
      "500/623 [=======================>......] - ETA: 0s - loss: 0.4387 - acc: 0.8000Epoch 00073: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4317 - acc: 0.8082 - val_loss: 0.4090 - val_acc: 0.8060\n",
      "Epoch 75/100\n",
      "500/623 [=======================>......] - ETA: 0s - loss: 0.4340 - acc: 0.8190Epoch 00074: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4316 - acc: 0.8146 - val_loss: 0.4100 - val_acc: 0.8097\n",
      "Epoch 76/100\n",
      "500/623 [=======================>......] - ETA: 0s - loss: 0.4323 - acc: 0.8060Epoch 00075: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4313 - acc: 0.8090 - val_loss: 0.4093 - val_acc: 0.8078\n",
      "Epoch 77/100\n",
      "460/623 [=====================>........] - ETA: 0s - loss: 0.4528 - acc: 0.7989Epoch 00076: val_loss improved from 0.40889 to 0.40863, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.4298 - acc: 0.8122 - val_loss: 0.4086 - val_acc: 0.8041\n",
      "Epoch 78/100\n",
      "440/623 [====================>.........] - ETA: 0s - loss: 0.4344 - acc: 0.8125Epoch 00077: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4247 - acc: 0.8162 - val_loss: 0.4099 - val_acc: 0.8134\n",
      "Epoch 79/100\n",
      "440/623 [====================>.........] - ETA: 0s - loss: 0.4213 - acc: 0.8261Epoch 00078: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4277 - acc: 0.8114 - val_loss: 0.4092 - val_acc: 0.8153\n",
      "Epoch 80/100\n",
      "440/623 [====================>.........] - ETA: 0s - loss: 0.4168 - acc: 0.8080Epoch 00079: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4248 - acc: 0.8058 - val_loss: 0.4101 - val_acc: 0.8190\n",
      "Epoch 81/100\n",
      "460/623 [=====================>........] - ETA: 0s - loss: 0.4454 - acc: 0.7924Epoch 00080: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4375 - acc: 0.8002 - val_loss: 0.4183 - val_acc: 0.8078\n",
      "Epoch 82/100\n",
      "620/623 [============================>.] - ETA: 0s - loss: 0.4212 - acc: 0.8137Epoch 00081: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4243 - acc: 0.8114 - val_loss: 0.4129 - val_acc: 0.8078\n",
      "Epoch 83/100\n",
      "440/623 [====================>.........] - ETA: 0s - loss: 0.4456 - acc: 0.8045Epoch 00082: val_loss improved from 0.40863 to 0.40818, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.4326 - acc: 0.8154 - val_loss: 0.4082 - val_acc: 0.8116\n",
      "Epoch 84/100\n",
      "440/623 [====================>.........] - ETA: 0s - loss: 0.4027 - acc: 0.8341Epoch 00083: val_loss improved from 0.40818 to 0.40812, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.4192 - acc: 0.8170 - val_loss: 0.4081 - val_acc: 0.8116\n",
      "Epoch 85/100\n",
      "440/623 [====================>.........] - ETA: 0s - loss: 0.4224 - acc: 0.8102Epoch 00084: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4104 - acc: 0.8162 - val_loss: 0.4116 - val_acc: 0.8209\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "440/623 [====================>.........] - ETA: 0s - loss: 0.4020 - acc: 0.8295Epoch 00085: val_loss improved from 0.40812 to 0.40697, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.4152 - acc: 0.8186 - val_loss: 0.4070 - val_acc: 0.8134\n",
      "Epoch 87/100\n",
      "460/623 [=====================>........] - ETA: 0s - loss: 0.4248 - acc: 0.7989Epoch 00086: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4266 - acc: 0.8002 - val_loss: 0.4165 - val_acc: 0.8284\n",
      "Epoch 88/100\n",
      "480/623 [======================>.......] - ETA: 0s - loss: 0.4400 - acc: 0.8146Epoch 00087: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4307 - acc: 0.8146 - val_loss: 0.4081 - val_acc: 0.8116\n",
      "Epoch 89/100\n",
      "460/623 [=====================>........] - ETA: 0s - loss: 0.4150 - acc: 0.8185Epoch 00088: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4214 - acc: 0.8210 - val_loss: 0.4186 - val_acc: 0.8190\n",
      "Epoch 90/100\n",
      "460/623 [=====================>........] - ETA: 0s - loss: 0.4342 - acc: 0.8054Epoch 00089: val_loss improved from 0.40697 to 0.40680, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.4284 - acc: 0.8138 - val_loss: 0.4068 - val_acc: 0.8134\n",
      "Epoch 91/100\n",
      "440/623 [====================>.........] - ETA: 0s - loss: 0.4144 - acc: 0.8250Epoch 00090: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4170 - acc: 0.8234 - val_loss: 0.4069 - val_acc: 0.8116\n",
      "Epoch 92/100\n",
      "480/623 [======================>.......] - ETA: 0s - loss: 0.4121 - acc: 0.8229Epoch 00091: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4096 - acc: 0.8234 - val_loss: 0.4114 - val_acc: 0.8078\n",
      "Epoch 93/100\n",
      "480/623 [======================>.......] - ETA: 0s - loss: 0.4268 - acc: 0.8146Epoch 00092: val_loss improved from 0.40680 to 0.40567, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.4191 - acc: 0.8226 - val_loss: 0.4057 - val_acc: 0.8134\n",
      "Epoch 94/100\n",
      "480/623 [======================>.......] - ETA: 0s - loss: 0.4080 - acc: 0.8281Epoch 00093: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4111 - acc: 0.8210 - val_loss: 0.4103 - val_acc: 0.8265\n",
      "Epoch 95/100\n",
      "480/623 [======================>.......] - ETA: 0s - loss: 0.4164 - acc: 0.8219Epoch 00094: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4185 - acc: 0.8146 - val_loss: 0.4062 - val_acc: 0.8134\n",
      "Epoch 96/100\n",
      "420/623 [===================>..........] - ETA: 0s - loss: 0.4216 - acc: 0.8143Epoch 00095: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4199 - acc: 0.8154 - val_loss: 0.4105 - val_acc: 0.8246\n",
      "Epoch 97/100\n",
      "620/623 [============================>.] - ETA: 0s - loss: 0.4190 - acc: 0.8234Epoch 00096: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4188 - acc: 0.8242 - val_loss: 0.4070 - val_acc: 0.8246\n",
      "Epoch 98/100\n",
      "440/623 [====================>.........] - ETA: 0s - loss: 0.4062 - acc: 0.8307Epoch 00097: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4239 - acc: 0.8218 - val_loss: 0.4089 - val_acc: 0.8246\n",
      "Epoch 99/100\n",
      "460/623 [=====================>........] - ETA: 0s - loss: 0.4047 - acc: 0.8315Epoch 00098: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4070 - acc: 0.8331 - val_loss: 0.4101 - val_acc: 0.8246\n",
      "Epoch 100/100\n",
      "500/623 [=======================>......] - ETA: 0s - loss: 0.4252 - acc: 0.8220Epoch 00099: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4107 - acc: 0.8250 - val_loss: 0.4071 - val_acc: 0.8246\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "checkpointer = ModelCheckpoint(filepath=model_weights_file, verbose=1, save_best_only=True)\n",
    "stopper = EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=10, verbose=1, mode='auto')\n",
    "hist = model.fit(X_train, y_train, epochs=100, batch_size=20, validation_split=0.3,\n",
    "                 callbacks=[checkpointer, stopper], \n",
    "                 verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 32/891 [>.............................] - ETA: 0s\n",
      "Training Accuracy: 0.820426487628\n"
     ]
    }
   ],
   "source": [
    "# Load the weights that yielded the best validation accuracy\n",
    "model.load_weights(model_weights_file)\n",
    "\n",
    "# Evaluate the model on the training set\n",
    "score = model.evaluate(X_train, y_train)\n",
    "print(\"\\nTraining Accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(418, 11)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      "PassengerId    418 non-null int64\n",
      "Pclass         418 non-null int64\n",
      "Name           418 non-null object\n",
      "Sex            418 non-null object\n",
      "Age            332 non-null float64\n",
      "SibSp          418 non-null int64\n",
      "Parch          418 non-null int64\n",
      "Ticket         418 non-null object\n",
      "Fare           417 non-null float64\n",
      "Cabin          91 non-null object\n",
      "Embarked       418 non-null object\n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# Load test data\n",
    "df_test_raw = pd.read_csv(test_file)\n",
    "print(df_test_raw.shape)\n",
    "df_test_raw.head()\n",
    "df_test_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before scaling: \n",
      "   PassengerId  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked  \\\n",
      "0          892       3    1  34.5      0      0   7.8292         1   \n",
      "1          893       3    0  47.0      1      0   7.0000         2   \n",
      "2          894       2    1  62.0      0      0   9.6875         1   \n",
      "3          895       3    1  27.0      0      0   8.6625         2   \n",
      "4          896       3    0  22.0      1      1  12.2875         2   \n",
      "\n",
      "   Adult_Or_Minor  Senior_Citizen        ...         Ticket10  Ticket11  \\\n",
      "0               1               1        ...                0         0   \n",
      "1               1               1        ...                0         0   \n",
      "2               1               1        ...                0         0   \n",
      "3               1               1        ...                0         0   \n",
      "4               1               1        ...                0         0   \n",
      "\n",
      "   Ticket12  Ticket13  Ticket14  Ticket15  Ticket16  Ticket17  In_Cabin  \\\n",
      "0         0         0         0         0         0         0         0   \n",
      "1         0         0         0         0         0         0         0   \n",
      "2         0         0         0         0         0         0         0   \n",
      "3         0         0         0         0         0         0         0   \n",
      "4         0         0         0         0         0         0         0   \n",
      "\n",
      "   Number_Of_Cabins  \n",
      "0                 0  \n",
      "1                 0  \n",
      "2                 0  \n",
      "3                 0  \n",
      "4                 0  \n",
      "\n",
      "[5 rows x 119 columns]\n",
      "After scaling: \n",
      "   0    1         2      3         4         5    6    7    8    9   ...   \\\n",
      "0  1.0  1.0  0.452723  0.000  0.000000  0.015282  0.5  1.0  1.0  0.0 ...    \n",
      "1  1.0  0.0  0.617566  0.125  0.000000  0.013663  1.0  1.0  1.0  0.1 ...    \n",
      "2  0.5  1.0  0.815377  0.000  0.000000  0.018909  0.5  1.0  1.0  0.0 ...    \n",
      "3  1.0  1.0  0.353818  0.000  0.000000  0.016908  1.0  1.0  1.0  0.0 ...    \n",
      "4  1.0  0.0  0.287881  0.125  0.111111  0.023984  1.0  1.0  1.0  0.2 ...    \n",
      "\n",
      "   108  109  110  111  112  113  114  115  116  117  \n",
      "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "\n",
      "[5 rows x 118 columns]\n",
      "(418, 118)\n",
      "[ 1.          1.          0.45272321  0.          0.          0.01528158\n",
      "  0.5         1.          1.          0.          1.          0.02983973\n",
      "  0.625       0.06        0.          0.18867925  0.75609756  0.85393256\n",
      "  0.84444445  0.98888886  0.13333334  0.          0.5         0.94252872\n",
      "  0.15555556  0.          0.49411765  0.74712646  0.92372882  0.83471072\n",
      "  0.94262296  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.2         0.05263158\n",
      "  0.36538461  0.30769232  0.71249998  0.50515461  0.42982456  0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "# Prepare the data for testing\n",
    "df_test = prep_data(df_test_raw)\n",
    "\n",
    "# Construct the X array\n",
    "X_test = np.array(df_test)[:,:]\n",
    "X_test = X_test.astype('float32')\n",
    "print(X_test.shape)\n",
    "print(X_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.8856203   0.12057135]\n"
     ]
    }
   ],
   "source": [
    "# Predict for test data\n",
    "y_test = model.predict(X_test)\n",
    "print(y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done 2434 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done 3184 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done 4034 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=-1)]: Done 4984 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=-1)]: Done 6034 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=-1)]: Done 7184 tasks      | elapsed:    9.7s\n",
      "[Parallel(n_jobs=-1)]: Done 8434 tasks      | elapsed:   11.4s\n",
      "[Parallel(n_jobs=-1)]: Done 9784 tasks      | elapsed:   13.2s\n",
      "[Parallel(n_jobs=-1)]: Done 11234 tasks      | elapsed:   15.2s\n",
      "[Parallel(n_jobs=-1)]: Done 12784 tasks      | elapsed:   17.3s\n",
      "[Parallel(n_jobs=-1)]: Done 14434 tasks      | elapsed:   19.5s\n",
      "[Parallel(n_jobs=-1)]: Done 16184 tasks      | elapsed:   21.8s\n",
      "[Parallel(n_jobs=-1)]: Done 18034 tasks      | elapsed:   24.3s\n",
      "[Parallel(n_jobs=-1)]: Done 19984 tasks      | elapsed:   26.9s\n",
      "[Parallel(n_jobs=-1)]: Done 20000 out of 20000 | elapsed:   27.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done 2434 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done 3184 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done 4034 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done 4984 tasks      | elapsed:    6.7s\n",
      "[Parallel(n_jobs=-1)]: Done 6034 tasks      | elapsed:    8.1s\n",
      "[Parallel(n_jobs=-1)]: Done 7184 tasks      | elapsed:    9.7s\n",
      "[Parallel(n_jobs=-1)]: Done 8434 tasks      | elapsed:   11.3s\n",
      "[Parallel(n_jobs=-1)]: Done 9784 tasks      | elapsed:   13.1s\n",
      "[Parallel(n_jobs=-1)]: Done 11234 tasks      | elapsed:   14.9s\n",
      "[Parallel(n_jobs=-1)]: Done 12784 tasks      | elapsed:   16.9s\n",
      "[Parallel(n_jobs=-1)]: Done 14434 tasks      | elapsed:   19.1s\n",
      "[Parallel(n_jobs=-1)]: Done 16184 tasks      | elapsed:   21.4s\n",
      "[Parallel(n_jobs=-1)]: Done 18034 tasks      | elapsed:   23.8s\n",
      "[Parallel(n_jobs=-1)]: Done 19984 tasks      | elapsed:   26.3s\n",
      "[Parallel(n_jobs=-1)]: Done 20000 out of 20000 | elapsed:   26.3s finished\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done 1234 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=8)]: Done 1784 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=8)]: Done 2434 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=8)]: Done 3184 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=8)]: Done 4034 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=8)]: Done 4984 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=8)]: Done 6034 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=8)]: Done 7184 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=8)]: Done 8434 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=8)]: Done 9784 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=8)]: Done 11234 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=8)]: Done 12784 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=8)]: Done 14434 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=8)]: Done 16184 tasks      | elapsed:    6.6s\n",
      "[Parallel(n_jobs=8)]: Done 18034 tasks      | elapsed:    7.4s\n",
      "[Parallel(n_jobs=8)]: Done 19984 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=8)]: Done 20000 out of 20000 | elapsed:    8.2s finished\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done 2434 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done 3184 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done 4034 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=-1)]: Done 4984 tasks      | elapsed:    6.5s\n",
      "[Parallel(n_jobs=-1)]: Done 6034 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=-1)]: Done 7184 tasks      | elapsed:    9.3s\n",
      "[Parallel(n_jobs=-1)]: Done 8434 tasks      | elapsed:   11.0s\n",
      "[Parallel(n_jobs=-1)]: Done 9784 tasks      | elapsed:   12.7s\n",
      "[Parallel(n_jobs=-1)]: Done 11234 tasks      | elapsed:   14.6s\n",
      "[Parallel(n_jobs=-1)]: Done 12784 tasks      | elapsed:   16.6s\n",
      "[Parallel(n_jobs=-1)]: Done 14434 tasks      | elapsed:   18.7s\n",
      "[Parallel(n_jobs=-1)]: Done 16184 tasks      | elapsed:   21.5s\n",
      "[Parallel(n_jobs=-1)]: Done 18034 tasks      | elapsed:   23.9s\n",
      "[Parallel(n_jobs=-1)]: Done 19984 tasks      | elapsed:   26.4s\n",
      "[Parallel(n_jobs=-1)]: Done 20000 out of 20000 | elapsed:   26.4s finished\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done 1234 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=8)]: Done 1784 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=8)]: Done 2434 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=8)]: Done 3184 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=8)]: Done 4034 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=8)]: Done 4984 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=8)]: Done 6034 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=8)]: Done 7184 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=8)]: Done 8434 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=8)]: Done 9784 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=8)]: Done 11234 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=8)]: Done 12784 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=8)]: Done 14434 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=8)]: Done 16184 tasks      | elapsed:    6.7s\n",
      "[Parallel(n_jobs=8)]: Done 18034 tasks      | elapsed:    7.5s\n",
      "[Parallel(n_jobs=8)]: Done 19984 tasks      | elapsed:    8.3s\n",
      "[Parallel(n_jobs=8)]: Done 20000 out of 20000 | elapsed:    8.3s finished\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done 2434 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done 3184 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done 4034 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=-1)]: Done 4984 tasks      | elapsed:    6.5s\n",
      "[Parallel(n_jobs=-1)]: Done 6034 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=-1)]: Done 7184 tasks      | elapsed:    9.4s\n",
      "[Parallel(n_jobs=-1)]: Done 8434 tasks      | elapsed:   11.0s\n",
      "[Parallel(n_jobs=-1)]: Done 9784 tasks      | elapsed:   12.8s\n",
      "[Parallel(n_jobs=-1)]: Done 11234 tasks      | elapsed:   14.7s\n",
      "[Parallel(n_jobs=-1)]: Done 12784 tasks      | elapsed:   16.7s\n",
      "[Parallel(n_jobs=-1)]: Done 14434 tasks      | elapsed:   18.9s\n",
      "[Parallel(n_jobs=-1)]: Done 16184 tasks      | elapsed:   21.1s\n",
      "[Parallel(n_jobs=-1)]: Done 18034 tasks      | elapsed:   23.5s\n",
      "[Parallel(n_jobs=-1)]: Done 19984 tasks      | elapsed:   26.1s\n",
      "[Parallel(n_jobs=-1)]: Done 20000 out of 20000 | elapsed:   26.1s finished\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done 1234 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=8)]: Done 1784 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=8)]: Done 2434 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=8)]: Done 3184 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=8)]: Done 4034 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=8)]: Done 4984 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=8)]: Done 6034 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=8)]: Done 7184 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=8)]: Done 8434 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=8)]: Done 9784 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=8)]: Done 11234 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=8)]: Done 12784 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=8)]: Done 14434 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=8)]: Done 16184 tasks      | elapsed:    6.6s\n",
      "[Parallel(n_jobs=8)]: Done 18034 tasks      | elapsed:    7.4s\n",
      "[Parallel(n_jobs=8)]: Done 19984 tasks      | elapsed:    8.1s\n",
      "[Parallel(n_jobs=8)]: Done 20000 out of 20000 | elapsed:    8.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.81705948372615034"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use random forest classification \n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=20000, warm_start=True, n_jobs=-1, random_state=0, verbose=1)\n",
    "clf.fit(X_train, y_train)\n",
    "scores = cross_val_score(clf, X_train, y_train)\n",
    "scores.mean()     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done 1234 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=8)]: Done 1784 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=8)]: Done 2434 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=8)]: Done 3184 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=8)]: Done 4034 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=8)]: Done 4984 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=8)]: Done 6034 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=8)]: Done 7184 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=8)]: Done 8434 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=8)]: Done 9784 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=8)]: Done 11234 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=8)]: Done 12784 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=8)]: Done 14434 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=8)]: Done 16184 tasks      | elapsed:    7.0s\n",
      "[Parallel(n_jobs=8)]: Done 18034 tasks      | elapsed:    7.8s\n",
      "[Parallel(n_jobs=8)]: Done 19984 tasks      | elapsed:    8.7s\n",
      "[Parallel(n_jobs=8)]: Done 20000 out of 20000 | elapsed:    8.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  0.]\n"
     ]
    }
   ],
   "source": [
    "y_test = clf.predict(X_test)\n",
    "print(y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save predictions\n",
    "with open(pred_file, 'w') as f:\n",
    "    f.write('PassengerId,Survived\\n')\n",
    "    for index, y_hat in enumerate(y_test):\n",
    "        prediction = np.argmax(y_hat)\n",
    "        f.write(str(int(df_test_raw.iloc[index]['PassengerId'])) + ',' + str(prediction)+'\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
