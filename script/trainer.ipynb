{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training and test data files\n",
    "train_file = '../input/train.csv'\n",
    "test_file = '../input/test.csv'\n",
    "model_file = '../output/titanic.model.json'\n",
    "model_weights_file = '../output/titanic.model.best.hdf5'\n",
    "pred_file = '../output/gender_submission.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load training data\n",
    "df_train = pd.read_csv(train_file)\n",
    "print(df_train.shape)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 2)\n",
      "[[ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]]\n"
     ]
    }
   ],
   "source": [
    "# Extract survived data as predictions: 0 = Died, 1 = Survived\n",
    "from keras.utils.np_utils import to_categorical\n",
    "y_train = to_categorical(df_train[\"Survived\"], 2)\n",
    "df_train.pop('Survived')\n",
    "print(y_train.shape)\n",
    "print(y_train[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prepare the rest of the data for training\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "max_name_len = df_train.Name.map(len).max()    \n",
    "\n",
    "def prep_data(frame):\n",
    "    frame = frame.fillna(0)\n",
    "\n",
    "    # Creating new family_size and fare per person columns \n",
    "    frame['Family_Size'] = frame['SibSp'] + frame['Parch'] + 1\n",
    "    frame['Fare_Per_Person'] = frame['Fare']/frame['Family_Size']\n",
    "\n",
    "    # Convert Sex and Embarked to number\n",
    "    frame['Sex'] = pd.Categorical(frame['Sex']).codes\n",
    "    frame['Embarked'] = pd.Categorical(frame['Embarked']).codes\n",
    "    \n",
    "    # Convert Name into characters\n",
    "    frame['Name_Length'] = frame.apply(lambda row: len(row['Name']), axis=1)\n",
    "#    for i in range(0, max_name_len):\n",
    "#        col_name = 'Name' + str(i)\n",
    "#        frame[col_name] = frame['Name'].str[i]\n",
    "#        frame[col_name] = frame.apply(lambda row: ord(' ') if isinstance(row[col_name], float) and math.isnan(row[col_name]) else ord(row[col_name]), axis=1)\n",
    "    frame.pop('Name')\n",
    "    \n",
    "    # TODO: Ignore Ticket for now\n",
    "    frame.pop('Ticket')\n",
    "    \n",
    "    # Convert Cabin column to whether in cabin\n",
    "    frame['In_Cabin'] = frame.apply(lambda row: 1 if row['Cabin'] != 0 else 0, axis=1)\n",
    "    frame.pop('Cabin')\n",
    "    \n",
    "    print(\"Before scaling: \")\n",
    "    print(frame.head())\n",
    "    \n",
    "    # Scale everything except PassengerId\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    col_list = frame.columns.tolist()\n",
    "    col_list.remove('PassengerId')\n",
    "    frame = frame[col_list]\n",
    "    np_scaled = min_max_scaler.fit_transform(frame)\n",
    "    frame = pd.DataFrame(np_scaled)\n",
    "    \n",
    "    print(\"After scaling: \")\n",
    "    print(frame.head())\n",
    "\n",
    "    return frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before scaling: \n",
      "   PassengerId  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked  \\\n",
      "0            1       3    1  22.0      1      0   7.2500         3   \n",
      "1            2       1    0  38.0      1      0  71.2833         1   \n",
      "2            3       3    0  26.0      0      0   7.9250         3   \n",
      "3            4       1    0  35.0      1      0  53.1000         3   \n",
      "4            5       3    1  35.0      0      0   8.0500         3   \n",
      "\n",
      "   Family_Size  Fare_Per_Person  Name_Length  In_Cabin  \n",
      "0            2          3.62500           23         0  \n",
      "1            2         35.64165           51         1  \n",
      "2            1          7.92500           22         0  \n",
      "3            2         26.55000           44         1  \n",
      "4            1          8.05000           24         0  \n",
      "After scaling: \n",
      "    0    1       2      3    4         5         6    7         8         9   \\\n",
      "0  1.0  1.0  0.2750  0.125  0.0  0.014151  1.000000  0.1  0.007076  0.157143   \n",
      "1  0.0  0.0  0.4750  0.125  0.0  0.139136  0.333333  0.1  0.069568  0.557143   \n",
      "2  1.0  0.0  0.3250  0.000  0.0  0.015469  1.000000  0.0  0.015469  0.142857   \n",
      "3  0.0  0.0  0.4375  0.125  0.0  0.103644  1.000000  0.1  0.051822  0.457143   \n",
      "4  1.0  1.0  0.4375  0.000  0.0  0.015713  1.000000  0.0  0.015713  0.171429   \n",
      "\n",
      "    10  \n",
      "0  0.0  \n",
      "1  1.0  \n",
      "2  0.0  \n",
      "3  1.0  \n",
      "4  0.0  \n",
      "(891, 11)\n",
      "[ 1.          1.          0.27500001  0.125       0.          0.01415106\n",
      "  1.          0.1         0.00707553  0.15714286  0.        ]\n"
     ]
    }
   ],
   "source": [
    "# Prepare the rest of the data for training\n",
    "df_train = prep_data(df_train)\n",
    "X_train = np.array(df_train)[:,:]\n",
    "X_train = X_train.astype('float32')\n",
    "print(X_train.shape)\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 512)               6144      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 137,986\n",
      "Trainable params: 137,986\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build a training network\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(X_train.shape[1], )))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/1000\n",
      "640/712 [=========================>....] - ETA: 0s - loss: 0.5376 - acc: 0.7172Epoch 00000: val_loss improved from inf to 0.48574, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.5308 - acc: 0.7233 - val_loss: 0.4857 - val_acc: 0.7765\n",
      "Epoch 2/1000\n",
      "670/712 [===========================>..] - ETA: 0s - loss: 0.4944 - acc: 0.7851Epoch 00001: val_loss improved from 0.48574 to 0.42296, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.4919 - acc: 0.7851 - val_loss: 0.4230 - val_acc: 0.8156\n",
      "Epoch 3/1000\n",
      "610/712 [========================>.....] - ETA: 0s - loss: 0.4847 - acc: 0.7803Epoch 00002: val_loss improved from 0.42296 to 0.41112, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.4800 - acc: 0.7851 - val_loss: 0.4111 - val_acc: 0.8324\n",
      "Epoch 4/1000\n",
      "630/712 [=========================>....] - ETA: 0s - loss: 0.4760 - acc: 0.7921Epoch 00003: val_loss improved from 0.41112 to 0.39779, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.4731 - acc: 0.7949 - val_loss: 0.3978 - val_acc: 0.8324\n",
      "Epoch 5/1000\n",
      "630/712 [=========================>....] - ETA: 0s - loss: 0.4567 - acc: 0.8111Epoch 00004: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4620 - acc: 0.8062 - val_loss: 0.4011 - val_acc: 0.8380\n",
      "Epoch 6/1000\n",
      "610/712 [========================>.....] - ETA: 0s - loss: 0.4624 - acc: 0.7984Epoch 00005: val_loss improved from 0.39779 to 0.39383, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.4517 - acc: 0.8034 - val_loss: 0.3938 - val_acc: 0.8380\n",
      "Epoch 7/1000\n",
      "630/712 [=========================>....] - ETA: 0s - loss: 0.4586 - acc: 0.7937Epoch 00006: val_loss improved from 0.39383 to 0.38801, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.4541 - acc: 0.7992 - val_loss: 0.3880 - val_acc: 0.8436\n",
      "Epoch 8/1000\n",
      "670/712 [===========================>..] - ETA: 0s - loss: 0.4518 - acc: 0.7955Epoch 00007: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4516 - acc: 0.7978 - val_loss: 0.3913 - val_acc: 0.8436\n",
      "Epoch 9/1000\n",
      "710/712 [============================>.] - ETA: 0s - loss: 0.4579 - acc: 0.8141Epoch 00008: val_loss improved from 0.38801 to 0.38406, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.4576 - acc: 0.8146 - val_loss: 0.3841 - val_acc: 0.8436\n",
      "Epoch 10/1000\n",
      "670/712 [===========================>..] - ETA: 0s - loss: 0.4318 - acc: 0.8090Epoch 00009: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4388 - acc: 0.8062 - val_loss: 0.3872 - val_acc: 0.8492\n",
      "Epoch 11/1000\n",
      "650/712 [==========================>...] - ETA: 0s - loss: 0.4397 - acc: 0.8046Epoch 00010: val_loss improved from 0.38406 to 0.36519, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.4422 - acc: 0.8006 - val_loss: 0.3652 - val_acc: 0.8380\n",
      "Epoch 12/1000\n",
      "700/712 [============================>.] - ETA: 0s - loss: 0.4323 - acc: 0.8229Epoch 00011: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4358 - acc: 0.8202 - val_loss: 0.4139 - val_acc: 0.8212\n",
      "Epoch 13/1000\n",
      "660/712 [==========================>...] - ETA: 0s - loss: 0.4379 - acc: 0.8227Epoch 00012: val_loss improved from 0.36519 to 0.36071, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.4371 - acc: 0.8202 - val_loss: 0.3607 - val_acc: 0.8436\n",
      "Epoch 14/1000\n",
      "690/712 [============================>.] - ETA: 0s - loss: 0.4371 - acc: 0.8145Epoch 00013: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4341 - acc: 0.8174 - val_loss: 0.3675 - val_acc: 0.8324\n",
      "Epoch 15/1000\n",
      "690/712 [============================>.] - ETA: 0s - loss: 0.4255 - acc: 0.8217Epoch 00014: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4313 - acc: 0.8216 - val_loss: 0.3644 - val_acc: 0.8436\n",
      "Epoch 16/1000\n",
      "710/712 [============================>.] - ETA: 0s - loss: 0.4360 - acc: 0.8211Epoch 00015: val_loss improved from 0.36071 to 0.35454, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.4354 - acc: 0.8216 - val_loss: 0.3545 - val_acc: 0.8436\n",
      "Epoch 17/1000\n",
      "690/712 [============================>.] - ETA: 0s - loss: 0.4224 - acc: 0.8232Epoch 00016: val_loss improved from 0.35454 to 0.34635, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.4252 - acc: 0.8188 - val_loss: 0.3463 - val_acc: 0.8492\n",
      "Epoch 18/1000\n",
      "640/712 [=========================>....] - ETA: 0s - loss: 0.4193 - acc: 0.8219Epoch 00017: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4281 - acc: 0.8202 - val_loss: 0.3798 - val_acc: 0.8436\n",
      "Epoch 19/1000\n",
      "670/712 [===========================>..] - ETA: 0s - loss: 0.4392 - acc: 0.8403Epoch 00018: val_loss improved from 0.34635 to 0.34475, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.4344 - acc: 0.8371 - val_loss: 0.3447 - val_acc: 0.8547\n",
      "Epoch 20/1000\n",
      "640/712 [=========================>....] - ETA: 0s - loss: 0.4254 - acc: 0.8234Epoch 00019: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4260 - acc: 0.8230 - val_loss: 0.3657 - val_acc: 0.8436\n",
      "Epoch 21/1000\n",
      "630/712 [=========================>....] - ETA: 0s - loss: 0.4135 - acc: 0.8270Epoch 00020: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4231 - acc: 0.8174 - val_loss: 0.3544 - val_acc: 0.8603\n",
      "Epoch 22/1000\n",
      "690/712 [============================>.] - ETA: 0s - loss: 0.4200 - acc: 0.8232Epoch 00021: val_loss improved from 0.34475 to 0.34173, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.4251 - acc: 0.8216 - val_loss: 0.3417 - val_acc: 0.8547\n",
      "Epoch 23/1000\n",
      "650/712 [==========================>...] - ETA: 0s - loss: 0.4017 - acc: 0.8354Epoch 00022: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4163 - acc: 0.8301 - val_loss: 0.3933 - val_acc: 0.8603\n",
      "Epoch 24/1000\n",
      "700/712 [============================>.] - ETA: 0s - loss: 0.4187 - acc: 0.8229Epoch 00023: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4196 - acc: 0.8216 - val_loss: 0.3526 - val_acc: 0.8436\n",
      "Epoch 25/1000\n",
      "610/712 [========================>.....] - ETA: 0s - loss: 0.4240 - acc: 0.8311Epoch 00024: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4180 - acc: 0.8287 - val_loss: 0.3500 - val_acc: 0.8659\n",
      "Epoch 26/1000\n",
      "690/712 [============================>.] - ETA: 0s - loss: 0.4150 - acc: 0.8275Epoch 00025: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4187 - acc: 0.8258 - val_loss: 0.3611 - val_acc: 0.8547\n",
      "Epoch 27/1000\n",
      "640/712 [=========================>....] - ETA: 0s - loss: 0.4245 - acc: 0.8328Epoch 00026: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4287 - acc: 0.8287 - val_loss: 0.3447 - val_acc: 0.8547\n",
      "Epoch 28/1000\n",
      "610/712 [========================>.....] - ETA: 0s - loss: 0.3896 - acc: 0.8410Epoch 00027: val_loss improved from 0.34173 to 0.33809, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.4140 - acc: 0.8315 - val_loss: 0.3381 - val_acc: 0.8659\n",
      "Epoch 29/1000\n",
      "690/712 [============================>.] - ETA: 0s - loss: 0.4235 - acc: 0.8261Epoch 00028: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4220 - acc: 0.8258 - val_loss: 0.3563 - val_acc: 0.8659\n",
      "Epoch 30/1000\n",
      "690/712 [============================>.] - ETA: 0s - loss: 0.4034 - acc: 0.8333Epoch 00029: val_loss did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s - loss: 0.4104 - acc: 0.8301 - val_loss: 0.3790 - val_acc: 0.8436\n",
      "Epoch 31/1000\n",
      "660/712 [==========================>...] - ETA: 0s - loss: 0.4298 - acc: 0.8258Epoch 00030: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4219 - acc: 0.8258 - val_loss: 0.3407 - val_acc: 0.8492\n",
      "Epoch 32/1000\n",
      "640/712 [=========================>....] - ETA: 0s - loss: 0.4070 - acc: 0.8266Epoch 00031: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4190 - acc: 0.8244 - val_loss: 0.3709 - val_acc: 0.8380\n",
      "Epoch 33/1000\n",
      "650/712 [==========================>...] - ETA: 0s - loss: 0.4153 - acc: 0.8354Epoch 00032: val_loss improved from 0.33809 to 0.33277, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.4235 - acc: 0.8287 - val_loss: 0.3328 - val_acc: 0.8547\n",
      "Epoch 34/1000\n",
      "670/712 [===========================>..] - ETA: 0s - loss: 0.4007 - acc: 0.8358Epoch 00033: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4003 - acc: 0.8343 - val_loss: 0.3723 - val_acc: 0.8324\n",
      "Epoch 35/1000\n",
      "660/712 [==========================>...] - ETA: 0s - loss: 0.4208 - acc: 0.8273Epoch 00034: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4128 - acc: 0.8343 - val_loss: 0.3371 - val_acc: 0.8603\n",
      "Epoch 36/1000\n",
      "650/712 [==========================>...] - ETA: 0s - loss: 0.4106 - acc: 0.8431Epoch 00035: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4047 - acc: 0.8469 - val_loss: 0.3494 - val_acc: 0.8603\n",
      "Epoch 37/1000\n",
      "650/712 [==========================>...] - ETA: 0s - loss: 0.4193 - acc: 0.8262Epoch 00036: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4206 - acc: 0.8244 - val_loss: 0.3349 - val_acc: 0.8659\n",
      "Epoch 38/1000\n",
      "650/712 [==========================>...] - ETA: 0s - loss: 0.3928 - acc: 0.8354Epoch 00037: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4041 - acc: 0.8287 - val_loss: 0.3389 - val_acc: 0.8547\n",
      "Epoch 39/1000\n",
      "680/712 [===========================>..] - ETA: 0s - loss: 0.4090 - acc: 0.8324Epoch 00038: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4077 - acc: 0.8357 - val_loss: 0.3544 - val_acc: 0.8436\n",
      "Epoch 40/1000\n",
      "690/712 [============================>.] - ETA: 0s - loss: 0.4092 - acc: 0.8261Epoch 00039: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4120 - acc: 0.8244 - val_loss: 0.3455 - val_acc: 0.8492\n",
      "Epoch 41/1000\n",
      "690/712 [============================>.] - ETA: 0s - loss: 0.4109 - acc: 0.8435Epoch 00040: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4081 - acc: 0.8455 - val_loss: 0.3420 - val_acc: 0.8771\n",
      "Epoch 42/1000\n",
      "640/712 [=========================>....] - ETA: 0s - loss: 0.4088 - acc: 0.8266Epoch 00041: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4175 - acc: 0.8244 - val_loss: 0.3416 - val_acc: 0.8603\n",
      "Epoch 43/1000\n",
      "640/712 [=========================>....] - ETA: 0s - loss: 0.4058 - acc: 0.8359Epoch 00042: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4013 - acc: 0.8385 - val_loss: 0.3426 - val_acc: 0.8603\n",
      "Epoch 44/1000\n",
      "660/712 [==========================>...] - ETA: 0s - loss: 0.4317 - acc: 0.8303Epoch 00043: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4290 - acc: 0.8315 - val_loss: 0.3533 - val_acc: 0.8603\n",
      "Epoch 00043: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "checkpointer = ModelCheckpoint(filepath=model_weights_file, verbose=1, save_best_only=True)\n",
    "stopper = EarlyStopping(monitor='val_loss', min_delta=1e-5, patience=10, verbose=1, mode='auto')\n",
    "hist = model.fit(X_train, y_train, epochs=1000, batch_size=10, validation_split=0.2, \n",
    "                 callbacks=[checkpointer, stopper], \n",
    "                 verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "672/891 [=====================>........] - ETA: 0s\n",
      " Training Accuracy: 0.846240180443\n"
     ]
    }
   ],
   "source": [
    "# Load the weights that yielded the best validation accuracy\n",
    "model.load_weights(model_weights_file)\n",
    "\n",
    "# Evaluate the model on the training set\n",
    "score = model.evaluate(X_train, y_train)\n",
    "print(\"\\n Training Accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(418, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load test data\n",
    "df_test_raw = pd.read_csv(test_file)\n",
    "print(df_test_raw.shape)\n",
    "df_test_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before scaling: \n",
      "   PassengerId  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked  \\\n",
      "0          892       3    1  34.5      0      0   7.8292         1   \n",
      "1          893       3    0  47.0      1      0   7.0000         2   \n",
      "2          894       2    1  62.0      0      0   9.6875         1   \n",
      "3          895       3    1  27.0      0      0   8.6625         2   \n",
      "4          896       3    0  22.0      1      1  12.2875         2   \n",
      "\n",
      "   Family_Size  Fare_Per_Person  Name_Length  In_Cabin  \n",
      "0            1         7.829200           16         0  \n",
      "1            2         3.500000           32         0  \n",
      "2            1         9.687500           25         0  \n",
      "3            1         8.662500           16         0  \n",
      "4            3         4.095833           44         0  \n",
      "After scaling: \n",
      "    0    1         2      3         4         5    6    7         8     9   \\\n",
      "0  1.0  1.0  0.453947  0.000  0.000000  0.015282  0.5  0.0  0.029840  0.06   \n",
      "1  1.0  0.0  0.618421  0.125  0.000000  0.013663  1.0  0.1  0.013340  0.38   \n",
      "2  0.5  1.0  0.815789  0.000  0.000000  0.018909  0.5  0.0  0.036922  0.24   \n",
      "3  1.0  1.0  0.355263  0.000  0.000000  0.016908  1.0  0.0  0.033016  0.06   \n",
      "4  1.0  0.0  0.289474  0.125  0.111111  0.023984  1.0  0.2  0.015611  0.62   \n",
      "\n",
      "    10  \n",
      "0  0.0  \n",
      "1  0.0  \n",
      "2  0.0  \n",
      "3  0.0  \n",
      "4  0.0  \n",
      "(418, 11)\n",
      "[ 1.          1.          0.45394737  0.          0.          0.01528158\n",
      "  0.5         0.          0.02983973  0.06        0.        ]\n"
     ]
    }
   ],
   "source": [
    "# Prepare the data for testing\n",
    "df_test = prep_data(df_test_raw)\n",
    "X_test = np.array(df_test)[:,:]\n",
    "X_test = X_test.astype('float32')\n",
    "print(X_test.shape)\n",
    "print(X_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.86151505  0.06864763]\n"
     ]
    }
   ],
   "source": [
    "# Predict for test data\n",
    "y_test = model.predict(X_test)\n",
    "print(y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save predictions\n",
    "with open(pred_file, 'w') as f:\n",
    "    f.write('PassengerId,Survived\\n')\n",
    "    for index, y_hat in enumerate(y_test):\n",
    "        prediction = np.argmax(y_hat)\n",
    "        f.write(str(df_test_raw.iloc[index]['PassengerId']) + ',' + str(prediction)+'\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
