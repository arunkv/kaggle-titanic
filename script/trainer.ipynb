{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training and test data files\n",
    "train_file = '../input/train.csv'\n",
    "test_file = '../input/test.csv'\n",
    "model_file = '../output/titanic.model.json'\n",
    "model_weights_file = '../output/titanic.model.best.hdf5'\n",
    "pred_file = '../output/gender_submission.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load training data\n",
    "df_train = pd.read_csv(train_file)\n",
    "print(df_train.shape)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 2)\n",
      "[[ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]]\n"
     ]
    }
   ],
   "source": [
    "# Extract survived data as predictions: 0 = Died, 1 = Survived\n",
    "from keras.utils.np_utils import to_categorical\n",
    "y_train = to_categorical(df_train[\"Survived\"], 2)\n",
    "df_train.pop('Survived')\n",
    "print(y_train.shape)\n",
    "print(y_train[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prepare the rest of the data for training\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "max_name_len = df_train.Name.map(len).max()    \n",
    "\n",
    "def prep_data(frame):\n",
    "    frame = frame.fillna(0)\n",
    "\n",
    "    # Creating new family_size and fare per person columns \n",
    "    frame['Family_Size'] = frame['SibSp'] + frame['Parch'] + 1\n",
    "    frame['Fare_Per_Person'] = frame['Fare']/frame['Family_Size']\n",
    "\n",
    "    # Convert Sex and Embarked to number\n",
    "    frame['Sex'] = pd.Categorical(frame['Sex']).codes\n",
    "    frame['Embarked'] = pd.Categorical(frame['Embarked']).codes\n",
    "    \n",
    "    # Convert name\n",
    "    for i in range(0, max_name_len):\n",
    "        col_name = 'Name' + str(i)\n",
    "        frame[col_name] = frame['Name'].str[i]\n",
    "        frame[col_name] = frame.apply(lambda row: ord(' ') if isinstance(row[col_name], float) and math.isnan(row[col_name]) else ord(row[col_name]), axis=1)\n",
    "    frame.pop('Name')\n",
    "    \n",
    "    # TODO: Ignore Ticket, Cabin for now\n",
    "    frame.pop('Ticket')\n",
    "    frame.pop('Cabin')\n",
    "    \n",
    "    print(\"Before scaling: \")\n",
    "    print(frame.head())\n",
    "    \n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    col_list = frame.columns.tolist()\n",
    "    col_list.remove('PassengerId')\n",
    "    frame = frame[col_list]\n",
    "    np_scaled = min_max_scaler.fit_transform(frame)\n",
    "    frame = pd.DataFrame(np_scaled)\n",
    "    \n",
    "    print(\"After scaling: \")\n",
    "    print(frame.head())\n",
    "\n",
    "    return frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before scaling: \n",
      "   PassengerId  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked  \\\n",
      "0            1       3    1  22.0      1      0   7.2500         3   \n",
      "1            2       1    0  38.0      1      0  71.2833         1   \n",
      "2            3       3    0  26.0      0      0   7.9250         3   \n",
      "3            4       1    0  35.0      1      0  53.1000         3   \n",
      "4            5       3    1  35.0      0      0   8.0500         3   \n",
      "\n",
      "   Family_Size  Fare_Per_Person   ...    Name72  Name73  Name74  Name75  \\\n",
      "0            2          3.62500   ...        32      32      32      32   \n",
      "1            2         35.64165   ...        32      32      32      32   \n",
      "2            1          7.92500   ...        32      32      32      32   \n",
      "3            2         26.55000   ...        32      32      32      32   \n",
      "4            1          8.05000   ...        32      32      32      32   \n",
      "\n",
      "   Name76  Name77  Name78  Name79  Name80  Name81  \n",
      "0      32      32      32      32      32      32  \n",
      "1      32      32      32      32      32      32  \n",
      "2      32      32      32      32      32      32  \n",
      "3      32      32      32      32      32      32  \n",
      "4      32      32      32      32      32      32  \n",
      "\n",
      "[5 rows x 92 columns]\n",
      "After scaling: \n",
      "    0    1       2      3    4         5         6    7         8         9   \\\n",
      "0  1.0  1.0  0.2750  0.125  0.0  0.014151  1.000000  0.1  0.007076  0.018868   \n",
      "1  0.0  0.0  0.4750  0.125  0.0  0.139136  0.333333  0.1  0.069568  0.037736   \n",
      "2  1.0  0.0  0.3250  0.000  0.0  0.015469  1.000000  0.0  0.015469  0.132075   \n",
      "3  0.0  0.0  0.4375  0.125  0.0  0.103644  1.000000  0.1  0.051822  0.094340   \n",
      "4  1.0  1.0  0.4375  0.000  0.0  0.015713  1.000000  0.0  0.015713  0.000000   \n",
      "\n",
      "  ...    81   82   83   84   85   86   87   88   89   90  \n",
      "0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "1 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "3 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "4 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "\n",
      "[5 rows x 91 columns]\n",
      "(891, 91)\n",
      "[ 1.          1.          0.27500001  0.125       0.          0.01415106\n",
      "  1.          0.1         0.00707553  0.01886792  0.91463417  0.72222221\n",
      "  0.94444442  0.86666667  0.75555557  0.13483146  0.          0.50561798\n",
      "  0.95348835  0.15730338  0.          0.54022986  0.9775281   0.76666665\n",
      "  0.87640452  0.          0.44444445  0.72222221  0.91111112  0.91111112\n",
      "  0.81111109  0.93258429  0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "# Prepare the rest of the data for training\n",
    "df_train = prep_data(df_train)\n",
    "X_train = np.array(df_train)[:,:]\n",
    "X_train = X_train.astype('float32')\n",
    "print(X_train.shape)\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_11 (Dense)             (None, 512)               47104     \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 219,714\n",
      "Trainable params: 219,714\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build a training network\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(X_train.shape[1], )))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/50\n",
      "500/712 [====================>.........] - ETA: 0s - loss: 0.7023 - acc: 0.5280Epoch 00000: val_loss improved from inf to 0.64285, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 1s - loss: 0.6898 - acc: 0.5534 - val_loss: 0.6429 - val_acc: 0.6425\n",
      "Epoch 2/50\n",
      "600/712 [========================>.....] - ETA: 0s - loss: 0.6799 - acc: 0.6100Epoch 00001: val_loss improved from 0.64285 to 0.61964, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.6712 - acc: 0.6222 - val_loss: 0.6196 - val_acc: 0.6425\n",
      "Epoch 3/50\n",
      "700/712 [============================>.] - ETA: 0s - loss: 0.6513 - acc: 0.6086Epoch 00002: val_loss improved from 0.61964 to 0.60232, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.6538 - acc: 0.6053 - val_loss: 0.6023 - val_acc: 0.7430\n",
      "Epoch 4/50\n",
      "700/712 [============================>.] - ETA: 0s - loss: 0.6283 - acc: 0.6414Epoch 00003: val_loss improved from 0.60232 to 0.57851, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.6267 - acc: 0.6447 - val_loss: 0.5785 - val_acc: 0.7709\n",
      "Epoch 5/50\n",
      "600/712 [========================>.....] - ETA: 0s - loss: 0.6150 - acc: 0.6733Epoch 00004: val_loss improved from 0.57851 to 0.53491, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.6071 - acc: 0.6728 - val_loss: 0.5349 - val_acc: 0.7598\n",
      "Epoch 6/50\n",
      "500/712 [====================>.........] - ETA: 0s - loss: 0.5797 - acc: 0.6900Epoch 00005: val_loss improved from 0.53491 to 0.50787, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.5681 - acc: 0.6938 - val_loss: 0.5079 - val_acc: 0.7709\n",
      "Epoch 7/50\n",
      "600/712 [========================>.....] - ETA: 0s - loss: 0.5579 - acc: 0.7117Epoch 00006: val_loss improved from 0.50787 to 0.49502, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.5469 - acc: 0.7261 - val_loss: 0.4950 - val_acc: 0.7598\n",
      "Epoch 8/50\n",
      "600/712 [========================>.....] - ETA: 0s - loss: 0.5685 - acc: 0.7483Epoch 00007: val_loss improved from 0.49502 to 0.48612, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.5603 - acc: 0.7458 - val_loss: 0.4861 - val_acc: 0.7709\n",
      "Epoch 9/50\n",
      "600/712 [========================>.....] - ETA: 0s - loss: 0.5549 - acc: 0.7350Epoch 00008: val_loss improved from 0.48612 to 0.48477, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.5490 - acc: 0.7416 - val_loss: 0.4848 - val_acc: 0.7933\n",
      "Epoch 10/50\n",
      "600/712 [========================>.....] - ETA: 0s - loss: 0.5570 - acc: 0.7533Epoch 00009: val_loss improved from 0.48477 to 0.46698, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.5589 - acc: 0.7486 - val_loss: 0.4670 - val_acc: 0.7877\n",
      "Epoch 11/50\n",
      "600/712 [========================>.....] - ETA: 0s - loss: 0.5063 - acc: 0.7817Epoch 00010: val_loss improved from 0.46698 to 0.45717, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.5186 - acc: 0.7725 - val_loss: 0.4572 - val_acc: 0.7933\n",
      "Epoch 12/50\n",
      "600/712 [========================>.....] - ETA: 0s - loss: 0.5051 - acc: 0.7783Epoch 00011: val_loss improved from 0.45717 to 0.45566, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.5046 - acc: 0.7837 - val_loss: 0.4557 - val_acc: 0.8045\n",
      "Epoch 13/50\n",
      "600/712 [========================>.....] - ETA: 0s - loss: 0.4932 - acc: 0.7683Epoch 00012: val_loss improved from 0.45566 to 0.43538, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.4883 - acc: 0.7669 - val_loss: 0.4354 - val_acc: 0.8212\n",
      "Epoch 14/50\n",
      "700/712 [============================>.] - ETA: 0s - loss: 0.5110 - acc: 0.7900Epoch 00013: val_loss improved from 0.43538 to 0.43175, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.5138 - acc: 0.7879 - val_loss: 0.4318 - val_acc: 0.7989\n",
      "Epoch 15/50\n",
      "700/712 [============================>.] - ETA: 0s - loss: 0.4867 - acc: 0.7814Epoch 00014: val_loss improved from 0.43175 to 0.43007, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.4845 - acc: 0.7851 - val_loss: 0.4301 - val_acc: 0.8324\n",
      "Epoch 16/50\n",
      "700/712 [============================>.] - ETA: 0s - loss: 0.4830 - acc: 0.7957Epoch 00015: val_loss improved from 0.43007 to 0.42356, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.4828 - acc: 0.7963 - val_loss: 0.4236 - val_acc: 0.8268\n",
      "Epoch 17/50\n",
      "600/712 [========================>.....] - ETA: 0s - loss: 0.4754 - acc: 0.7817Epoch 00016: val_loss improved from 0.42356 to 0.42069, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.4744 - acc: 0.7851 - val_loss: 0.4207 - val_acc: 0.8268\n",
      "Epoch 18/50\n",
      "500/712 [====================>.........] - ETA: 0s - loss: 0.4586 - acc: 0.8020Epoch 00017: val_loss improved from 0.42069 to 0.41909, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.4570 - acc: 0.8048 - val_loss: 0.4191 - val_acc: 0.8324\n",
      "Epoch 19/50\n",
      "600/712 [========================>.....] - ETA: 0s - loss: 0.4531 - acc: 0.8017Epoch 00018: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4510 - acc: 0.8006 - val_loss: 0.4209 - val_acc: 0.8268\n",
      "Epoch 20/50\n",
      "700/712 [============================>.] - ETA: 0s - loss: 0.4508 - acc: 0.8143Epoch 00019: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4489 - acc: 0.8132 - val_loss: 0.4246 - val_acc: 0.8045\n",
      "Epoch 21/50\n",
      "500/712 [====================>.........] - ETA: 0s - loss: 0.4914 - acc: 0.7960Epoch 00020: val_loss improved from 0.41909 to 0.41430, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.4693 - acc: 0.8090 - val_loss: 0.4143 - val_acc: 0.8268\n",
      "Epoch 22/50\n",
      "600/712 [========================>.....] - ETA: 0s - loss: 0.4690 - acc: 0.7917Epoch 00021: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4721 - acc: 0.7935 - val_loss: 0.4175 - val_acc: 0.8156\n",
      "Epoch 23/50\n",
      "500/712 [====================>.........] - ETA: 0s - loss: 0.4497 - acc: 0.8040Epoch 00022: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4474 - acc: 0.8076 - val_loss: 0.4162 - val_acc: 0.8101\n",
      "Epoch 24/50\n",
      "700/712 [============================>.] - ETA: 0s - loss: 0.4363 - acc: 0.8286Epoch 00023: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4390 - acc: 0.8272 - val_loss: 0.4157 - val_acc: 0.8101\n",
      "Epoch 25/50\n",
      "500/712 [====================>.........] - ETA: 0s - loss: 0.4095 - acc: 0.8360Epoch 00024: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4241 - acc: 0.8230 - val_loss: 0.4214 - val_acc: 0.8156\n",
      "Epoch 26/50\n",
      "500/712 [====================>.........] - ETA: 0s - loss: 0.4819 - acc: 0.8060Epoch 00025: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4543 - acc: 0.8174 - val_loss: 0.4253 - val_acc: 0.8045\n",
      "Epoch 27/50\n",
      "500/712 [====================>.........] - ETA: 0s - loss: 0.4317 - acc: 0.8180Epoch 00026: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4351 - acc: 0.8104 - val_loss: 0.4243 - val_acc: 0.8101\n",
      "Epoch 28/50\n",
      "500/712 [====================>.........] - ETA: 0s - loss: 0.4520 - acc: 0.8060Epoch 00027: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4358 - acc: 0.8174 - val_loss: 0.4197 - val_acc: 0.8156\n",
      "Epoch 29/50\n",
      "500/712 [====================>.........] - ETA: 0s - loss: 0.4539 - acc: 0.8240Epoch 00028: val_loss improved from 0.41430 to 0.41314, saving model to ../output/titanic.model.best.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s - loss: 0.4525 - acc: 0.8244 - val_loss: 0.4131 - val_acc: 0.8212\n",
      "Epoch 30/50\n",
      "700/712 [============================>.] - ETA: 0s - loss: 0.4369 - acc: 0.8214Epoch 00029: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4361 - acc: 0.8216 - val_loss: 0.4166 - val_acc: 0.8212\n",
      "Epoch 31/50\n",
      "500/712 [====================>.........] - ETA: 0s - loss: 0.4029 - acc: 0.8340Epoch 00030: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4039 - acc: 0.8272 - val_loss: 0.4311 - val_acc: 0.8101\n",
      "Epoch 32/50\n",
      "400/712 [===============>..............] - ETA: 0s - loss: 0.4213 - acc: 0.8150Epoch 00031: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4363 - acc: 0.8146 - val_loss: 0.4152 - val_acc: 0.8268\n",
      "Epoch 33/50\n",
      "500/712 [====================>.........] - ETA: 0s - loss: 0.4116 - acc: 0.8100Epoch 00032: val_loss improved from 0.41314 to 0.41185, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.4179 - acc: 0.8174 - val_loss: 0.4118 - val_acc: 0.8101\n",
      "Epoch 34/50\n",
      "400/712 [===============>..............] - ETA: 0s - loss: 0.4332 - acc: 0.8225Epoch 00033: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4341 - acc: 0.8258 - val_loss: 0.4288 - val_acc: 0.8045\n",
      "Epoch 35/50\n",
      "500/712 [====================>.........] - ETA: 0s - loss: 0.4290 - acc: 0.8320Epoch 00034: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4201 - acc: 0.8272 - val_loss: 0.4170 - val_acc: 0.8156\n",
      "Epoch 36/50\n",
      "500/712 [====================>.........] - ETA: 0s - loss: 0.4045 - acc: 0.8440Epoch 00035: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4060 - acc: 0.8413 - val_loss: 0.4209 - val_acc: 0.8101\n",
      "Epoch 37/50\n",
      "500/712 [====================>.........] - ETA: 0s - loss: 0.4203 - acc: 0.8540Epoch 00036: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4186 - acc: 0.8553 - val_loss: 0.4136 - val_acc: 0.8268\n",
      "Epoch 38/50\n",
      "500/712 [====================>.........] - ETA: 0s - loss: 0.4030 - acc: 0.8300Epoch 00037: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4257 - acc: 0.8216 - val_loss: 0.4179 - val_acc: 0.8045\n",
      "Epoch 39/50\n",
      "500/712 [====================>.........] - ETA: 0s - loss: 0.4234 - acc: 0.8440Epoch 00038: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4140 - acc: 0.8441 - val_loss: 0.4133 - val_acc: 0.8268\n",
      "Epoch 40/50\n",
      "500/712 [====================>.........] - ETA: 0s - loss: 0.3876 - acc: 0.8480Epoch 00039: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4076 - acc: 0.8287 - val_loss: 0.4233 - val_acc: 0.8101\n",
      "Epoch 41/50\n",
      "400/712 [===============>..............] - ETA: 0s - loss: 0.3912 - acc: 0.8450Epoch 00040: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.3842 - acc: 0.8525 - val_loss: 0.4133 - val_acc: 0.8268\n",
      "Epoch 42/50\n",
      "500/712 [====================>.........] - ETA: 0s - loss: 0.4131 - acc: 0.8220Epoch 00041: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.3960 - acc: 0.8385 - val_loss: 0.4156 - val_acc: 0.8156\n",
      "Epoch 43/50\n",
      "400/712 [===============>..............] - ETA: 0s - loss: 0.4016 - acc: 0.8200Epoch 00042: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.3899 - acc: 0.8329 - val_loss: 0.4127 - val_acc: 0.8212\n",
      "Epoch 44/50\n",
      "400/712 [===============>..............] - ETA: 0s - loss: 0.3829 - acc: 0.8400Epoch 00043: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.3889 - acc: 0.8469 - val_loss: 0.4216 - val_acc: 0.8156\n",
      "Epoch 00043: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "checkpointer = ModelCheckpoint(filepath=model_weights_file, verbose=1, save_best_only=True)\n",
    "stopper = EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=10, verbose=1, mode='auto')\n",
    "hist = model.fit(X_train, y_train, epochs=50, batch_size=100, validation_split=0.2, callbacks=[checkpointer, stopper], verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891/891 [==============================] - 0s     \n",
      "\n",
      " Training Accuracy: 0.840628508165\n"
     ]
    }
   ],
   "source": [
    "# Load the weights that yielded the best validation accuracy\n",
    "model.load_weights(model_weights_file)\n",
    "\n",
    "# Evaluate the model on the training set\n",
    "score = model.evaluate(X_train, y_train)\n",
    "print(\"\\n Training Accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(418, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load test data\n",
    "df_test_raw = pd.read_csv(test_file)\n",
    "print(df_test_raw.shape)\n",
    "df_test_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before scaling: \n",
      "   PassengerId  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked  \\\n",
      "0          892       3    1  34.5      0      0   7.8292         1   \n",
      "1          893       3    0  47.0      1      0   7.0000         2   \n",
      "2          894       2    1  62.0      0      0   9.6875         1   \n",
      "3          895       3    1  27.0      0      0   8.6625         2   \n",
      "4          896       3    0  22.0      1      1  12.2875         2   \n",
      "\n",
      "   Family_Size  Fare_Per_Person   ...    Name72  Name73  Name74  Name75  \\\n",
      "0            1         7.829200   ...        32      32      32      32   \n",
      "1            2         3.500000   ...        32      32      32      32   \n",
      "2            1         9.687500   ...        32      32      32      32   \n",
      "3            1         8.662500   ...        32      32      32      32   \n",
      "4            3         4.095833   ...        32      32      32      32   \n",
      "\n",
      "   Name76  Name77  Name78  Name79  Name80  Name81  \n",
      "0      32      32      32      32      32      32  \n",
      "1      32      32      32      32      32      32  \n",
      "2      32      32      32      32      32      32  \n",
      "3      32      32      32      32      32      32  \n",
      "4      32      32      32      32      32      32  \n",
      "\n",
      "[5 rows x 92 columns]\n",
      "After scaling: \n",
      "    0    1         2      3         4         5    6    7         8   \\\n",
      "0  1.0  1.0  0.453947  0.000  0.000000  0.015282  0.5  0.0  0.029840   \n",
      "1  1.0  0.0  0.618421  0.125  0.000000  0.013663  1.0  0.1  0.013340   \n",
      "2  0.5  1.0  0.815789  0.000  0.000000  0.018909  0.5  0.0  0.036922   \n",
      "3  1.0  1.0  0.355263  0.000  0.000000  0.016908  1.0  0.0  0.033016   \n",
      "4  1.0  0.0  0.289474  0.125  0.111111  0.023984  1.0  0.2  0.015611   \n",
      "\n",
      "         9  ...    81   82   83   84   85   86   87   88   89   90  \n",
      "0  0.188679 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "1  0.415094 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2  0.226415 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "3  0.415094 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "4  0.132075 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "\n",
      "[5 rows x 91 columns]\n",
      "(418, 91)\n",
      "[ 1.          1.          0.45394737  0.          0.          0.01528158\n",
      "  0.5         0.          0.02983973  0.18867925  0.75609756  0.85393256\n",
      "  0.84444445  0.98888886  0.13333334  0.          0.5         0.94252872\n",
      "  0.15555556  0.          0.49411765  0.74712646  0.89534885  0.77528089\n",
      "  0.9222222   0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "# Prepare the data for testing\n",
    "df_test = prep_data(df_test_raw)\n",
    "X_test = np.array(df_test)[:,:]\n",
    "X_test = X_test.astype('float32')\n",
    "print(X_test.shape)\n",
    "print(X_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.86104864  0.21974753]\n"
     ]
    }
   ],
   "source": [
    "# Predict for test data\n",
    "y_test = model.predict(X_test)\n",
    "print(y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions\n",
    "with open(pred_file, 'w') as f:\n",
    "    f.write('PassengerId,Survived\\n')\n",
    "    for index, y_hat in enumerate(y_test):\n",
    "        prediction = np.argmax(y_hat)\n",
    "        f.write(str(df_test_raw.iloc[index]['PassengerId']) + ',' + str(prediction)+'\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
