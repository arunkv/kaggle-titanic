{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training and test data files\n",
    "train_file = '../input/train.csv'\n",
    "test_file = '../input/test.csv'\n",
    "model_file = '../output/titanic.model.json'\n",
    "model_weights_file = '../output/titanic.model.best.hdf5'\n",
    "pred_file = '../output/gender_submission.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 12)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load training data\n",
    "df_train = pd.read_csv(train_file)\n",
    "print(df_train.shape)\n",
    "df_train.info()\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 2)\n",
      "[[ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]]\n"
     ]
    }
   ],
   "source": [
    "# Extract survived data as predictions: 0 = Died, 1 = Survived\n",
    "from keras.utils.np_utils import to_categorical\n",
    "y_train = to_categorical(df_train[\"Survived\"], 2)\n",
    "df_train.pop('Survived')\n",
    "print(y_train.shape)\n",
    "print(y_train[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prepare the rest of the data for training\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "max_name_len = df_train.Name.map(len).max()\n",
    "max_ticket_len = df_train.Ticket.map(len).max()\n",
    "\n",
    "title_list=['Mrs', 'Mr', 'Master', 'Miss', 'Major', 'Rev', 'Dr', 'Ms', 'Mlle',\n",
    "            'Col', 'Capt', 'Mme', 'Countess', 'Don', 'Jonkheer']\n",
    "\n",
    "import string\n",
    "def substrings_in_string(big_string, substrings):\n",
    "    for substring in substrings:\n",
    "        if substring in big_string:\n",
    "            return substring\n",
    "    return np.nan\n",
    "\n",
    "def prep_data(frame):\n",
    "    # Fill missing Age data with median \n",
    "    frame['Age'] = frame['Age'].fillna(frame['Age'].median())\n",
    "    \n",
    "    # Generate data about whether adult or minor\n",
    "    frame['Adult_Or_Minor'] = frame.apply(lambda row: 0 if row['Age'] < 18 else 1, axis=1)\n",
    "\n",
    "    # Fill missing Fare data with median\n",
    "    frame['Fare'] = frame['Fare'].fillna(frame['Fare'].median())\n",
    "    \n",
    "    # Creating new family_size and fare per person columns \n",
    "    frame['Family_Size'] = frame['SibSp'] + frame['Parch'] + 1\n",
    "    frame['Fare_Per_Person'] = frame['Fare']/frame['Family_Size']\n",
    "\n",
    "    # Convert Sex and Embarked to number\n",
    "    frame['Sex'] = pd.Categorical(frame['Sex']).codes\n",
    "    frame['Age'] = frame['Age'].fillna('S')\n",
    "    frame['Embarked'] = pd.Categorical(frame['Embarked']).codes\n",
    "    \n",
    "    # Extract title from name\n",
    "    frame['Title'] = frame['Name'].map(lambda x: substrings_in_string(x, title_list))\n",
    "    frame['Title'] = pd.Categorical(frame['Title']).codes\n",
    "\n",
    "    # Convert Name into characters\n",
    "    frame['Name_Length'] = frame.apply(lambda row: len(row['Name']), axis=1)\n",
    "    for i in range(0, max_name_len):\n",
    "        col_name = 'Name' + str(i)\n",
    "        frame[col_name] = frame['Name'].str[i]\n",
    "        frame[col_name] = frame.apply(lambda row: 0 if isinstance(row[col_name], float) and math.isnan(row[col_name]) else ord(row[col_name]), axis=1)\n",
    "    frame.pop('Name')    \n",
    "    \n",
    "    # Convert Ticket into characters\n",
    "    frame['Ticket_Length'] = frame.apply(lambda row: len(row['Ticket']), axis=1)\n",
    "    for i in range(0, max_ticket_len):\n",
    "        col_name = 'Ticket' + str(i)\n",
    "        frame[col_name] = frame['Ticket'].str[i]\n",
    "        frame[col_name] = frame.apply(lambda row: 0 if isinstance(row[col_name], float) and math.isnan(row[col_name]) else ord(row[col_name]), axis=1)\n",
    "    frame.pop('Ticket')    \n",
    "    \n",
    "    # Convert Cabin column to whether in cabin\n",
    "    frame['Cabin'] = frame['Age'].fillna(0)\n",
    "    frame['In_Cabin'] = frame.apply(lambda row: 1 if row['Cabin'] != 0 else 0, axis=1)\n",
    "    frame.pop('Cabin')\n",
    "    \n",
    "    frame.fillna(0, axis=1)\n",
    "    \n",
    "    print(\"Before scaling: \")\n",
    "    print(frame.head())\n",
    "    \n",
    "    # Scale everything except PassengerId\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    col_list = frame.columns.tolist()\n",
    "    col_list.remove('PassengerId')\n",
    "    frame = frame[col_list]\n",
    "    np_scaled = min_max_scaler.fit_transform(frame)\n",
    "    frame = pd.DataFrame(np_scaled)\n",
    "    \n",
    "    print(\"After scaling: \")\n",
    "    print(frame.head())\n",
    "\n",
    "    return frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before scaling: \n",
      "   PassengerId  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked  \\\n",
      "0            1       3    1  22.0      1      0   7.2500         2   \n",
      "1            2       1    0  38.0      1      0  71.2833         0   \n",
      "2            3       3    0  26.0      0      0   7.9250         2   \n",
      "3            4       1    0  35.0      1      0  53.1000         2   \n",
      "4            5       3    1  35.0      0      0   8.0500         2   \n",
      "\n",
      "   Adult_Or_Minor  Family_Size    ...     Ticket9  Ticket10  Ticket11  \\\n",
      "0               1            2    ...           0         0         0   \n",
      "1               1            2    ...           0         0         0   \n",
      "2               1            1    ...          51        49        48   \n",
      "3               1            2    ...           0         0         0   \n",
      "4               1            1    ...           0         0         0   \n",
      "\n",
      "   Ticket12  Ticket13  Ticket14  Ticket15  Ticket16  Ticket17  In_Cabin  \n",
      "0         0         0         0         0         0         0         1  \n",
      "1         0         0         0         0         0         0         1  \n",
      "2        49        50        56        50         0         0         1  \n",
      "3         0         0         0         0         0         0         1  \n",
      "4         0         0         0         0         0         0         1  \n",
      "\n",
      "[5 rows x 115 columns]\n",
      "After scaling: \n",
      "   0    1         2      3    4         5         6    7    8         9    \\\n",
      "0  1.0  1.0  0.271174  0.125  0.0  0.014151  1.000000  1.0  0.1  0.007076   \n",
      "1  0.0  0.0  0.472229  0.125  0.0  0.139136  0.333333  1.0  0.1  0.069568   \n",
      "2  1.0  0.0  0.321438  0.000  0.0  0.015469  1.000000  1.0  0.0  0.015469   \n",
      "3  0.0  0.0  0.434531  0.125  0.0  0.103644  1.000000  1.0  0.1  0.051822   \n",
      "4  1.0  1.0  0.434531  0.000  0.0  0.015713  1.000000  1.0  0.0  0.015713   \n",
      "\n",
      "  ...        104       105       106       107       108       109       110  \\\n",
      "0 ...   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "1 ...   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "2 ...   0.472222  0.485149  0.842105  0.859649  0.877193  0.982456  0.877193   \n",
      "3 ...   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "4 ...   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "\n",
      "   111  112  113  \n",
      "0  0.0  0.0  0.0  \n",
      "1  0.0  0.0  0.0  \n",
      "2  0.0  0.0  0.0  \n",
      "3  0.0  0.0  0.0  \n",
      "4  0.0  0.0  0.0  \n",
      "\n",
      "[5 rows x 114 columns]\n",
      "(891, 114)\n",
      "[ 1.          1.          0.27117366  0.125       0.          0.01415106\n",
      "  1.          1.          0.1         0.00707553  0.78571427  0.15714286\n",
      "  0.01886792  0.91463417  0.72222221  0.94444442  0.86666667  0.75555557\n",
      "  0.13483146  0.          0.50561798  0.95348835  0.15730338  0.\n",
      "  0.66386557  0.9834711   0.82786888  0.90909094  0.26229507  0.59016395\n",
      "  0.79508197  0.93442625  0.93442625  0.86065573  0.95041323  0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.40000001  0.42105263  0.23076923  0.38181818  0.40000001\n",
      "  0.51546389  0.42982456  0.46666667  0.47826087  0.42608696  0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.        ]\n"
     ]
    }
   ],
   "source": [
    "# Prepare the rest of the data for training\n",
    "df_train = prep_data(df_train)\n",
    "X_train = np.array(df_train)[:,:]\n",
    "X_train = X_train.astype('float32')\n",
    "print(X_train.shape)\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_53 (Dense)             (None, 891)               102465    \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 891)               0         \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 445)               396940    \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 445)               0         \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 2)                 892       \n",
      "=================================================================\n",
      "Total params: 500,297\n",
      "Trainable params: 500,297\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build a training network\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, RepeatVector, Flatten, Activation\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(891, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(445, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model_json = model.to_json()\n",
    "with open(model_file, 'w') as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/1000\n",
      "645/712 [==========================>...] - ETA: 0s - loss: 0.6867 - acc: 0.5256Epoch 00000: val_loss improved from inf to 0.64533, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 1s - loss: 0.6868 - acc: 0.5281 - val_loss: 0.6453 - val_acc: 0.6425\n",
      "Epoch 2/1000\n",
      "690/712 [============================>.] - ETA: 0s - loss: 0.6511 - acc: 0.6188Epoch 00001: val_loss improved from 0.64533 to 0.61108, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.6479 - acc: 0.6250 - val_loss: 0.6111 - val_acc: 0.6425\n",
      "Epoch 3/1000\n",
      "630/712 [=========================>....] - ETA: 0s - loss: 0.6294 - acc: 0.6365Epoch 00002: val_loss improved from 0.61108 to 0.58730, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.6290 - acc: 0.6334 - val_loss: 0.5873 - val_acc: 0.7207\n",
      "Epoch 4/1000\n",
      "615/712 [========================>.....] - ETA: 0s - loss: 0.5972 - acc: 0.6846Epoch 00003: val_loss improved from 0.58730 to 0.56342, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.5947 - acc: 0.6868 - val_loss: 0.5634 - val_acc: 0.7598\n",
      "Epoch 5/1000\n",
      "630/712 [=========================>....] - ETA: 0s - loss: 0.5693 - acc: 0.7159Epoch 00004: val_loss improved from 0.56342 to 0.53882, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.5763 - acc: 0.7051 - val_loss: 0.5388 - val_acc: 0.7765\n",
      "Epoch 6/1000\n",
      "675/712 [===========================>..] - ETA: 0s - loss: 0.5577 - acc: 0.7081Epoch 00005: val_loss improved from 0.53882 to 0.51947, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.5575 - acc: 0.7107 - val_loss: 0.5195 - val_acc: 0.7821\n",
      "Epoch 7/1000\n",
      "705/712 [============================>.] - ETA: 0s - loss: 0.5538 - acc: 0.7191Epoch 00006: val_loss improved from 0.51947 to 0.50969, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.5529 - acc: 0.7219 - val_loss: 0.5097 - val_acc: 0.7598\n",
      "Epoch 8/1000\n",
      "705/712 [============================>.] - ETA: 0s - loss: 0.5331 - acc: 0.7447Epoch 00007: val_loss improved from 0.50969 to 0.49745, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.5330 - acc: 0.7430 - val_loss: 0.4975 - val_acc: 0.7765\n",
      "Epoch 9/1000\n",
      "690/712 [============================>.] - ETA: 0s - loss: 0.5249 - acc: 0.7406Epoch 00008: val_loss improved from 0.49745 to 0.48079, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.5210 - acc: 0.7444 - val_loss: 0.4808 - val_acc: 0.7989\n",
      "Epoch 10/1000\n",
      "660/712 [==========================>...] - ETA: 0s - loss: 0.5079 - acc: 0.7621Epoch 00009: val_loss improved from 0.48079 to 0.47748, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.5138 - acc: 0.7570 - val_loss: 0.4775 - val_acc: 0.7765\n",
      "Epoch 11/1000\n",
      "645/712 [==========================>...] - ETA: 0s - loss: 0.5169 - acc: 0.7705Epoch 00010: val_loss improved from 0.47748 to 0.46375, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.5120 - acc: 0.7711 - val_loss: 0.4637 - val_acc: 0.8045\n",
      "Epoch 12/1000\n",
      "690/712 [============================>.] - ETA: 0s - loss: 0.4972 - acc: 0.7710Epoch 00011: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.5009 - acc: 0.7654 - val_loss: 0.4674 - val_acc: 0.7877\n",
      "Epoch 13/1000\n",
      "690/712 [============================>.] - ETA: 0s - loss: 0.5012 - acc: 0.7797Epoch 00012: val_loss improved from 0.46375 to 0.45103, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.4980 - acc: 0.7837 - val_loss: 0.4510 - val_acc: 0.7877\n",
      "Epoch 14/1000\n",
      "705/712 [============================>.] - ETA: 0s - loss: 0.4865 - acc: 0.7844Epoch 00013: val_loss improved from 0.45103 to 0.45022, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.4855 - acc: 0.7865 - val_loss: 0.4502 - val_acc: 0.7933\n",
      "Epoch 15/1000\n",
      "705/712 [============================>.] - ETA: 0s - loss: 0.4837 - acc: 0.7816Epoch 00014: val_loss improved from 0.45022 to 0.44473, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.4827 - acc: 0.7809 - val_loss: 0.4447 - val_acc: 0.7877\n",
      "Epoch 16/1000\n",
      "660/712 [==========================>...] - ETA: 0s - loss: 0.4782 - acc: 0.7848Epoch 00015: val_loss improved from 0.44473 to 0.44042, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.4757 - acc: 0.7851 - val_loss: 0.4404 - val_acc: 0.7933\n",
      "Epoch 17/1000\n",
      "705/712 [============================>.] - ETA: 0s - loss: 0.4765 - acc: 0.7801Epoch 00016: val_loss improved from 0.44042 to 0.43204, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.4757 - acc: 0.7809 - val_loss: 0.4320 - val_acc: 0.8045\n",
      "Epoch 18/1000\n",
      "675/712 [===========================>..] - ETA: 0s - loss: 0.4641 - acc: 0.8000Epoch 00017: val_loss improved from 0.43204 to 0.43004, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.4655 - acc: 0.7978 - val_loss: 0.4300 - val_acc: 0.8101\n",
      "Epoch 19/1000\n",
      "615/712 [========================>.....] - ETA: 0s - loss: 0.4647 - acc: 0.8000Epoch 00018: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4668 - acc: 0.7992 - val_loss: 0.4346 - val_acc: 0.7933\n",
      "Epoch 20/1000\n",
      "645/712 [==========================>...] - ETA: 0s - loss: 0.4494 - acc: 0.8062Epoch 00019: val_loss improved from 0.43004 to 0.42773, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.4570 - acc: 0.7978 - val_loss: 0.4277 - val_acc: 0.8156\n",
      "Epoch 21/1000\n",
      "675/712 [===========================>..] - ETA: 0s - loss: 0.4725 - acc: 0.7941Epoch 00020: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4689 - acc: 0.7978 - val_loss: 0.4287 - val_acc: 0.8045\n",
      "Epoch 22/1000\n",
      "660/712 [==========================>...] - ETA: 0s - loss: 0.4491 - acc: 0.8091Epoch 00021: val_loss improved from 0.42773 to 0.42009, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.4583 - acc: 0.8034 - val_loss: 0.4201 - val_acc: 0.8101\n",
      "Epoch 23/1000\n",
      "645/712 [==========================>...] - ETA: 0s - loss: 0.4606 - acc: 0.7969Epoch 00022: val_loss improved from 0.42009 to 0.41890, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.4551 - acc: 0.7992 - val_loss: 0.4189 - val_acc: 0.8156\n",
      "Epoch 24/1000\n",
      "660/712 [==========================>...] - ETA: 0s - loss: 0.4420 - acc: 0.8015Epoch 00023: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4462 - acc: 0.7978 - val_loss: 0.4270 - val_acc: 0.7933\n",
      "Epoch 25/1000\n",
      "660/712 [==========================>...] - ETA: 0s - loss: 0.4453 - acc: 0.7879Epoch 00024: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4428 - acc: 0.7935 - val_loss: 0.4294 - val_acc: 0.7989\n",
      "Epoch 26/1000\n",
      "660/712 [==========================>...] - ETA: 0s - loss: 0.4438 - acc: 0.8045Epoch 00025: val_loss improved from 0.41890 to 0.41745, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.4447 - acc: 0.8048 - val_loss: 0.4174 - val_acc: 0.8156\n",
      "Epoch 27/1000\n",
      "705/712 [============================>.] - ETA: 0s - loss: 0.4367 - acc: 0.8142Epoch 00026: val_loss improved from 0.41745 to 0.41247, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.4421 - acc: 0.8118 - val_loss: 0.4125 - val_acc: 0.8101\n",
      "Epoch 28/1000\n",
      "645/712 [==========================>...] - ETA: 0s - loss: 0.4396 - acc: 0.8062Epoch 00027: val_loss did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s - loss: 0.4307 - acc: 0.8104 - val_loss: 0.4129 - val_acc: 0.8156\n",
      "Epoch 29/1000\n",
      "645/712 [==========================>...] - ETA: 0s - loss: 0.4397 - acc: 0.8062Epoch 00028: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4388 - acc: 0.8034 - val_loss: 0.4229 - val_acc: 0.8268\n",
      "Epoch 30/1000\n",
      "705/712 [============================>.] - ETA: 0s - loss: 0.4290 - acc: 0.8099Epoch 00029: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4272 - acc: 0.8104 - val_loss: 0.4128 - val_acc: 0.8101\n",
      "Epoch 31/1000\n",
      "705/712 [============================>.] - ETA: 0s - loss: 0.4365 - acc: 0.8142Epoch 00030: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4368 - acc: 0.8132 - val_loss: 0.4164 - val_acc: 0.7989\n",
      "Epoch 32/1000\n",
      "630/712 [=========================>....] - ETA: 0s - loss: 0.4361 - acc: 0.8111- ETA: 0s - loss: 0.3951 - acc: 0.Epoch 00031: val_loss improved from 0.41247 to 0.41073, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.4331 - acc: 0.8146 - val_loss: 0.4107 - val_acc: 0.8101\n",
      "Epoch 33/1000\n",
      "690/712 [============================>.] - ETA: 0s - loss: 0.4339 - acc: 0.8087Epoch 00032: val_loss improved from 0.41073 to 0.40970, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.4350 - acc: 0.8118 - val_loss: 0.4097 - val_acc: 0.8101\n",
      "Epoch 34/1000\n",
      "675/712 [===========================>..] - ETA: 0s - loss: 0.4285 - acc: 0.8148Epoch 00033: val_loss improved from 0.40970 to 0.40913, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.4285 - acc: 0.8146 - val_loss: 0.4091 - val_acc: 0.8101\n",
      "Epoch 35/1000\n",
      "660/712 [==========================>...] - ETA: 0s - loss: 0.4183 - acc: 0.8242Epoch 00034: val_loss improved from 0.40913 to 0.40867, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.4311 - acc: 0.8188 - val_loss: 0.4087 - val_acc: 0.8101\n",
      "Epoch 36/1000\n",
      "645/712 [==========================>...] - ETA: 0s - loss: 0.4052 - acc: 0.8217Epoch 00035: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4220 - acc: 0.8118 - val_loss: 0.4101 - val_acc: 0.8101\n",
      "Epoch 37/1000\n",
      "615/712 [========================>.....] - ETA: 0s - loss: 0.4349 - acc: 0.8081Epoch 00036: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4327 - acc: 0.8076 - val_loss: 0.4184 - val_acc: 0.8156\n",
      "Epoch 38/1000\n",
      "615/712 [========================>.....] - ETA: 0s - loss: 0.4114 - acc: 0.8146Epoch 00037: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4279 - acc: 0.8090 - val_loss: 0.4090 - val_acc: 0.8156\n",
      "Epoch 39/1000\n",
      "630/712 [=========================>....] - ETA: 0s - loss: 0.4339 - acc: 0.8032Epoch 00038: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4230 - acc: 0.8118 - val_loss: 0.4119 - val_acc: 0.8212\n",
      "Epoch 40/1000\n",
      "690/712 [============================>.] - ETA: 0s - loss: 0.4309 - acc: 0.8188Epoch 00039: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4313 - acc: 0.8160 - val_loss: 0.4130 - val_acc: 0.8212\n",
      "Epoch 41/1000\n",
      "675/712 [===========================>..] - ETA: 0s - loss: 0.4164 - acc: 0.8237Epoch 00040: val_loss improved from 0.40867 to 0.40606, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.4261 - acc: 0.8174 - val_loss: 0.4061 - val_acc: 0.8156\n",
      "Epoch 42/1000\n",
      "645/712 [==========================>...] - ETA: 0s - loss: 0.4297 - acc: 0.8155Epoch 00041: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4222 - acc: 0.8174 - val_loss: 0.4079 - val_acc: 0.8156\n",
      "Epoch 43/1000\n",
      "705/712 [============================>.] - ETA: 0s - loss: 0.4065 - acc: 0.8255Epoch 00042: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4057 - acc: 0.8258 - val_loss: 0.4069 - val_acc: 0.8156\n",
      "Epoch 44/1000\n",
      "675/712 [===========================>..] - ETA: 0s - loss: 0.4166 - acc: 0.8193Epoch 00043: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4127 - acc: 0.8230 - val_loss: 0.4090 - val_acc: 0.8268\n",
      "Epoch 45/1000\n",
      "645/712 [==========================>...] - ETA: 0s - loss: 0.4066 - acc: 0.8248Epoch 00044: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4135 - acc: 0.8244 - val_loss: 0.4070 - val_acc: 0.8156\n",
      "Epoch 46/1000\n",
      "660/712 [==========================>...] - ETA: 0s - loss: 0.4133 - acc: 0.8167Epoch 00045: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4166 - acc: 0.8132 - val_loss: 0.4061 - val_acc: 0.8156\n",
      "Epoch 47/1000\n",
      "675/712 [===========================>..] - ETA: 0s - loss: 0.4088 - acc: 0.8311Epoch 00046: val_loss improved from 0.40606 to 0.40368, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.4099 - acc: 0.8301 - val_loss: 0.4037 - val_acc: 0.8156\n",
      "Epoch 48/1000\n",
      "660/712 [==========================>...] - ETA: 0s - loss: 0.4107 - acc: 0.8197Epoch 00047: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4117 - acc: 0.8174 - val_loss: 0.4041 - val_acc: 0.8156\n",
      "Epoch 49/1000\n",
      "675/712 [===========================>..] - ETA: 0s - loss: 0.4054 - acc: 0.8178Epoch 00048: val_loss improved from 0.40368 to 0.40241, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.4086 - acc: 0.8160 - val_loss: 0.4024 - val_acc: 0.8101\n",
      "Epoch 50/1000\n",
      "690/712 [============================>.] - ETA: 0s - loss: 0.4022 - acc: 0.8290Epoch 00049: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4114 - acc: 0.8244 - val_loss: 0.4035 - val_acc: 0.8212\n",
      "Epoch 51/1000\n",
      "690/712 [============================>.] - ETA: 0s - loss: 0.4146 - acc: 0.8130Epoch 00050: val_loss improved from 0.40241 to 0.40204, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.4109 - acc: 0.8146 - val_loss: 0.4020 - val_acc: 0.8101\n",
      "Epoch 52/1000\n",
      "675/712 [===========================>..] - ETA: 0s - loss: 0.4158 - acc: 0.8222Epoch 00051: val_loss improved from 0.40204 to 0.40115, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.4164 - acc: 0.8216 - val_loss: 0.4011 - val_acc: 0.8156\n",
      "Epoch 53/1000\n",
      "630/712 [=========================>....] - ETA: 0s - loss: 0.4021 - acc: 0.8333Epoch 00052: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4063 - acc: 0.8315 - val_loss: 0.4019 - val_acc: 0.8212\n",
      "Epoch 54/1000\n",
      "630/712 [=========================>....] - ETA: 0s - loss: 0.4006 - acc: 0.8286Epoch 00053: val_loss improved from 0.40115 to 0.40082, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.4061 - acc: 0.8230 - val_loss: 0.4008 - val_acc: 0.8101\n",
      "Epoch 55/1000\n",
      "675/712 [===========================>..] - ETA: 0s - loss: 0.4079 - acc: 0.8222Epoch 00054: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4038 - acc: 0.8244 - val_loss: 0.4052 - val_acc: 0.8268\n",
      "Epoch 56/1000\n",
      "645/712 [==========================>...] - ETA: 0s - loss: 0.3962 - acc: 0.8465Epoch 00055: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.3962 - acc: 0.8441 - val_loss: 0.4100 - val_acc: 0.8324\n",
      "Epoch 57/1000\n",
      "660/712 [==========================>...] - ETA: 0s - loss: 0.3986 - acc: 0.8227Epoch 00056: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.3970 - acc: 0.8258 - val_loss: 0.4016 - val_acc: 0.8268\n",
      "Epoch 58/1000\n",
      "690/712 [============================>.] - ETA: 0s - loss: 0.3868 - acc: 0.8246Epoch 00057: val_loss improved from 0.40082 to 0.40005, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.3840 - acc: 0.8258 - val_loss: 0.4000 - val_acc: 0.8324\n",
      "Epoch 59/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "675/712 [===========================>..] - ETA: 0s - loss: 0.4049 - acc: 0.8356Epoch 00058: val_loss improved from 0.40005 to 0.39971, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.4021 - acc: 0.8371 - val_loss: 0.3997 - val_acc: 0.8156\n",
      "Epoch 60/1000\n",
      "630/712 [=========================>....] - ETA: 0s - loss: 0.3969 - acc: 0.8317Epoch 00059: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.3866 - acc: 0.8385 - val_loss: 0.4032 - val_acc: 0.8268\n",
      "Epoch 61/1000\n",
      "630/712 [=========================>....] - ETA: 0s - loss: 0.3786 - acc: 0.8317Epoch 00060: val_loss improved from 0.39971 to 0.39896, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.3858 - acc: 0.8301 - val_loss: 0.3990 - val_acc: 0.8212\n",
      "Epoch 62/1000\n",
      "705/712 [============================>.] - ETA: 0s - loss: 0.4022 - acc: 0.8340Epoch 00061: val_loss improved from 0.39896 to 0.39880, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.4020 - acc: 0.8329 - val_loss: 0.3988 - val_acc: 0.8212\n",
      "Epoch 63/1000\n",
      "660/712 [==========================>...] - ETA: 0s - loss: 0.3946 - acc: 0.8258Epoch 00062: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4005 - acc: 0.8230 - val_loss: 0.4001 - val_acc: 0.8324\n",
      "Epoch 64/1000\n",
      "675/712 [===========================>..] - ETA: 0s - loss: 0.3886 - acc: 0.8400Epoch 00063: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.3915 - acc: 0.8385 - val_loss: 0.4009 - val_acc: 0.8268\n",
      "Epoch 65/1000\n",
      "660/712 [==========================>...] - ETA: 0s - loss: 0.3940 - acc: 0.8258Epoch 00064: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.3895 - acc: 0.8301 - val_loss: 0.4065 - val_acc: 0.8324\n",
      "Epoch 66/1000\n",
      "690/712 [============================>.] - ETA: 0s - loss: 0.3970 - acc: 0.8275Epoch 00065: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.3931 - acc: 0.8315 - val_loss: 0.3989 - val_acc: 0.8212\n",
      "Epoch 67/1000\n",
      "675/712 [===========================>..] - ETA: 0s - loss: 0.3925 - acc: 0.8370Epoch 00066: val_loss improved from 0.39880 to 0.39787, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.3897 - acc: 0.8385 - val_loss: 0.3979 - val_acc: 0.8212\n",
      "Epoch 68/1000\n",
      "705/712 [============================>.] - ETA: 0s - loss: 0.3847 - acc: 0.8312Epoch 00067: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.3838 - acc: 0.8329 - val_loss: 0.3989 - val_acc: 0.8156\n",
      "Epoch 69/1000\n",
      "630/712 [=========================>....] - ETA: 0s - loss: 0.3937 - acc: 0.8317Epoch 00068: val_loss improved from 0.39787 to 0.39766, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.3838 - acc: 0.8385 - val_loss: 0.3977 - val_acc: 0.8212\n",
      "Epoch 70/1000\n",
      "660/712 [==========================>...] - ETA: 0s - loss: 0.3844 - acc: 0.8348Epoch 00069: val_loss improved from 0.39766 to 0.39574, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.3823 - acc: 0.8343 - val_loss: 0.3957 - val_acc: 0.8212\n",
      "Epoch 71/1000\n",
      "690/712 [============================>.] - ETA: 0s - loss: 0.3635 - acc: 0.8391Epoch 00070: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.3795 - acc: 0.8329 - val_loss: 0.4022 - val_acc: 0.8324\n",
      "Epoch 72/1000\n",
      "675/712 [===========================>..] - ETA: 0s - loss: 0.3865 - acc: 0.8415Epoch 00071: val_loss improved from 0.39574 to 0.39508, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.3813 - acc: 0.8441 - val_loss: 0.3951 - val_acc: 0.8212\n",
      "Epoch 73/1000\n",
      "645/712 [==========================>...] - ETA: 0s - loss: 0.3847 - acc: 0.8496Epoch 00072: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.3737 - acc: 0.8567 - val_loss: 0.4034 - val_acc: 0.8324\n",
      "Epoch 74/1000\n",
      "705/712 [============================>.] - ETA: 0s - loss: 0.3689 - acc: 0.8525Epoch 00073: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.3761 - acc: 0.8483 - val_loss: 0.4181 - val_acc: 0.8212\n",
      "Epoch 75/1000\n",
      "675/712 [===========================>..] - ETA: 0s - loss: 0.3629 - acc: 0.8444Epoch 00074: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.3695 - acc: 0.8399 - val_loss: 0.3978 - val_acc: 0.8212\n",
      "Epoch 76/1000\n",
      "660/712 [==========================>...] - ETA: 0s - loss: 0.3556 - acc: 0.8470Epoch 00075: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.3673 - acc: 0.8427 - val_loss: 0.4265 - val_acc: 0.8156\n",
      "Epoch 77/1000\n",
      "630/712 [=========================>....] - ETA: 0s - loss: 0.3804 - acc: 0.8492Epoch 00076: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.3794 - acc: 0.8511 - val_loss: 0.3970 - val_acc: 0.8324\n",
      "Epoch 78/1000\n",
      "675/712 [===========================>..] - ETA: 0s - loss: 0.3617 - acc: 0.8533Epoch 00077: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.3577 - acc: 0.8525 - val_loss: 0.4002 - val_acc: 0.8156\n",
      "Epoch 79/1000\n",
      "630/712 [=========================>....] - ETA: 0s - loss: 0.3663 - acc: 0.8508Epoch 00078: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.3714 - acc: 0.8483 - val_loss: 0.4009 - val_acc: 0.8268\n",
      "Epoch 80/1000\n",
      "630/712 [=========================>....] - ETA: 0s - loss: 0.3774 - acc: 0.8460Epoch 00079: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.3718 - acc: 0.8497 - val_loss: 0.3962 - val_acc: 0.8324\n",
      "Epoch 81/1000\n",
      "675/712 [===========================>..] - ETA: 0s - loss: 0.3610 - acc: 0.8563Epoch 00080: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.3650 - acc: 0.8539 - val_loss: 0.3983 - val_acc: 0.8156\n",
      "Epoch 82/1000\n",
      "705/712 [============================>.] - ETA: 0s - loss: 0.3727 - acc: 0.8411Epoch 00081: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.3711 - acc: 0.8427 - val_loss: 0.4034 - val_acc: 0.8101\n",
      "Epoch 83/1000\n",
      "690/712 [============================>.] - ETA: 0s - loss: 0.3717 - acc: 0.8377Epoch 00082: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.3709 - acc: 0.8385 - val_loss: 0.3972 - val_acc: 0.8268\n",
      "Epoch 00082: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "checkpointer = ModelCheckpoint(filepath=model_weights_file, verbose=1, save_best_only=True)\n",
    "stopper = EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=10, verbose=1, mode='auto')\n",
    "hist = model.fit(X_train, y_train, epochs=1000, batch_size=15, validation_split=0.2,\n",
    "                 callbacks=[checkpointer, stopper], \n",
    "                 verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "672/891 [=====================>........] - ETA: 0s\n",
      "Training Accuracy: 0.84960718381\n"
     ]
    }
   ],
   "source": [
    "# Load the weights that yielded the best validation accuracy\n",
    "model.load_weights(model_weights_file)\n",
    "\n",
    "# Evaluate the model on the training set\n",
    "score = model.evaluate(X_train, y_train)\n",
    "print(\"\\nTraining Accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(418, 11)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      "PassengerId    418 non-null int64\n",
      "Pclass         418 non-null int64\n",
      "Name           418 non-null object\n",
      "Sex            418 non-null object\n",
      "Age            332 non-null float64\n",
      "SibSp          418 non-null int64\n",
      "Parch          418 non-null int64\n",
      "Ticket         418 non-null object\n",
      "Fare           417 non-null float64\n",
      "Cabin          91 non-null object\n",
      "Embarked       418 non-null object\n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# Load test data\n",
    "df_test_raw = pd.read_csv(test_file)\n",
    "print(df_test_raw.shape)\n",
    "df_test_raw.head()\n",
    "df_test_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before scaling: \n",
      "   PassengerId  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked  \\\n",
      "0          892       3    1  34.5      0      0   7.8292         1   \n",
      "1          893       3    0  47.0      1      0   7.0000         2   \n",
      "2          894       2    1  62.0      0      0   9.6875         1   \n",
      "3          895       3    1  27.0      0      0   8.6625         2   \n",
      "4          896       3    0  22.0      1      1  12.2875         2   \n",
      "\n",
      "   Adult_Or_Minor  Family_Size    ...     Ticket9  Ticket10  Ticket11  \\\n",
      "0               1            1    ...           0         0         0   \n",
      "1               1            2    ...           0         0         0   \n",
      "2               1            1    ...           0         0         0   \n",
      "3               1            1    ...           0         0         0   \n",
      "4               1            3    ...           0         0         0   \n",
      "\n",
      "   Ticket12  Ticket13  Ticket14  Ticket15  Ticket16  Ticket17  In_Cabin  \n",
      "0         0         0         0         0         0         0         1  \n",
      "1         0         0         0         0         0         0         1  \n",
      "2         0         0         0         0         0         0         1  \n",
      "3         0         0         0         0         0         0         1  \n",
      "4         0         0         0         0         0         0         1  \n",
      "\n",
      "[5 rows x 115 columns]\n",
      "After scaling: \n",
      "   0    1         2      3         4         5    6    7    8         9    \\\n",
      "0  1.0  1.0  0.452723  0.000  0.000000  0.015282  0.5  1.0  0.0  0.029840   \n",
      "1  1.0  0.0  0.617566  0.125  0.000000  0.013663  1.0  1.0  0.1  0.013340   \n",
      "2  0.5  1.0  0.815377  0.000  0.000000  0.018909  0.5  1.0  0.0  0.036922   \n",
      "3  1.0  1.0  0.353818  0.000  0.000000  0.016908  1.0  1.0  0.0  0.033016   \n",
      "4  1.0  0.0  0.287881  0.125  0.111111  0.023984  1.0  1.0  0.2  0.015611   \n",
      "\n",
      "  ...   104  105  106  107  108  109  110  111  112  113  \n",
      "0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "1 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "3 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "4 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "\n",
      "[5 rows x 114 columns]\n",
      "(418, 114)\n",
      "[ 1.          1.          0.45272321  0.          0.          0.01528158\n",
      "  0.5         1.          0.          0.02983973  0.625       0.06\n",
      "  0.18867925  0.75609756  0.85393256  0.84444445  0.98888886  0.13333334\n",
      "  0.          0.5         0.94252872  0.15555556  0.          0.49411765\n",
      "  0.74712646  0.92372882  0.83471072  0.94262296  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.2         0.05263158  0.36538461  0.30769232  0.71249998  0.50515461\n",
      "  0.42982456  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "# Prepare the data for testing\n",
    "df_test = prep_data(df_test_raw)\n",
    "X_test = np.array(df_test)[:,:]\n",
    "X_test = X_test.astype('float32')\n",
    "print(X_test.shape)\n",
    "print(X_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.34917012  0.04882123]\n"
     ]
    }
   ],
   "source": [
    "# Predict for test data\n",
    "y_test = model.predict(X_test)\n",
    "print(y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save predictions\n",
    "with open(pred_file, 'w') as f:\n",
    "    f.write('PassengerId,Survived\\n')\n",
    "    for index, y_hat in enumerate(y_test):\n",
    "        prediction = np.argmax(y_hat)\n",
    "        f.write(str(int(df_test_raw.iloc[index]['PassengerId'])) + ',' + str(prediction)+'\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
