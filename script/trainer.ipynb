{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training and test data files\n",
    "train_file = '../input/train.csv'\n",
    "test_file = '../input/test.csv'\n",
    "model_file = '../output/titanic.model.json'\n",
    "model_weights_file = '../output/titanic.model.best.hdf5'\n",
    "pred_file = '../output/gender_submission.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load training data\n",
    "df_train = pd.read_csv(train_file)\n",
    "print(df_train.shape)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 2)\n",
      "[[ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]]\n"
     ]
    }
   ],
   "source": [
    "# Extract survived data as predictions: 0 = Died, 1 = Survived\n",
    "from keras.utils.np_utils import to_categorical\n",
    "y_train = to_categorical(df_train[\"Survived\"], 2)\n",
    "df_train.pop('Survived')\n",
    "print(y_train.shape)\n",
    "print(y_train[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the rest of the data for training\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "max_name_len = df_train.Name.map(len).max()    \n",
    "\n",
    "title_list=['Mrs', 'Mr', 'Master', 'Miss', 'Major', 'Rev', 'Dr', 'Ms', 'Mlle',\n",
    "            'Col', 'Capt', 'Mme', 'Countess', 'Don', 'Jonkheer']\n",
    "\n",
    "import string\n",
    "def substrings_in_string(big_string, substrings):\n",
    "    for substring in substrings:\n",
    "        if substring in big_string:\n",
    "            return substring\n",
    "    return np.nan\n",
    "\n",
    "def prep_data(frame):\n",
    "    frame = frame.fillna(0)\n",
    "\n",
    "    # Creating new family_size and fare per person columns \n",
    "    frame['Family_Size'] = frame['SibSp'] + frame['Parch'] + 1\n",
    "    frame['Fare_Per_Person'] = frame['Fare']/frame['Family_Size']\n",
    "\n",
    "    # Convert Sex and Embarked to number\n",
    "    frame['Sex'] = pd.Categorical(frame['Sex']).codes\n",
    "    frame['Embarked'] = pd.Categorical(frame['Embarked']).codes\n",
    "    \n",
    "    # Extract title from name\n",
    "    frame['Title'] = frame['Name'].map(lambda x: substrings_in_string(x, title_list))\n",
    "    frame['Title'] = pd.Categorical(frame['Title']).codes\n",
    "\n",
    "    # Convert Name into characters\n",
    "    frame['Name_Length'] = frame.apply(lambda row: len(row['Name']), axis=1)\n",
    "#    for i in range(0, max_name_len):\n",
    "#        col_name = 'Name' + str(i)\n",
    "#        frame[col_name] = frame['Name'].str[i]\n",
    "#        frame[col_name] = frame.apply(lambda row: ord(' ') if isinstance(row[col_name], float) and math.isnan(row[col_name]) else ord(row[col_name]), axis=1)\n",
    "    frame.pop('Name')\n",
    "\n",
    "    \n",
    "    \n",
    "    # TODO: Ignore Ticket for now\n",
    "    frame.pop('Ticket')\n",
    "    \n",
    "    # Convert Cabin column to whether in cabin\n",
    "    frame['In_Cabin'] = frame.apply(lambda row: 1 if row['Cabin'] != 0 else 0, axis=1)\n",
    "    frame.pop('Cabin')\n",
    "    \n",
    "    print(\"Before scaling: \")\n",
    "    print(frame.head())\n",
    "    \n",
    "    # Scale everything except PassengerId\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    col_list = frame.columns.tolist()\n",
    "    col_list.remove('PassengerId')\n",
    "    frame = frame[col_list]\n",
    "    np_scaled = min_max_scaler.fit_transform(frame)\n",
    "    frame = pd.DataFrame(np_scaled)\n",
    "    \n",
    "    print(\"After scaling: \")\n",
    "    print(frame.head())\n",
    "\n",
    "    return frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before scaling: \n",
      "   PassengerId  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked  \\\n",
      "0            1       3    1  22.0      1      0   7.2500         3   \n",
      "1            2       1    0  38.0      1      0  71.2833         1   \n",
      "2            3       3    0  26.0      0      0   7.9250         3   \n",
      "3            4       1    0  35.0      1      0  53.1000         3   \n",
      "4            5       3    1  35.0      0      0   8.0500         3   \n",
      "\n",
      "   Family_Size  Fare_Per_Person  Title  Name_Length  In_Cabin  \n",
      "0            2          3.62500     11           23         0  \n",
      "1            2         35.64165     12           51         1  \n",
      "2            1          7.92500      8           22         0  \n",
      "3            2         26.55000     12           44         1  \n",
      "4            1          8.05000     11           24         0  \n",
      "After scaling: \n",
      "    0    1       2      3    4         5         6    7         8         9   \\\n",
      "0  1.0  1.0  0.2750  0.125  0.0  0.014151  1.000000  0.1  0.007076  0.785714   \n",
      "1  0.0  0.0  0.4750  0.125  0.0  0.139136  0.333333  0.1  0.069568  0.857143   \n",
      "2  1.0  0.0  0.3250  0.000  0.0  0.015469  1.000000  0.0  0.015469  0.571429   \n",
      "3  0.0  0.0  0.4375  0.125  0.0  0.103644  1.000000  0.1  0.051822  0.857143   \n",
      "4  1.0  1.0  0.4375  0.000  0.0  0.015713  1.000000  0.0  0.015713  0.785714   \n",
      "\n",
      "         10   11  \n",
      "0  0.157143  0.0  \n",
      "1  0.557143  1.0  \n",
      "2  0.142857  0.0  \n",
      "3  0.457143  1.0  \n",
      "4  0.171429  0.0  \n",
      "(891, 12)\n",
      "[ 1.          1.          0.27500001  0.125       0.          0.01415106\n",
      "  1.          0.1         0.00707553  0.78571427  0.15714286  0.        ]\n"
     ]
    }
   ],
   "source": [
    "# Prepare the rest of the data for training\n",
    "df_train = prep_data(df_train)\n",
    "X_train = np.array(df_train)[:,:]\n",
    "X_train = X_train.astype('float32')\n",
    "print(X_train.shape)\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_23 (Dense)             (None, 512)               6656      \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 795,394\n",
      "Trainable params: 795,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build a training network\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(X_train.shape[1], )))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/1000\n",
      "700/712 [============================>.] - ETA: 0s - loss: 0.5550 - acc: 0.7214Epoch 00000: val_loss improved from inf to 0.40748, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 2s - loss: 0.5577 - acc: 0.7219 - val_loss: 0.4075 - val_acc: 0.8324\n",
      "Epoch 2/1000\n",
      "710/712 [============================>.] - ETA: 0s - loss: 0.4852 - acc: 0.7972Epoch 00001: val_loss did not improve\n",
      "712/712 [==============================] - 1s - loss: 0.4950 - acc: 0.7949 - val_loss: 0.5569 - val_acc: 0.7654\n",
      "Epoch 3/1000\n",
      "690/712 [============================>.] - ETA: 0s - loss: 0.4801 - acc: 0.7841Epoch 00002: val_loss did not improve\n",
      "712/712 [==============================] - 1s - loss: 0.4851 - acc: 0.7795 - val_loss: 0.4256 - val_acc: 0.8436\n",
      "Epoch 4/1000\n",
      "710/712 [============================>.] - ETA: 0s - loss: 0.4807 - acc: 0.7915Epoch 00003: val_loss did not improve\n",
      "712/712 [==============================] - 1s - loss: 0.4824 - acc: 0.7907 - val_loss: 0.5839 - val_acc: 0.8045\n",
      "Epoch 5/1000\n",
      "690/712 [============================>.] - ETA: 0s - loss: 0.4745 - acc: 0.7986Epoch 00004: val_loss improved from 0.40748 to 0.38741, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 1s - loss: 0.4733 - acc: 0.7992 - val_loss: 0.3874 - val_acc: 0.8324\n",
      "Epoch 6/1000\n",
      "690/712 [============================>.] - ETA: 0s - loss: 0.4789 - acc: 0.8072Epoch 00005: val_loss did not improve\n",
      "712/712 [==============================] - 1s - loss: 0.4851 - acc: 0.8062 - val_loss: 0.3925 - val_acc: 0.8380\n",
      "Epoch 7/1000\n",
      "710/712 [============================>.] - ETA: 0s - loss: 0.4693 - acc: 0.8070Epoch 00006: val_loss did not improve\n",
      "712/712 [==============================] - 1s - loss: 0.4685 - acc: 0.8076 - val_loss: 0.3878 - val_acc: 0.8436\n",
      "Epoch 8/1000\n",
      "690/712 [============================>.] - ETA: 0s - loss: 0.4634 - acc: 0.8174Epoch 00007: val_loss improved from 0.38741 to 0.37825, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 1s - loss: 0.4626 - acc: 0.8174 - val_loss: 0.3782 - val_acc: 0.8324\n",
      "Epoch 9/1000\n",
      "690/712 [============================>.] - ETA: 0s - loss: 0.4771 - acc: 0.8029Epoch 00008: val_loss did not improve\n",
      "712/712 [==============================] - 1s - loss: 0.4697 - acc: 0.8048 - val_loss: 0.5087 - val_acc: 0.8156\n",
      "Epoch 10/1000\n",
      "680/712 [===========================>..] - ETA: 0s - loss: 0.4492 - acc: 0.8265Epoch 00009: val_loss improved from 0.37825 to 0.36914, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 1s - loss: 0.4476 - acc: 0.8258 - val_loss: 0.3691 - val_acc: 0.8436\n",
      "Epoch 11/1000\n",
      "690/712 [============================>.] - ETA: 0s - loss: 0.4413 - acc: 0.8174Epoch 00010: val_loss did not improve\n",
      "712/712 [==============================] - 1s - loss: 0.4457 - acc: 0.8132 - val_loss: 0.3785 - val_acc: 0.8659\n",
      "Epoch 12/1000\n",
      "700/712 [============================>.] - ETA: 0s - loss: 0.4518 - acc: 0.8243Epoch 00011: val_loss did not improve\n",
      "712/712 [==============================] - 1s - loss: 0.4516 - acc: 0.8244 - val_loss: 0.3878 - val_acc: 0.8603\n",
      "Epoch 13/1000\n",
      "700/712 [============================>.] - ETA: 0s - loss: 0.4454 - acc: 0.8114- ETA: 0s - loss: 0.4475 - acc: 0.810Epoch 00012: val_loss improved from 0.36914 to 0.36253, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 1s - loss: 0.4462 - acc: 0.8090 - val_loss: 0.3625 - val_acc: 0.8436\n",
      "Epoch 14/1000\n",
      "690/712 [============================>.] - ETA: 0s - loss: 0.4457 - acc: 0.8261Epoch 00013: val_loss did not improve\n",
      "712/712 [==============================] - 1s - loss: 0.4436 - acc: 0.8258 - val_loss: 0.4051 - val_acc: 0.8492\n",
      "Epoch 15/1000\n",
      "700/712 [============================>.] - ETA: 0s - loss: 0.4407 - acc: 0.8171Epoch 00014: val_loss did not improve\n",
      "712/712 [==============================] - 2s - loss: 0.4364 - acc: 0.8188 - val_loss: 0.6165 - val_acc: 0.8436\n",
      "Epoch 16/1000\n",
      "670/712 [===========================>..] - ETA: 0s - loss: 0.4456 - acc: 0.8239Epoch 00015: val_loss did not improve\n",
      "712/712 [==============================] - 1s - loss: 0.4434 - acc: 0.8230 - val_loss: 0.4917 - val_acc: 0.8324\n",
      "Epoch 17/1000\n",
      "710/712 [============================>.] - ETA: 0s - loss: 0.4587 - acc: 0.8169Epoch 00016: val_loss did not improve\n",
      "712/712 [==============================] - 1s - loss: 0.4582 - acc: 0.8174 - val_loss: 0.3990 - val_acc: 0.8324\n",
      "Epoch 18/1000\n",
      "700/712 [============================>.] - ETA: 0s - loss: 0.4414 - acc: 0.8200Epoch 00017: val_loss did not improve\n",
      "712/712 [==============================] - 1s - loss: 0.4421 - acc: 0.8188 - val_loss: 0.3764 - val_acc: 0.8603\n",
      "Epoch 19/1000\n",
      "700/712 [============================>.] - ETA: 0s - loss: 0.4398 - acc: 0.8186Epoch 00018: val_loss did not improve\n",
      "712/712 [==============================] - 1s - loss: 0.4373 - acc: 0.8202 - val_loss: 0.3996 - val_acc: 0.8547\n",
      "Epoch 20/1000\n",
      "690/712 [============================>.] - ETA: 0s - loss: 0.4222 - acc: 0.8246Epoch 00019: val_loss improved from 0.36253 to 0.35623, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 1s - loss: 0.4304 - acc: 0.8216 - val_loss: 0.3562 - val_acc: 0.8324\n",
      "Epoch 21/1000\n",
      "680/712 [===========================>..] - ETA: 0s - loss: 0.4152 - acc: 0.8368Epoch 00020: val_loss did not improve\n",
      "712/712 [==============================] - 1s - loss: 0.4354 - acc: 0.8329 - val_loss: 0.3909 - val_acc: 0.8659\n",
      "Epoch 22/1000\n",
      "710/712 [============================>.] - ETA: 0s - loss: 0.4295 - acc: 0.8296Epoch 00021: val_loss did not improve\n",
      "712/712 [==============================] - 1s - loss: 0.4286 - acc: 0.8301 - val_loss: 0.3600 - val_acc: 0.8436\n",
      "Epoch 23/1000\n",
      "690/712 [============================>.] - ETA: 0s - loss: 0.4574 - acc: 0.8232Epoch 00022: val_loss did not improve\n",
      "712/712 [==============================] - 1s - loss: 0.4523 - acc: 0.8244 - val_loss: 0.6316 - val_acc: 0.8380\n",
      "Epoch 24/1000\n",
      "700/712 [============================>.] - ETA: 0s - loss: 0.4656 - acc: 0.8314Epoch 00023: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4627 - acc: 0.8329 - val_loss: 0.4046 - val_acc: 0.8436\n",
      "Epoch 25/1000\n",
      "670/712 [===========================>..] - ETA: 0s - loss: 0.4688 - acc: 0.8224Epoch 00024: val_loss did not improve\n",
      "712/712 [==============================] - 1s - loss: 0.4667 - acc: 0.8244 - val_loss: 0.4327 - val_acc: 0.8101\n",
      "Epoch 26/1000\n",
      "710/712 [============================>.] - ETA: 0s - loss: 0.4171 - acc: 0.8366Epoch 00025: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4178 - acc: 0.8357 - val_loss: 0.4256 - val_acc: 0.8547\n",
      "Epoch 27/1000\n",
      "680/712 [===========================>..] - ETA: 0s - loss: 0.4255 - acc: 0.8338Epoch 00026: val_loss did not improve\n",
      "712/712 [==============================] - 1s - loss: 0.4272 - acc: 0.8343 - val_loss: 0.5659 - val_acc: 0.8268\n",
      "Epoch 28/1000\n",
      "690/712 [============================>.] - ETA: 0s - loss: 0.4580 - acc: 0.8290Epoch 00027: val_loss did not improve\n",
      "712/712 [==============================] - 1s - loss: 0.4565 - acc: 0.8301 - val_loss: 0.4660 - val_acc: 0.8268\n",
      "Epoch 29/1000\n",
      "690/712 [============================>.] - ETA: 0s - loss: 0.4612 - acc: 0.8290Epoch 00028: val_loss did not improve\n",
      "712/712 [==============================] - 1s - loss: 0.4549 - acc: 0.8315 - val_loss: 0.5525 - val_acc: 0.8715\n",
      "Epoch 30/1000\n",
      "700/712 [============================>.] - ETA: 0s - loss: 0.4190 - acc: 0.8257Epoch 00029: val_loss did not improve\n",
      "712/712 [==============================] - 1s - loss: 0.4195 - acc: 0.8244 - val_loss: 0.6811 - val_acc: 0.8101\n",
      "Epoch 31/1000\n",
      "710/712 [============================>.] - ETA: 0s - loss: 0.4699 - acc: 0.8113Epoch 00030: val_loss did not improve\n",
      "712/712 [==============================] - 1s - loss: 0.4687 - acc: 0.8118 - val_loss: 0.5659 - val_acc: 0.8380\n",
      "Epoch 00030: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "checkpointer = ModelCheckpoint(filepath=model_weights_file, verbose=1, save_best_only=True)\n",
    "stopper = EarlyStopping(monitor='val_loss', min_delta=1e-5, patience=10, verbose=1, mode='auto')\n",
    "hist = model.fit(X_train, y_train, epochs=1000, batch_size=10, validation_split=0.2, \n",
    "                 callbacks=[checkpointer, stopper], \n",
    "                 verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891/891 [==============================] - 0s     \n",
      "\n",
      " Training Accuracy: 0.839506173709\n"
     ]
    }
   ],
   "source": [
    "# Load the weights that yielded the best validation accuracy\n",
    "model.load_weights(model_weights_file)\n",
    "\n",
    "# Evaluate the model on the training set\n",
    "score = model.evaluate(X_train, y_train)\n",
    "print(\"\\n Training Accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(418, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load test data\n",
    "df_test_raw = pd.read_csv(test_file)\n",
    "print(df_test_raw.shape)\n",
    "df_test_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before scaling: \n",
      "   PassengerId  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked  \\\n",
      "0          892       3    1  34.5      0      0   7.8292         1   \n",
      "1          893       3    0  47.0      1      0   7.0000         2   \n",
      "2          894       2    1  62.0      0      0   9.6875         1   \n",
      "3          895       3    1  27.0      0      0   8.6625         2   \n",
      "4          896       3    0  22.0      1      1  12.2875         2   \n",
      "\n",
      "   Family_Size  Fare_Per_Person  Title  Name_Length  In_Cabin  \n",
      "0            1         7.829200      5           16         0  \n",
      "1            2         3.500000      6           32         0  \n",
      "2            1         9.687500      5           25         0  \n",
      "3            1         8.662500      5           16         0  \n",
      "4            3         4.095833      6           44         0  \n",
      "After scaling: \n",
      "    0    1         2      3         4         5    6    7         8      9   \\\n",
      "0  1.0  1.0  0.453947  0.000  0.000000  0.015282  0.5  0.0  0.029840  0.625   \n",
      "1  1.0  0.0  0.618421  0.125  0.000000  0.013663  1.0  0.1  0.013340  0.750   \n",
      "2  0.5  1.0  0.815789  0.000  0.000000  0.018909  0.5  0.0  0.036922  0.625   \n",
      "3  1.0  1.0  0.355263  0.000  0.000000  0.016908  1.0  0.0  0.033016  0.625   \n",
      "4  1.0  0.0  0.289474  0.125  0.111111  0.023984  1.0  0.2  0.015611  0.750   \n",
      "\n",
      "     10   11  \n",
      "0  0.06  0.0  \n",
      "1  0.38  0.0  \n",
      "2  0.24  0.0  \n",
      "3  0.06  0.0  \n",
      "4  0.62  0.0  \n",
      "(418, 12)\n",
      "[ 1.          1.          0.45394737  0.          0.          0.01528158\n",
      "  0.5         0.          0.02983973  0.625       0.06        0.        ]\n"
     ]
    }
   ],
   "source": [
    "# Prepare the data for testing\n",
    "df_test = prep_data(df_test_raw)\n",
    "X_test = np.array(df_test)[:,:]\n",
    "X_test = X_test.astype('float32')\n",
    "print(X_test.shape)\n",
    "print(X_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99957401  0.06453325]\n"
     ]
    }
   ],
   "source": [
    "# Predict for test data\n",
    "y_test = model.predict(X_test)\n",
    "print(y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save predictions\n",
    "with open(pred_file, 'w') as f:\n",
    "    f.write('PassengerId,Survived\\n')\n",
    "    for index, y_hat in enumerate(y_test):\n",
    "        prediction = np.argmax(y_hat)\n",
    "        f.write(str(df_test_raw.iloc[index]['PassengerId']) + ',' + str(prediction)+'\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
