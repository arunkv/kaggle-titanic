{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training and test data files\n",
    "train_file = '../input/train.csv'\n",
    "test_file = '../input/test.csv'\n",
    "model_file = '../output/titanic.model.json'\n",
    "model_weights_file = '../output/titanic.model.best.hdf5'\n",
    "pred_file = '../output/gender_submission.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 12)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load training data\n",
    "df_train_raw = pd.read_csv(train_file)\n",
    "print(df_train_raw.shape)\n",
    "df_train_raw.info()\n",
    "df_train_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prepare the data for training and testing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "max_name_len = df_train_raw.Name.map(len).max()\n",
    "max_ticket_len = df_train_raw.Ticket.map(len).max()\n",
    "\n",
    "title_list=['Mrs', 'Mr', 'Master', 'Miss', 'Major', 'Rev', 'Dr', 'Ms', 'Mlle',\n",
    "            'Col', 'Capt', 'Mme', 'Countess', 'Don', 'Jonkheer']\n",
    "\n",
    "import string\n",
    "def substrings_in_string(big_string, substrings):\n",
    "    for substring in substrings:\n",
    "        if substring in big_string:\n",
    "            return substring\n",
    "    return np.nan\n",
    "\n",
    "def prep_data(frame, mode='test'):\n",
    "    # Fill missing Age data with median \n",
    "    frame['Age'] = frame['Age'].fillna(frame['Age'].mean())\n",
    "    \n",
    "    # Generate data about whether adult or minor\n",
    "    frame['Adult_Or_Minor'] = frame.apply(lambda row: 0 if row['Age'] < 18 else 1, axis=1)\n",
    "\n",
    "    # Generate data about whether senior citizen\n",
    "    frame['Senior_Citizen'] = frame.apply(lambda row: 0 if row['Age'] > 65 else 1, axis=1)\n",
    "\n",
    "    # Fill missing Fare data with median\n",
    "    frame['Fare'] = frame['Fare'].fillna(frame['Fare'].median())\n",
    "    \n",
    "    # Creating new family_size and fare per person columns \n",
    "    frame['Family_Size'] = frame['SibSp'] + frame['Parch'] + 1\n",
    "    frame['Alone'] = frame.apply(lambda row: 1 if row['Family_Size'] == 1 else 0, axis=1)\n",
    "    frame['Fare_Per_Person'] = frame['Fare']/frame['Family_Size']\n",
    "\n",
    "    # Convert Sex to number\n",
    "    frame['Sex'] = pd.Categorical(frame['Sex']).codes\n",
    "\n",
    "    # Generate data for missing Embarked and convert to number\n",
    "    frame['Embarked'] = frame['Embarked'].fillna('X')\n",
    "    frame['Embarked'] = pd.Categorical(frame['Embarked']).codes\n",
    "    \n",
    "    # Extract title from name\n",
    "    frame['Title'] = frame['Name'].map(lambda x: substrings_in_string(x, title_list))\n",
    "    frame['Title'] = pd.Categorical(frame['Title']).codes\n",
    "\n",
    "    # Convert Name into characters\n",
    "    frame['Name_Length'] = frame.apply(lambda row: len(row['Name']), axis=1)\n",
    "    frame['Words_In_Name'] = frame.apply(lambda row: len(row['Name'].split()), axis=1)    \n",
    "#    for i in range(0, max_name_len):\n",
    "#        col_name = 'Name' + str(i)\n",
    "#        frame[col_name] = frame['Name'].str[i]\n",
    "#        frame[col_name] = frame.apply(lambda row: 0 if isinstance(row[col_name], float) and math.isnan(row[col_name]) else ord(row[col_name]), axis=1)\n",
    "    frame.pop('Name')    \n",
    "    \n",
    "    # Convert Ticket into characters\n",
    "    frame['Ticket_Length'] = frame.apply(lambda row: len(row['Ticket']), axis=1)\n",
    "#    for i in range(0, max_ticket_len):\n",
    "#        col_name = 'Ticket' + str(i)\n",
    "#        frame[col_name] = frame['Ticket'].str[i]\n",
    "#        frame[col_name] = frame.apply(lambda row: 0 if isinstance(row[col_name], float) and math.isnan(row[col_name]) else ord(row[col_name]), axis=1)\n",
    "    frame.pop('Ticket')    \n",
    "    \n",
    "    # Convert Cabin column to whether in cabin\n",
    "    frame['Cabin'] = frame['Cabin'].fillna('')\n",
    "    frame['In_Cabin'] = frame.apply(lambda row: 1 if row['Cabin'] != '' else 0, axis=1)\n",
    "    frame['Number_Of_Cabins'] = frame.apply(lambda row: len(row['Cabin'].split()), axis=1)    \n",
    "    frame.pop('Cabin')\n",
    "    \n",
    "    frame.fillna(0, axis=1)\n",
    "    \n",
    "    # Introduce rows with some noise\n",
    "    if (mode == 'augment'):\n",
    "        print('Adding more rows to training data')\n",
    "        row_count = frame.shape[0]\n",
    "        print('Row count before: ', row_count)\n",
    "        col_std = np.std(frame) \n",
    "        for i in range(0, row_count):\n",
    "            rand = np.random.random_sample()\n",
    "            if rand < 0.11:\n",
    "                row1 = pd.Series(frame.iloc[i])\n",
    "                row2 = pd.Series(frame.iloc[i])\n",
    "                col_list = frame.columns.tolist()\n",
    "                col_list.remove('PassengerId')\n",
    "                col_list.remove('Survived')\n",
    "                for col in frame.columns.tolist():\n",
    "                    row1[col] = row1[col] + rand * col_std[col]\n",
    "                    row2[col] = row2[col] - rand * col_std[col]\n",
    "                frame = frame.append(row1)\n",
    "                frame = frame.append(row2)\n",
    "        row_count = frame.shape[0]\n",
    "        print('Row count after: ', row_count)\n",
    "    \n",
    "    \n",
    "    print(\"Before scaling: \")\n",
    "    print(frame.head())\n",
    "    \n",
    "    # Scale everything except PassengerId\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    col_list = frame.columns.tolist()\n",
    "    col_list.remove('PassengerId')\n",
    "    frame = frame[col_list]\n",
    "    np_scaled = min_max_scaler.fit_transform(frame)\n",
    "    frame = pd.DataFrame(np_scaled)\n",
    "    \n",
    "    print(\"After scaling: \")\n",
    "    print(frame.head())\n",
    "\n",
    "    return frame\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding more rows to training data\n",
      "Row count before:  891\n",
      "Row count after:  1099\n",
      "Before scaling: \n",
      "   PassengerId  Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked  \\\n",
      "0          1.0       0.0     3.0  1.0  22.0    1.0    0.0   7.2500       2.0   \n",
      "1          2.0       1.0     1.0  0.0  38.0    1.0    0.0  71.2833       0.0   \n",
      "2          3.0       1.0     3.0  0.0  26.0    0.0    0.0   7.9250       2.0   \n",
      "3          4.0       1.0     1.0  0.0  35.0    1.0    0.0  53.1000       2.0   \n",
      "4          5.0       0.0     3.0  1.0  35.0    0.0    0.0   8.0500       2.0   \n",
      "\n",
      "   Adult_Or_Minor  Senior_Citizen  Family_Size  Alone  Fare_Per_Person  Title  \\\n",
      "0             1.0             1.0          2.0    0.0          3.62500   11.0   \n",
      "1             1.0             1.0          2.0    0.0         35.64165   12.0   \n",
      "2             1.0             1.0          1.0    1.0          7.92500    8.0   \n",
      "3             1.0             1.0          2.0    0.0         26.55000   12.0   \n",
      "4             1.0             1.0          1.0    1.0          8.05000   11.0   \n",
      "\n",
      "   Name_Length  Words_In_Name  Ticket_Length  In_Cabin  Number_Of_Cabins  \n",
      "0         23.0            4.0            9.0       0.0               0.0  \n",
      "1         51.0            7.0            8.0       1.0               1.0  \n",
      "2         22.0            3.0           16.0       0.0               0.0  \n",
      "3         44.0            7.0            6.0       1.0               1.0  \n",
      "4         24.0            4.0            6.0       0.0               0.0  \n",
      "After scaling: \n",
      "         0             1         2         3      4    5         6         7   \\\n",
      "0  0.024133  9.791964e-01  0.976284  0.271174  0.125  0.0  0.014151  0.666667   \n",
      "1  1.000000  5.551115e-17  0.000000  0.472229  0.125  0.0  0.139136  0.000000   \n",
      "2  1.000000  9.791964e-01  0.000000  0.321438  0.000  0.0  0.015469  0.666667   \n",
      "3  1.000000  5.551115e-17  0.000000  0.434531  0.125  0.0  0.103644  0.666667   \n",
      "4  0.024133  9.791964e-01  0.976284  0.434531  0.000  0.0  0.015713  0.666667   \n",
      "\n",
      "    8         9             10        11        12        13        14  \\\n",
      "0  1.0  0.995226  1.000000e-01  0.024279  0.007076  0.785714  0.157143   \n",
      "1  1.0  0.995226  1.000000e-01  0.024279  0.069568  0.857143  0.557143   \n",
      "2  1.0  0.995226  1.387779e-17  1.000000  0.015469  0.571429  0.142857   \n",
      "3  1.0  0.995226  1.000000e-01  0.024279  0.051822  0.857143  0.457143   \n",
      "4  1.0  0.995226  1.387779e-17  1.000000  0.015713  0.785714  0.171429   \n",
      "\n",
      "         15        16        17        18  \n",
      "0  0.090909  0.400000  0.020919  0.006904  \n",
      "1  0.363636  0.333333  1.000000  0.255178  \n",
      "2  0.000000  0.866667  0.020919  0.006904  \n",
      "3  0.363636  0.200000  1.000000  0.255178  \n",
      "4  0.090909  0.200000  0.020919  0.006904  \n",
      "(1099, 18)\n",
      "[ 0.97919643  0.97628355  0.27117366  0.125       0.          0.01415106\n",
      "  0.66666669  1.          0.99522614  0.1         0.02427924  0.00707553\n",
      "  0.78571427  0.15714286  0.09090909  0.40000001  0.02091862  0.00690367]\n"
     ]
    }
   ],
   "source": [
    "# Prep training data\n",
    "df_train = prep_data(df_train_raw, mode='augment')\n",
    "\n",
    "# Construct the X array\n",
    "X_train = np.array(df_train)[:,1:]\n",
    "X_train = X_train.astype('float32')\n",
    "print(X_train.shape)\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1099, 2)\n",
      "[[ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]]\n"
     ]
    }
   ],
   "source": [
    "# Extract survived data as predictions\n",
    "from keras.utils.np_utils import to_categorical\n",
    "y_train = np.array(df_train)[:,0]\n",
    "y_train = y_train.astype('int')\n",
    "y_train = to_categorical(y_train, 2)\n",
    "print(y_train.shape)\n",
    "print(y_train[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(418, 11)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      "PassengerId    418 non-null int64\n",
      "Pclass         418 non-null int64\n",
      "Name           418 non-null object\n",
      "Sex            418 non-null object\n",
      "Age            332 non-null float64\n",
      "SibSp          418 non-null int64\n",
      "Parch          418 non-null int64\n",
      "Ticket         418 non-null object\n",
      "Fare           417 non-null float64\n",
      "Cabin          91 non-null object\n",
      "Embarked       418 non-null object\n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# Load test data\n",
    "df_test_raw = pd.read_csv(test_file)\n",
    "print(df_test_raw.shape)\n",
    "df_test_raw.head()\n",
    "df_test_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before scaling: \n",
      "   PassengerId  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked  \\\n",
      "0          892       3    1  34.5      0      0   7.8292         1   \n",
      "1          893       3    0  47.0      1      0   7.0000         2   \n",
      "2          894       2    1  62.0      0      0   9.6875         1   \n",
      "3          895       3    1  27.0      0      0   8.6625         2   \n",
      "4          896       3    0  22.0      1      1  12.2875         2   \n",
      "\n",
      "   Adult_Or_Minor  Senior_Citizen  Family_Size  Alone  Fare_Per_Person  Title  \\\n",
      "0               1               1            1      1         7.829200      5   \n",
      "1               1               1            2      0         3.500000      6   \n",
      "2               1               1            1      1         9.687500      5   \n",
      "3               1               1            1      1         8.662500      5   \n",
      "4               1               1            3      0         4.095833      6   \n",
      "\n",
      "   Name_Length  Words_In_Name  Ticket_Length  In_Cabin  Number_Of_Cabins  \n",
      "0           16              3              6         0                 0  \n",
      "1           32              5              6         0                 0  \n",
      "2           25              4              6         0                 0  \n",
      "3           16              3              6         0                 0  \n",
      "4           44              6              7         0                 0  \n",
      "After scaling: \n",
      "    0    1         2      3         4         5    6    7    8    9    10  \\\n",
      "0  1.0  1.0  0.452723  0.000  0.000000  0.015282  0.5  1.0  1.0  0.0  1.0   \n",
      "1  1.0  0.0  0.617566  0.125  0.000000  0.013663  1.0  1.0  1.0  0.1  0.0   \n",
      "2  0.5  1.0  0.815377  0.000  0.000000  0.018909  0.5  1.0  1.0  0.0  1.0   \n",
      "3  1.0  1.0  0.353818  0.000  0.000000  0.016908  1.0  1.0  1.0  0.0  1.0   \n",
      "4  1.0  0.0  0.287881  0.125  0.111111  0.023984  1.0  1.0  1.0  0.2  0.0   \n",
      "\n",
      "         11     12    13   14        15   16   17  \n",
      "0  0.029840  0.625  0.06  0.0  0.200000  0.0  0.0  \n",
      "1  0.013340  0.750  0.38  0.4  0.200000  0.0  0.0  \n",
      "2  0.036922  0.625  0.24  0.2  0.200000  0.0  0.0  \n",
      "3  0.033016  0.625  0.06  0.0  0.200000  0.0  0.0  \n",
      "4  0.015611  0.750  0.62  0.6  0.266667  0.0  0.0  \n",
      "(418, 18)\n",
      "[ 1.          1.          0.45272321  0.          0.          0.01528158\n",
      "  0.5         1.          1.          0.          1.          0.02983973\n",
      "  0.625       0.06        0.          0.2         0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "# Prepare the data for testing\n",
    "df_test = prep_data(df_test_raw)\n",
    "\n",
    "# Construct the X array\n",
    "X_test = np.array(df_test)[:,:]\n",
    "X_test = X_test.astype('float32')\n",
    "print(X_test.shape)\n",
    "print(X_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 891)               16929     \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 891)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 445)               396940    \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 445)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 222)               99012     \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 222)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 2)                 446       \n",
      "=================================================================\n",
      "Total params: 513,327\n",
      "Trainable params: 513,327\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build a training network\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, RepeatVector, Flatten, Activation\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(891, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(445, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(222, activation='relu'))\n",
    "model.add(Dropout(0.75))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model_json = model.to_json()\n",
    "with open(model_file, 'w') as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 769 samples, validate on 330 samples\n",
      "Epoch 1/200\n",
      "700/769 [==========================>...] - ETA: 0s - loss: 0.6112 - acc: 0.6379Epoch 00000: val_loss improved from inf to 0.48209, saving model to ../output/titanic.model.best.hdf5\n",
      "769/769 [==============================] - 1s - loss: 0.6083 - acc: 0.6443 - val_loss: 0.4821 - val_acc: 0.7424\n",
      "Epoch 2/200\n",
      "740/769 [===========================>..] - ETA: 0s - loss: 0.5302 - acc: 0.7723Epoch 00001: val_loss improved from 0.48209 to 0.45635, saving model to ../output/titanic.model.best.hdf5\n",
      "769/769 [==============================] - 0s - loss: 0.5323 - acc: 0.7718 - val_loss: 0.4563 - val_acc: 0.8076\n",
      "Epoch 3/200\n",
      "720/769 [===========================>..] - ETA: 0s - loss: 0.4966 - acc: 0.7819Epoch 00002: val_loss improved from 0.45635 to 0.45019, saving model to ../output/titanic.model.best.hdf5\n",
      "769/769 [==============================] - 0s - loss: 0.4958 - acc: 0.7809 - val_loss: 0.4502 - val_acc: 0.8000\n",
      "Epoch 4/200\n",
      "720/769 [===========================>..] - ETA: 0s - loss: 0.4867 - acc: 0.7924Epoch 00003: val_loss did not improve\n",
      "769/769 [==============================] - 0s - loss: 0.4860 - acc: 0.7913 - val_loss: 0.4564 - val_acc: 0.8242\n",
      "Epoch 5/200\n",
      "680/769 [=========================>....] - ETA: 0s - loss: 0.4572 - acc: 0.7926Epoch 00004: val_loss did not improve\n",
      "769/769 [==============================] - 0s - loss: 0.4642 - acc: 0.7887 - val_loss: 0.4601 - val_acc: 0.8121\n",
      "Epoch 6/200\n",
      "700/769 [==========================>...] - ETA: 0s - loss: 0.4693 - acc: 0.7971Epoch 00005: val_loss did not improve\n",
      "769/769 [==============================] - 0s - loss: 0.4655 - acc: 0.7978 - val_loss: 0.4880 - val_acc: 0.8182\n",
      "Epoch 7/200\n",
      "760/769 [============================>.] - ETA: 0s - loss: 0.4614 - acc: 0.8099Epoch 00006: val_loss did not improve\n",
      "769/769 [==============================] - 0s - loss: 0.4604 - acc: 0.8095 - val_loss: 0.4621 - val_acc: 0.8182\n",
      "Epoch 8/200\n",
      "720/769 [===========================>..] - ETA: 0s - loss: 0.4577 - acc: 0.8215Epoch 00007: val_loss did not improve\n",
      "769/769 [==============================] - 0s - loss: 0.4632 - acc: 0.8179 - val_loss: 0.4892 - val_acc: 0.8348\n",
      "Epoch 9/200\n",
      "700/769 [==========================>...] - ETA: 0s - loss: 0.4576 - acc: 0.8050Epoch 00008: val_loss did not improve\n",
      "769/769 [==============================] - 0s - loss: 0.4622 - acc: 0.8023 - val_loss: 0.4866 - val_acc: 0.8258\n",
      "Epoch 10/200\n",
      "700/769 [==========================>...] - ETA: 0s - loss: 0.4294 - acc: 0.8243Epoch 00009: val_loss improved from 0.45019 to 0.44375, saving model to ../output/titanic.model.best.hdf5\n",
      "769/769 [==============================] - 0s - loss: 0.4426 - acc: 0.8212 - val_loss: 0.4437 - val_acc: 0.8439\n",
      "Epoch 11/200\n",
      "720/769 [===========================>..] - ETA: 0s - loss: 0.4505 - acc: 0.8299Epoch 00010: val_loss did not improve\n",
      "769/769 [==============================] - 0s - loss: 0.4442 - acc: 0.8303 - val_loss: 0.4691 - val_acc: 0.8197\n",
      "Epoch 12/200\n",
      "760/769 [============================>.] - ETA: 0s - loss: 0.4427 - acc: 0.8066Epoch 00011: val_loss improved from 0.44375 to 0.43207, saving model to ../output/titanic.model.best.hdf5\n",
      "769/769 [==============================] - 0s - loss: 0.4404 - acc: 0.8075 - val_loss: 0.4321 - val_acc: 0.8394\n",
      "Epoch 13/200\n",
      "760/769 [============================>.] - ETA: 0s - loss: 0.4314 - acc: 0.8329Epoch 00012: val_loss did not improve\n",
      "769/769 [==============================] - 0s - loss: 0.4336 - acc: 0.8316 - val_loss: 0.5532 - val_acc: 0.7758\n",
      "Epoch 14/200\n",
      "720/769 [===========================>..] - ETA: 0s - loss: 0.4511 - acc: 0.8097Epoch 00013: val_loss did not improve\n",
      "769/769 [==============================] - 0s - loss: 0.4445 - acc: 0.8134 - val_loss: 0.4378 - val_acc: 0.8394\n",
      "Epoch 15/200\n",
      "740/769 [===========================>..] - ETA: 0s - loss: 0.4422 - acc: 0.8169Epoch 00014: val_loss did not improve\n",
      "769/769 [==============================] - 0s - loss: 0.4384 - acc: 0.8212 - val_loss: 0.4415 - val_acc: 0.8152\n",
      "Epoch 16/200\n",
      "740/769 [===========================>..] - ETA: 0s - loss: 0.4460 - acc: 0.8203Epoch 00015: val_loss improved from 0.43207 to 0.42253, saving model to ../output/titanic.model.best.hdf5\n",
      "769/769 [==============================] - 0s - loss: 0.4419 - acc: 0.8231 - val_loss: 0.4225 - val_acc: 0.8333\n",
      "Epoch 17/200\n",
      "740/769 [===========================>..] - ETA: 0s - loss: 0.4380 - acc: 0.8236Epoch 00016: val_loss did not improve\n",
      "769/769 [==============================] - 0s - loss: 0.4336 - acc: 0.8264 - val_loss: 0.4267 - val_acc: 0.8364\n",
      "Epoch 18/200\n",
      "740/769 [===========================>..] - ETA: 0s - loss: 0.4225 - acc: 0.8250Epoch 00017: val_loss did not improve\n",
      "769/769 [==============================] - 0s - loss: 0.4190 - acc: 0.8290 - val_loss: 0.4232 - val_acc: 0.8333\n",
      "Epoch 19/200\n",
      "760/769 [============================>.] - ETA: 0s - loss: 0.4167 - acc: 0.8224Epoch 00018: val_loss did not improve\n",
      "769/769 [==============================] - 0s - loss: 0.4167 - acc: 0.8218 - val_loss: 0.4297 - val_acc: 0.8500\n",
      "Epoch 20/200\n",
      "760/769 [============================>.] - ETA: 0s - loss: 0.4152 - acc: 0.8270Epoch 00019: val_loss did not improve\n",
      "769/769 [==============================] - 0s - loss: 0.4200 - acc: 0.8212 - val_loss: 0.4760 - val_acc: 0.8242\n",
      "Epoch 21/200\n",
      "760/769 [============================>.] - ETA: 0s - loss: 0.4253 - acc: 0.8263Epoch 00020: val_loss did not improve\n",
      "769/769 [==============================] - 0s - loss: 0.4255 - acc: 0.8257 - val_loss: 0.4487 - val_acc: 0.8333\n",
      "Epoch 22/200\n",
      "700/769 [==========================>...] - ETA: 0s - loss: 0.4093 - acc: 0.8171Epoch 00021: val_loss improved from 0.42253 to 0.41867, saving model to ../output/titanic.model.best.hdf5\n",
      "769/769 [==============================] - 0s - loss: 0.4155 - acc: 0.8160 - val_loss: 0.4187 - val_acc: 0.8394\n",
      "Epoch 23/200\n",
      "720/769 [===========================>..] - ETA: 0s - loss: 0.4248 - acc: 0.8160Epoch 00022: val_loss did not improve\n",
      "769/769 [==============================] - 0s - loss: 0.4096 - acc: 0.8264 - val_loss: 0.4628 - val_acc: 0.8303\n",
      "Epoch 24/200\n",
      "760/769 [============================>.] - ETA: 0s - loss: 0.4110 - acc: 0.8283Epoch 00023: val_loss improved from 0.41867 to 0.40933, saving model to ../output/titanic.model.best.hdf5\n",
      "769/769 [==============================] - 0s - loss: 0.4100 - acc: 0.8290 - val_loss: 0.4093 - val_acc: 0.8500\n",
      "Epoch 25/200\n",
      "740/769 [===========================>..] - ETA: 0s - loss: 0.4321 - acc: 0.8189Epoch 00024: val_loss did not improve\n",
      "769/769 [==============================] - 0s - loss: 0.4280 - acc: 0.8218 - val_loss: 0.4182 - val_acc: 0.8424\n",
      "Epoch 26/200\n",
      "740/769 [===========================>..] - ETA: 0s - loss: 0.4003 - acc: 0.8412Epoch 00025: val_loss did not improve\n",
      "769/769 [==============================] - 0s - loss: 0.4076 - acc: 0.8381 - val_loss: 0.4238 - val_acc: 0.8394\n",
      "Epoch 27/200\n",
      "720/769 [===========================>..] - ETA: 0s - loss: 0.4079 - acc: 0.8340Epoch 00026: val_loss improved from 0.40933 to 0.39396, saving model to ../output/titanic.model.best.hdf5\n",
      "769/769 [==============================] - 0s - loss: 0.4109 - acc: 0.8329 - val_loss: 0.3940 - val_acc: 0.8561\n",
      "Epoch 28/200\n",
      "720/769 [===========================>..] - ETA: 0s - loss: 0.4005 - acc: 0.8465Epoch 00027: val_loss did not improve\n",
      "769/769 [==============================] - 0s - loss: 0.4095 - acc: 0.8401 - val_loss: 0.4107 - val_acc: 0.8455\n",
      "Epoch 29/200\n",
      "760/769 [============================>.] - ETA: 0s - loss: 0.3974 - acc: 0.8322Epoch 00028: val_loss improved from 0.39396 to 0.39152, saving model to ../output/titanic.model.best.hdf5\n",
      "769/769 [==============================] - 0s - loss: 0.3976 - acc: 0.8316 - val_loss: 0.3915 - val_acc: 0.8500\n",
      "Epoch 30/200\n",
      "720/769 [===========================>..] - ETA: 0s - loss: 0.4072 - acc: 0.8229Epoch 00029: val_loss improved from 0.39152 to 0.39090, saving model to ../output/titanic.model.best.hdf5\n",
      "769/769 [==============================] - 0s - loss: 0.3993 - acc: 0.8277 - val_loss: 0.3909 - val_acc: 0.8455\n",
      "Epoch 31/200\n",
      "700/769 [==========================>...] - ETA: 0s - loss: 0.4116 - acc: 0.8186Epoch 00030: val_loss did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "769/769 [==============================] - 0s - loss: 0.4053 - acc: 0.8212 - val_loss: 0.4463 - val_acc: 0.8273\n",
      "Epoch 32/200\n",
      "700/769 [==========================>...] - ETA: 0s - loss: 0.3895 - acc: 0.8336Epoch 00031: val_loss improved from 0.39090 to 0.38455, saving model to ../output/titanic.model.best.hdf5\n",
      "769/769 [==============================] - 0s - loss: 0.3973 - acc: 0.8342 - val_loss: 0.3846 - val_acc: 0.8545\n",
      "Epoch 33/200\n",
      "700/769 [==========================>...] - ETA: 0s - loss: 0.4075 - acc: 0.8400Epoch 00032: val_loss did not improve\n",
      "769/769 [==============================] - 0s - loss: 0.4069 - acc: 0.8414 - val_loss: 0.4071 - val_acc: 0.8424\n",
      "Epoch 34/200\n",
      "760/769 [============================>.] - ETA: 0s - loss: 0.4200 - acc: 0.8303Epoch 00033: val_loss did not improve\n",
      "769/769 [==============================] - 0s - loss: 0.4200 - acc: 0.8309 - val_loss: 0.3923 - val_acc: 0.8394\n",
      "Epoch 35/200\n",
      "760/769 [============================>.] - ETA: 0s - loss: 0.3997 - acc: 0.8362Epoch 00034: val_loss did not improve\n",
      "769/769 [==============================] - 0s - loss: 0.3999 - acc: 0.8355 - val_loss: 0.3854 - val_acc: 0.8455\n",
      "Epoch 36/200\n",
      "760/769 [============================>.] - ETA: 0s - loss: 0.3899 - acc: 0.8362Epoch 00035: val_loss did not improve\n",
      "769/769 [==============================] - 0s - loss: 0.3932 - acc: 0.8355 - val_loss: 0.3896 - val_acc: 0.8394\n",
      "Epoch 37/200\n",
      "720/769 [===========================>..] - ETA: 0s - loss: 0.4047 - acc: 0.8306Epoch 00036: val_loss improved from 0.38455 to 0.38127, saving model to ../output/titanic.model.best.hdf5\n",
      "769/769 [==============================] - 0s - loss: 0.4045 - acc: 0.8349 - val_loss: 0.3813 - val_acc: 0.8545\n",
      "Epoch 38/200\n",
      "700/769 [==========================>...] - ETA: 0s - loss: 0.4017 - acc: 0.8243Epoch 00037: val_loss did not improve\n",
      "769/769 [==============================] - 0s - loss: 0.3934 - acc: 0.8257 - val_loss: 0.4022 - val_acc: 0.8364\n",
      "Epoch 39/200\n",
      "760/769 [============================>.] - ETA: 0s - loss: 0.3859 - acc: 0.8401Epoch 00038: val_loss did not improve\n",
      "769/769 [==============================] - 0s - loss: 0.3922 - acc: 0.8355 - val_loss: 0.3827 - val_acc: 0.8561\n",
      "Epoch 40/200\n",
      "760/769 [============================>.] - ETA: 0s - loss: 0.3896 - acc: 0.8408Epoch 00039: val_loss did not improve\n",
      "769/769 [==============================] - 0s - loss: 0.3875 - acc: 0.8414 - val_loss: 0.3847 - val_acc: 0.8424\n",
      "Epoch 41/200\n",
      "720/769 [===========================>..] - ETA: 0s - loss: 0.3873 - acc: 0.8354Epoch 00040: val_loss did not improve\n",
      "769/769 [==============================] - 0s - loss: 0.3863 - acc: 0.8349 - val_loss: 0.3874 - val_acc: 0.8545\n",
      "Epoch 42/200\n",
      "740/769 [===========================>..] - ETA: 0s - loss: 0.3726 - acc: 0.8378Epoch 00041: val_loss did not improve\n",
      "769/769 [==============================] - 0s - loss: 0.3782 - acc: 0.8349 - val_loss: 0.3919 - val_acc: 0.8485\n",
      "Epoch 43/200\n",
      "720/769 [===========================>..] - ETA: 0s - loss: 0.3946 - acc: 0.8368Epoch 00042: val_loss improved from 0.38127 to 0.36778, saving model to ../output/titanic.model.best.hdf5\n",
      "769/769 [==============================] - 0s - loss: 0.3979 - acc: 0.8355 - val_loss: 0.3678 - val_acc: 0.8530\n",
      "Epoch 44/200\n",
      "700/769 [==========================>...] - ETA: 0s - loss: 0.4110 - acc: 0.8150Epoch 00043: val_loss did not improve\n",
      "769/769 [==============================] - 0s - loss: 0.3995 - acc: 0.8251 - val_loss: 0.3937 - val_acc: 0.8379\n",
      "Epoch 45/200\n",
      "700/769 [==========================>...] - ETA: 0s - loss: 0.3990 - acc: 0.8264Epoch 00044: val_loss did not improve\n",
      "769/769 [==============================] - 0s - loss: 0.3888 - acc: 0.8349 - val_loss: 0.3848 - val_acc: 0.8485\n",
      "Epoch 46/200\n",
      "700/769 [==========================>...] - ETA: 0s - loss: 0.3959 - acc: 0.8350Epoch 00045: val_loss did not improve\n",
      "769/769 [==============================] - 0s - loss: 0.3967 - acc: 0.8355 - val_loss: 0.3954 - val_acc: 0.8455\n",
      "Epoch 47/200\n",
      "740/769 [===========================>..] - ETA: 0s - loss: 0.3800 - acc: 0.8372Epoch 00046: val_loss did not improve\n",
      "769/769 [==============================] - 0s - loss: 0.3843 - acc: 0.8342 - val_loss: 0.4132 - val_acc: 0.8394\n",
      "Epoch 48/200\n",
      "740/769 [===========================>..] - ETA: 0s - loss: 0.3737 - acc: 0.8412Epoch 00047: val_loss did not improve\n",
      "769/769 [==============================] - 0s - loss: 0.3685 - acc: 0.8459 - val_loss: 0.3836 - val_acc: 0.8545\n",
      "Epoch 49/200\n",
      "740/769 [===========================>..] - ETA: 0s - loss: 0.3735 - acc: 0.8338Epoch 00048: val_loss did not improve\n",
      "769/769 [==============================] - 0s - loss: 0.3770 - acc: 0.8336 - val_loss: 0.3918 - val_acc: 0.8485\n",
      "Epoch 50/200\n",
      "700/769 [==========================>...] - ETA: 0s - loss: 0.3639 - acc: 0.8471Epoch 00049: val_loss did not improve\n",
      "769/769 [==============================] - 0s - loss: 0.3648 - acc: 0.8485 - val_loss: 0.4141 - val_acc: 0.8515\n",
      "Epoch 51/200\n",
      "700/769 [==========================>...] - ETA: 0s - loss: 0.3761 - acc: 0.8371Epoch 00050: val_loss did not improve\n",
      "769/769 [==============================] - 0s - loss: 0.3653 - acc: 0.8414 - val_loss: 0.3921 - val_acc: 0.8455\n",
      "Epoch 52/200\n",
      "720/769 [===========================>..] - ETA: 0s - loss: 0.3662 - acc: 0.8396Epoch 00051: val_loss did not improve\n",
      "769/769 [==============================] - 0s - loss: 0.3682 - acc: 0.8381 - val_loss: 0.3868 - val_acc: 0.8485\n",
      "Epoch 53/200\n",
      "700/769 [==========================>...] - ETA: 0s - loss: 0.3578 - acc: 0.8521Epoch 00052: val_loss did not improve\n",
      "769/769 [==============================] - 0s - loss: 0.3583 - acc: 0.8498 - val_loss: 0.4059 - val_acc: 0.8591\n",
      "Epoch 54/200\n",
      "760/769 [============================>.] - ETA: 0s - loss: 0.3743 - acc: 0.8454Epoch 00053: val_loss did not improve\n",
      "769/769 [==============================] - 0s - loss: 0.3744 - acc: 0.8459 - val_loss: 0.3799 - val_acc: 0.8545\n",
      "Epoch 00053: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "checkpointer = ModelCheckpoint(filepath=model_weights_file, verbose=1, save_best_only=True)\n",
    "stopper = EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=10, verbose=1, mode='auto')\n",
    "hist = model.fit(X_train, y_train, epochs=200, batch_size=20, validation_split=0.3,\n",
    "                 callbacks=[checkpointer, stopper], \n",
    "                 verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 864/1099 [======================>.......] - ETA: 0s\n",
      "Training Accuracy: 0.846223839746\n"
     ]
    }
   ],
   "source": [
    "# Load the weights that yielded the best validation accuracy\n",
    "model.load_weights(model_weights_file)\n",
    "\n",
    "# Evaluate the model on the training set\n",
    "score = model.evaluate(X_train, y_train)\n",
    "print(\"\\nTraining Accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.9267258   0.07209027]\n"
     ]
    }
   ],
   "source": [
    "# Predict for test data\n",
    "y_test = model.predict(X_test)\n",
    "print(y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save predictions\n",
    "with open(pred_file, 'w') as f:\n",
    "    f.write('PassengerId,Survived\\n')\n",
    "    for index, y_hat in enumerate(y_test):\n",
    "        prediction = np.argmax(y_hat)\n",
    "        f.write(str(int(df_test_raw.iloc[index]['PassengerId'])) + ',' + str(prediction)+'\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done 2434 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done 3184 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done 4034 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=-1)]: Done 4984 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=-1)]: Done 6034 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=-1)]: Done 7184 tasks      | elapsed:    9.7s\n",
      "[Parallel(n_jobs=-1)]: Done 8434 tasks      | elapsed:   11.4s\n",
      "[Parallel(n_jobs=-1)]: Done 9784 tasks      | elapsed:   13.2s\n",
      "[Parallel(n_jobs=-1)]: Done 11234 tasks      | elapsed:   15.2s\n",
      "[Parallel(n_jobs=-1)]: Done 12784 tasks      | elapsed:   17.3s\n",
      "[Parallel(n_jobs=-1)]: Done 14434 tasks      | elapsed:   19.5s\n",
      "[Parallel(n_jobs=-1)]: Done 16184 tasks      | elapsed:   21.8s\n",
      "[Parallel(n_jobs=-1)]: Done 18034 tasks      | elapsed:   24.3s\n",
      "[Parallel(n_jobs=-1)]: Done 19984 tasks      | elapsed:   26.9s\n",
      "[Parallel(n_jobs=-1)]: Done 20000 out of 20000 | elapsed:   27.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done 2434 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done 3184 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done 4034 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done 4984 tasks      | elapsed:    6.7s\n",
      "[Parallel(n_jobs=-1)]: Done 6034 tasks      | elapsed:    8.1s\n",
      "[Parallel(n_jobs=-1)]: Done 7184 tasks      | elapsed:    9.7s\n",
      "[Parallel(n_jobs=-1)]: Done 8434 tasks      | elapsed:   11.3s\n",
      "[Parallel(n_jobs=-1)]: Done 9784 tasks      | elapsed:   13.1s\n",
      "[Parallel(n_jobs=-1)]: Done 11234 tasks      | elapsed:   14.9s\n",
      "[Parallel(n_jobs=-1)]: Done 12784 tasks      | elapsed:   16.9s\n",
      "[Parallel(n_jobs=-1)]: Done 14434 tasks      | elapsed:   19.1s\n",
      "[Parallel(n_jobs=-1)]: Done 16184 tasks      | elapsed:   21.4s\n",
      "[Parallel(n_jobs=-1)]: Done 18034 tasks      | elapsed:   23.8s\n",
      "[Parallel(n_jobs=-1)]: Done 19984 tasks      | elapsed:   26.3s\n",
      "[Parallel(n_jobs=-1)]: Done 20000 out of 20000 | elapsed:   26.3s finished\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done 1234 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=8)]: Done 1784 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=8)]: Done 2434 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=8)]: Done 3184 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=8)]: Done 4034 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=8)]: Done 4984 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=8)]: Done 6034 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=8)]: Done 7184 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=8)]: Done 8434 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=8)]: Done 9784 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=8)]: Done 11234 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=8)]: Done 12784 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=8)]: Done 14434 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=8)]: Done 16184 tasks      | elapsed:    6.6s\n",
      "[Parallel(n_jobs=8)]: Done 18034 tasks      | elapsed:    7.4s\n",
      "[Parallel(n_jobs=8)]: Done 19984 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=8)]: Done 20000 out of 20000 | elapsed:    8.2s finished\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done 2434 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done 3184 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done 4034 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=-1)]: Done 4984 tasks      | elapsed:    6.5s\n",
      "[Parallel(n_jobs=-1)]: Done 6034 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=-1)]: Done 7184 tasks      | elapsed:    9.3s\n",
      "[Parallel(n_jobs=-1)]: Done 8434 tasks      | elapsed:   11.0s\n",
      "[Parallel(n_jobs=-1)]: Done 9784 tasks      | elapsed:   12.7s\n",
      "[Parallel(n_jobs=-1)]: Done 11234 tasks      | elapsed:   14.6s\n",
      "[Parallel(n_jobs=-1)]: Done 12784 tasks      | elapsed:   16.6s\n",
      "[Parallel(n_jobs=-1)]: Done 14434 tasks      | elapsed:   18.7s\n",
      "[Parallel(n_jobs=-1)]: Done 16184 tasks      | elapsed:   21.5s\n",
      "[Parallel(n_jobs=-1)]: Done 18034 tasks      | elapsed:   23.9s\n",
      "[Parallel(n_jobs=-1)]: Done 19984 tasks      | elapsed:   26.4s\n",
      "[Parallel(n_jobs=-1)]: Done 20000 out of 20000 | elapsed:   26.4s finished\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done 1234 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=8)]: Done 1784 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=8)]: Done 2434 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=8)]: Done 3184 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=8)]: Done 4034 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=8)]: Done 4984 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=8)]: Done 6034 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=8)]: Done 7184 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=8)]: Done 8434 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=8)]: Done 9784 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=8)]: Done 11234 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=8)]: Done 12784 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=8)]: Done 14434 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=8)]: Done 16184 tasks      | elapsed:    6.7s\n",
      "[Parallel(n_jobs=8)]: Done 18034 tasks      | elapsed:    7.5s\n",
      "[Parallel(n_jobs=8)]: Done 19984 tasks      | elapsed:    8.3s\n",
      "[Parallel(n_jobs=8)]: Done 20000 out of 20000 | elapsed:    8.3s finished\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done 2434 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done 3184 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done 4034 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=-1)]: Done 4984 tasks      | elapsed:    6.5s\n",
      "[Parallel(n_jobs=-1)]: Done 6034 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=-1)]: Done 7184 tasks      | elapsed:    9.4s\n",
      "[Parallel(n_jobs=-1)]: Done 8434 tasks      | elapsed:   11.0s\n",
      "[Parallel(n_jobs=-1)]: Done 9784 tasks      | elapsed:   12.8s\n",
      "[Parallel(n_jobs=-1)]: Done 11234 tasks      | elapsed:   14.7s\n",
      "[Parallel(n_jobs=-1)]: Done 12784 tasks      | elapsed:   16.7s\n",
      "[Parallel(n_jobs=-1)]: Done 14434 tasks      | elapsed:   18.9s\n",
      "[Parallel(n_jobs=-1)]: Done 16184 tasks      | elapsed:   21.1s\n",
      "[Parallel(n_jobs=-1)]: Done 18034 tasks      | elapsed:   23.5s\n",
      "[Parallel(n_jobs=-1)]: Done 19984 tasks      | elapsed:   26.1s\n",
      "[Parallel(n_jobs=-1)]: Done 20000 out of 20000 | elapsed:   26.1s finished\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done 1234 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=8)]: Done 1784 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=8)]: Done 2434 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=8)]: Done 3184 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=8)]: Done 4034 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=8)]: Done 4984 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=8)]: Done 6034 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=8)]: Done 7184 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=8)]: Done 8434 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=8)]: Done 9784 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=8)]: Done 11234 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=8)]: Done 12784 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=8)]: Done 14434 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=8)]: Done 16184 tasks      | elapsed:    6.6s\n",
      "[Parallel(n_jobs=8)]: Done 18034 tasks      | elapsed:    7.4s\n",
      "[Parallel(n_jobs=8)]: Done 19984 tasks      | elapsed:    8.1s\n",
      "[Parallel(n_jobs=8)]: Done 20000 out of 20000 | elapsed:    8.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.81705948372615034"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use random forest classification \n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=20000, warm_start=True, n_jobs=-1, random_state=0, verbose=1)\n",
    "clf.fit(X_train, y_train)\n",
    "scores = cross_val_score(clf, X_train, y_train)\n",
    "scores.mean()     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done 1234 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=8)]: Done 1784 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=8)]: Done 2434 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=8)]: Done 3184 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=8)]: Done 4034 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=8)]: Done 4984 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=8)]: Done 6034 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=8)]: Done 7184 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=8)]: Done 8434 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=8)]: Done 9784 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=8)]: Done 11234 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=8)]: Done 12784 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=8)]: Done 14434 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=8)]: Done 16184 tasks      | elapsed:    7.0s\n",
      "[Parallel(n_jobs=8)]: Done 18034 tasks      | elapsed:    7.8s\n",
      "[Parallel(n_jobs=8)]: Done 19984 tasks      | elapsed:    8.7s\n",
      "[Parallel(n_jobs=8)]: Done 20000 out of 20000 | elapsed:    8.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  0.]\n"
     ]
    }
   ],
   "source": [
    "y_test = clf.predict(X_test)\n",
    "print(y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
