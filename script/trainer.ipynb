{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training and test data files\n",
    "train_file = '../input/train.csv'\n",
    "test_file = '../input/test.csv'\n",
    "model_file = '../output/titanic.model.json'\n",
    "model_weights_file = '../output/titanic.model.best.hdf5'\n",
    "pred_file = '../output/gender_submission.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load training data\n",
    "df_train = pd.read_csv(train_file)\n",
    "print(df_train.shape)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 2)\n",
      "[[ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]]\n"
     ]
    }
   ],
   "source": [
    "# Extract survived data as predictions: 0 = Died, 1 = Survived\n",
    "from keras.utils.np_utils import to_categorical\n",
    "y_train = to_categorical(df_train[\"Survived\"], 2)\n",
    "df_train.pop('Survived')\n",
    "print(y_train.shape)\n",
    "print(y_train[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prepare the rest of the data for training\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "max_name_len = df_train.Name.map(len).max()    \n",
    "\n",
    "title_list=['Mrs', 'Mr', 'Master', 'Miss', 'Major', 'Rev', 'Dr', 'Ms', 'Mlle',\n",
    "            'Col', 'Capt', 'Mme', 'Countess', 'Don', 'Jonkheer']\n",
    "\n",
    "import string\n",
    "def substrings_in_string(big_string, substrings):\n",
    "    for substring in substrings:\n",
    "        if substring in big_string:\n",
    "            return substring\n",
    "    return np.nan\n",
    "\n",
    "def prep_data(frame):\n",
    "    # Creating new family_size and fare per person columns \n",
    "    frame['Family_Size'] = frame['SibSp'] + frame['Parch'] + 1\n",
    "\n",
    "    # Convert Sex and Embarked to number\n",
    "    frame['Sex'] = pd.Categorical(frame['Sex']).codes\n",
    "    frame['Embarked'] = pd.Categorical(frame['Embarked']).codes\n",
    "    \n",
    "    # Extract title from name\n",
    "    frame['Title'] = frame['Name'].map(lambda x: substrings_in_string(x, title_list))\n",
    "    frame['Title'] = pd.Categorical(frame['Title']).codes\n",
    "\n",
    "    # Convert Name into characters\n",
    "    frame['Name_Length'] = frame.apply(lambda row: len(row['Name']), axis=1)\n",
    "    for i in range(0, max_name_len):\n",
    "        col_name = 'Name' + str(i)\n",
    "        frame[col_name] = frame['Name'].str[i]\n",
    "        frame[col_name] = frame.apply(lambda row: 0 if isinstance(row[col_name], float) and math.isnan(row[col_name]) else ord(row[col_name]), axis=1)\n",
    "    frame.pop('Name')    \n",
    "    \n",
    "    # TODO: Ignore Ticket for now\n",
    "    frame.pop('Ticket')\n",
    "    \n",
    "    # Convert Cabin column to whether in cabin\n",
    "    frame['In_Cabin'] = frame.apply(lambda row: 1 if row['Cabin'] != 0 else 0, axis=1)\n",
    "    frame.pop('Cabin')\n",
    "    \n",
    "    # Change any remaining N/As to 0\n",
    "    frame = frame.fillna(0)\n",
    "\n",
    "    print(\"Before scaling: \")\n",
    "    print(frame.head())\n",
    "    \n",
    "    # Scale everything except PassengerId\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    col_list = frame.columns.tolist()\n",
    "    col_list.remove('PassengerId')\n",
    "    frame = frame[col_list]\n",
    "    np_scaled = min_max_scaler.fit_transform(frame)\n",
    "    frame = pd.DataFrame(np_scaled)\n",
    "    \n",
    "    print(\"After scaling: \")\n",
    "    print(frame.head())\n",
    "\n",
    "    return frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before scaling: \n",
      "   PassengerId  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked  \\\n",
      "0            1       3    1  22.0      1      0   7.2500         2   \n",
      "1            2       1    0  38.0      1      0  71.2833         0   \n",
      "2            3       3    0  26.0      0      0   7.9250         2   \n",
      "3            4       1    0  35.0      1      0  53.1000         2   \n",
      "4            5       3    1  35.0      0      0   8.0500         2   \n",
      "\n",
      "   Family_Size  Title    ...     Name73  Name74  Name75  Name76  Name77  \\\n",
      "0            2     11    ...          0       0       0       0       0   \n",
      "1            2     12    ...          0       0       0       0       0   \n",
      "2            1      8    ...          0       0       0       0       0   \n",
      "3            2     12    ...          0       0       0       0       0   \n",
      "4            1     11    ...          0       0       0       0       0   \n",
      "\n",
      "   Name78  Name79  Name80  Name81  In_Cabin  \n",
      "0       0       0       0       0         1  \n",
      "1       0       0       0       0         1  \n",
      "2       0       0       0       0         1  \n",
      "3       0       0       0       0         1  \n",
      "4       0       0       0       0         1  \n",
      "\n",
      "[5 rows x 94 columns]\n",
      "After scaling: \n",
      "    0    1       2      3    4         5         6    7         8         9   \\\n",
      "0  1.0  1.0  0.2750  0.125  0.0  0.014151  1.000000  0.1  0.785714  0.157143   \n",
      "1  0.0  0.0  0.4750  0.125  0.0  0.139136  0.333333  0.1  0.857143  0.557143   \n",
      "2  1.0  0.0  0.3250  0.000  0.0  0.015469  1.000000  0.0  0.571429  0.142857   \n",
      "3  0.0  0.0  0.4375  0.125  0.0  0.103644  1.000000  0.1  0.857143  0.457143   \n",
      "4  1.0  1.0  0.4375  0.000  0.0  0.015713  1.000000  0.0  0.785714  0.171429   \n",
      "\n",
      "  ...    83   84   85   86   87   88   89   90   91   92  \n",
      "0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "1 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "3 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "4 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "\n",
      "[5 rows x 93 columns]\n",
      "(891, 93)\n",
      "[ 1.          1.          0.27500001  0.125       0.          0.01415106\n",
      "  1.          0.1         0.78571427  0.15714286  0.01886792  0.91463417\n",
      "  0.72222221  0.94444442  0.86666667  0.75555557  0.13483146  0.\n",
      "  0.50561798  0.95348835  0.15730338  0.          0.66386557  0.9834711\n",
      "  0.82786888  0.90909094  0.26229507  0.59016395  0.79508197  0.93442625\n",
      "  0.93442625  0.86065573  0.95041323  0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "# Prepare the rest of the data for training\n",
    "df_train = prep_data(df_train)\n",
    "X_train = np.array(df_train)[:,:]\n",
    "X_train = X_train.astype('float32')\n",
    "print(X_train.shape)\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               48128     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 1,034,242\n",
      "Trainable params: 1,034,242\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build a training network\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(X_train.shape[1], )))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model_json = model.to_json()\n",
    "with open(model_file, 'w') as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/1000\n",
      "690/712 [============================>.] - ETA: 0s - loss: 0.6902 - acc: 0.5725Epoch 00000: val_loss improved from inf to 0.68273, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 1s - loss: 0.6904 - acc: 0.5688 - val_loss: 0.6827 - val_acc: 0.6425\n",
      "Epoch 2/1000\n",
      "690/712 [============================>.] - ETA: 0s - loss: 0.6832 - acc: 0.6101Epoch 00001: val_loss improved from 0.68273 to 0.67540, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.6834 - acc: 0.6096 - val_loss: 0.6754 - val_acc: 0.6425\n",
      "Epoch 3/1000\n",
      "700/712 [============================>.] - ETA: 0s - loss: 0.6782 - acc: 0.6100Epoch 00002: val_loss improved from 0.67540 to 0.66934, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 1s - loss: 0.6782 - acc: 0.6096 - val_loss: 0.6693 - val_acc: 0.6425\n",
      "Epoch 4/1000\n",
      "700/712 [============================>.] - ETA: 0s - loss: 0.6752 - acc: 0.6071Epoch 00003: val_loss improved from 0.66934 to 0.66418, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 1s - loss: 0.6747 - acc: 0.6096 - val_loss: 0.6642 - val_acc: 0.6425\n",
      "Epoch 5/1000\n",
      "690/712 [============================>.] - ETA: 0s - loss: 0.6702 - acc: 0.6159Epoch 00004: val_loss improved from 0.66418 to 0.66047, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 1s - loss: 0.6720 - acc: 0.6096 - val_loss: 0.6605 - val_acc: 0.6425\n",
      "Epoch 6/1000\n",
      "700/712 [============================>.] - ETA: 0s - loss: 0.6710 - acc: 0.6086Epoch 00005: val_loss improved from 0.66047 to 0.65743, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 1s - loss: 0.6708 - acc: 0.6096 - val_loss: 0.6574 - val_acc: 0.6425\n",
      "Epoch 7/1000\n",
      "710/712 [============================>.] - ETA: 0s - loss: 0.6687 - acc: 0.6099Epoch 00006: val_loss improved from 0.65743 to 0.65429, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 1s - loss: 0.6688 - acc: 0.6096 - val_loss: 0.6543 - val_acc: 0.6425\n",
      "Epoch 8/1000\n",
      "690/712 [============================>.] - ETA: 0s - loss: 0.6667 - acc: 0.6130Epoch 00007: val_loss improved from 0.65429 to 0.65112, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 1s - loss: 0.6680 - acc: 0.6096 - val_loss: 0.6511 - val_acc: 0.6425\n",
      "Epoch 9/1000\n",
      "710/712 [============================>.] - ETA: 0s - loss: 0.6644 - acc: 0.6099Epoch 00008: val_loss improved from 0.65112 to 0.64770, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 1s - loss: 0.6645 - acc: 0.6096 - val_loss: 0.6477 - val_acc: 0.6425\n",
      "Epoch 10/1000\n",
      "690/712 [============================>.] - ETA: 0s - loss: 0.6623 - acc: 0.6072Epoch 00009: val_loss improved from 0.64770 to 0.64292, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 1s - loss: 0.6614 - acc: 0.6096 - val_loss: 0.6429 - val_acc: 0.6425\n",
      "Epoch 11/1000\n",
      "690/712 [============================>.] - ETA: 0s - loss: 0.6602 - acc: 0.6072Epoch 00010: val_loss improved from 0.64292 to 0.63739, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 1s - loss: 0.6597 - acc: 0.6096 - val_loss: 0.6374 - val_acc: 0.6425\n",
      "Epoch 12/1000\n",
      "690/712 [============================>.] - ETA: 0s - loss: 0.6547 - acc: 0.6101Epoch 00011: val_loss improved from 0.63739 to 0.62991, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 1s - loss: 0.6546 - acc: 0.6096 - val_loss: 0.6299 - val_acc: 0.6425\n",
      "Epoch 13/1000\n",
      "710/712 [============================>.] - ETA: 0s - loss: 0.6459 - acc: 0.6113Epoch 00012: val_loss improved from 0.62991 to 0.61668, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 1s - loss: 0.6460 - acc: 0.6110 - val_loss: 0.6167 - val_acc: 0.6425\n",
      "Epoch 14/1000\n",
      "710/712 [============================>.] - ETA: 0s - loss: 0.6373 - acc: 0.6099Epoch 00013: val_loss improved from 0.61668 to 0.60483, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 1s - loss: 0.6373 - acc: 0.6096 - val_loss: 0.6048 - val_acc: 0.6425\n",
      "Epoch 15/1000\n",
      "710/712 [============================>.] - ETA: 0s - loss: 0.6158 - acc: 0.6239Epoch 00014: val_loss improved from 0.60483 to 0.57548, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 1s - loss: 0.6157 - acc: 0.6236 - val_loss: 0.5755 - val_acc: 0.7430\n",
      "Epoch 16/1000\n",
      "690/712 [============================>.] - ETA: 0s - loss: 0.5856 - acc: 0.6884Epoch 00015: val_loss improved from 0.57548 to 0.54663, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 1s - loss: 0.5859 - acc: 0.6882 - val_loss: 0.5466 - val_acc: 0.7765\n",
      "Epoch 17/1000\n",
      "690/712 [============================>.] - ETA: 0s - loss: 0.5521 - acc: 0.7493Epoch 00016: val_loss improved from 0.54663 to 0.51011, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 1s - loss: 0.5493 - acc: 0.7514 - val_loss: 0.5101 - val_acc: 0.7765\n",
      "Epoch 18/1000\n",
      "690/712 [============================>.] - ETA: 0s - loss: 0.5276 - acc: 0.7696Epoch 00017: val_loss improved from 0.51011 to 0.47747, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 1s - loss: 0.5236 - acc: 0.7753 - val_loss: 0.4775 - val_acc: 0.7989\n",
      "Epoch 19/1000\n",
      "670/712 [===========================>..] - ETA: 0s - loss: 0.5023 - acc: 0.7806Epoch 00018: val_loss improved from 0.47747 to 0.47472, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 1s - loss: 0.5027 - acc: 0.7823 - val_loss: 0.4747 - val_acc: 0.7821\n",
      "Epoch 20/1000\n",
      "680/712 [===========================>..] - ETA: 0s - loss: 0.5020 - acc: 0.7868Epoch 00019: val_loss did not improve\n",
      "712/712 [==============================] - 1s - loss: 0.5004 - acc: 0.7879 - val_loss: 0.4802 - val_acc: 0.7821\n",
      "Epoch 21/1000\n",
      "700/712 [============================>.] - ETA: 0s - loss: 0.4903 - acc: 0.7900Epoch 00020: val_loss improved from 0.47472 to 0.45749, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 1s - loss: 0.4862 - acc: 0.7935 - val_loss: 0.4575 - val_acc: 0.7821\n",
      "Epoch 22/1000\n",
      "680/712 [===========================>..] - ETA: 0s - loss: 0.4868 - acc: 0.7926Epoch 00021: val_loss improved from 0.45749 to 0.44497, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 1s - loss: 0.4838 - acc: 0.7963 - val_loss: 0.4450 - val_acc: 0.8268\n",
      "Epoch 23/1000\n",
      "690/712 [============================>.] - ETA: 0s - loss: 0.4797 - acc: 0.8014Epoch 00022: val_loss did not improve\n",
      "712/712 [==============================] - 1s - loss: 0.4740 - acc: 0.8048 - val_loss: 0.4591 - val_acc: 0.8212\n",
      "Epoch 24/1000\n",
      "690/712 [============================>.] - ETA: 0s - loss: 0.4700 - acc: 0.7870Epoch 00023: val_loss improved from 0.44497 to 0.44002, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 1s - loss: 0.4727 - acc: 0.7851 - val_loss: 0.4400 - val_acc: 0.8156\n",
      "Epoch 25/1000\n",
      "670/712 [===========================>..] - ETA: 0s - loss: 0.4497 - acc: 0.8030Epoch 00024: val_loss did not improve\n",
      "712/712 [==============================] - 1s - loss: 0.4610 - acc: 0.7949 - val_loss: 0.4829 - val_acc: 0.7933\n",
      "Epoch 26/1000\n",
      "690/712 [============================>.] - ETA: 0s - loss: 0.4577 - acc: 0.8043Epoch 00025: val_loss improved from 0.44002 to 0.42759, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 1s - loss: 0.4590 - acc: 0.8048 - val_loss: 0.4276 - val_acc: 0.8045\n",
      "Epoch 27/1000\n",
      "700/712 [============================>.] - ETA: 0s - loss: 0.4477 - acc: 0.8186Epoch 00026: val_loss improved from 0.42759 to 0.42424, saving model to ../output/titanic.model.best.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 1s - loss: 0.4461 - acc: 0.8202 - val_loss: 0.4242 - val_acc: 0.8101\n",
      "Epoch 28/1000\n",
      "670/712 [===========================>..] - ETA: 0s - loss: 0.4355 - acc: 0.8239Epoch 00027: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4477 - acc: 0.8174 - val_loss: 0.4407 - val_acc: 0.7933\n",
      "Epoch 29/1000\n",
      "680/712 [===========================>..] - ETA: 0s - loss: 0.4358 - acc: 0.8221- ETA: 0s - loss: 0.4283 - acc:Epoch 00028: val_loss improved from 0.42424 to 0.42149, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 1s - loss: 0.4377 - acc: 0.8202 - val_loss: 0.4215 - val_acc: 0.8156\n",
      "Epoch 30/1000\n",
      "710/712 [============================>.] - ETA: 0s - loss: 0.4306 - acc: 0.8085Epoch 00029: val_loss did not improve\n",
      "712/712 [==============================] - 1s - loss: 0.4299 - acc: 0.8090 - val_loss: 0.4490 - val_acc: 0.8045\n",
      "Epoch 31/1000\n",
      "710/712 [============================>.] - ETA: 0s - loss: 0.4274 - acc: 0.8254Epoch 00030: val_loss improved from 0.42149 to 0.42124, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 1s - loss: 0.4264 - acc: 0.8258 - val_loss: 0.4212 - val_acc: 0.8045\n",
      "Epoch 32/1000\n",
      "680/712 [===========================>..] - ETA: 0s - loss: 0.4248 - acc: 0.8235Epoch 00031: val_loss improved from 0.42124 to 0.42058, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.4260 - acc: 0.8244 - val_loss: 0.4206 - val_acc: 0.8212\n",
      "Epoch 33/1000\n",
      "680/712 [===========================>..] - ETA: 0s - loss: 0.4295 - acc: 0.8191Epoch 00032: val_loss improved from 0.42058 to 0.41531, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.4279 - acc: 0.8188 - val_loss: 0.4153 - val_acc: 0.8268\n",
      "Epoch 34/1000\n",
      "710/712 [============================>.] - ETA: 0s - loss: 0.4156 - acc: 0.8310Epoch 00033: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4146 - acc: 0.8315 - val_loss: 0.4307 - val_acc: 0.8045\n",
      "Epoch 35/1000\n",
      "680/712 [===========================>..] - ETA: 0s - loss: 0.4091 - acc: 0.8309Epoch 00034: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4177 - acc: 0.8258 - val_loss: 0.7270 - val_acc: 0.6760\n",
      "Epoch 36/1000\n",
      "690/712 [============================>.] - ETA: 0s - loss: 0.4241 - acc: 0.8217Epoch 00035: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4210 - acc: 0.8244 - val_loss: 0.4180 - val_acc: 0.8045\n",
      "Epoch 37/1000\n",
      "700/712 [============================>.] - ETA: 0s - loss: 0.3981 - acc: 0.8400Epoch 00036: val_loss improved from 0.41531 to 0.41108, saving model to ../output/titanic.model.best.hdf5\n",
      "712/712 [==============================] - 0s - loss: 0.4024 - acc: 0.8385 - val_loss: 0.4111 - val_acc: 0.8101\n",
      "Epoch 38/1000\n",
      "700/712 [============================>.] - ETA: 0s - loss: 0.4034 - acc: 0.8314Epoch 00037: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4004 - acc: 0.8329 - val_loss: 0.4142 - val_acc: 0.8268\n",
      "Epoch 39/1000\n",
      "700/712 [============================>.] - ETA: 0s - loss: 0.4056 - acc: 0.8414Epoch 00038: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.4093 - acc: 0.8385 - val_loss: 0.5442 - val_acc: 0.7542\n",
      "Epoch 40/1000\n",
      "690/712 [============================>.] - ETA: 0s - loss: 0.3876 - acc: 0.8449Epoch 00039: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.3929 - acc: 0.8385 - val_loss: 0.5373 - val_acc: 0.7374\n",
      "Epoch 41/1000\n",
      "670/712 [===========================>..] - ETA: 0s - loss: 0.3857 - acc: 0.8507Epoch 00040: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.3831 - acc: 0.8511 - val_loss: 0.4243 - val_acc: 0.8101\n",
      "Epoch 42/1000\n",
      "670/712 [===========================>..] - ETA: 0s - loss: 0.3767 - acc: 0.8657Epoch 00041: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.3767 - acc: 0.8652 - val_loss: 0.4216 - val_acc: 0.8045\n",
      "Epoch 43/1000\n",
      "680/712 [===========================>..] - ETA: 0s - loss: 0.3706 - acc: 0.8515Epoch 00042: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.3834 - acc: 0.8483 - val_loss: 0.4273 - val_acc: 0.8212\n",
      "Epoch 44/1000\n",
      "700/712 [============================>.] - ETA: 0s - loss: 0.3869 - acc: 0.8629Epoch 00043: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.3855 - acc: 0.8638 - val_loss: 0.4395 - val_acc: 0.7989\n",
      "Epoch 45/1000\n",
      "700/712 [============================>.] - ETA: 0s - loss: 0.3581 - acc: 0.8686Epoch 00044: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.3581 - acc: 0.8680 - val_loss: 0.5277 - val_acc: 0.7709\n",
      "Epoch 46/1000\n",
      "660/712 [==========================>...] - ETA: 0s - loss: 0.3540 - acc: 0.8652Epoch 00045: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.3538 - acc: 0.8652 - val_loss: 0.4169 - val_acc: 0.8156\n",
      "Epoch 47/1000\n",
      "670/712 [===========================>..] - ETA: 0s - loss: 0.3565 - acc: 0.8567Epoch 00046: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.3613 - acc: 0.8539 - val_loss: 0.4697 - val_acc: 0.7989\n",
      "Epoch 48/1000\n",
      "710/712 [============================>.] - ETA: 0s - loss: 0.3642 - acc: 0.8648Epoch 00047: val_loss did not improve\n",
      "712/712 [==============================] - 0s - loss: 0.3634 - acc: 0.8652 - val_loss: 0.4254 - val_acc: 0.7989\n",
      "Epoch 00047: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "checkpointer = ModelCheckpoint(filepath=model_weights_file, verbose=1, save_best_only=True)\n",
    "stopper = EarlyStopping(monitor='val_loss', min_delta=1e-5, patience=10, verbose=1, mode='auto')\n",
    "hist = model.fit(X_train, y_train, epochs=1000, batch_size=10, validation_split=0.2, \n",
    "                 callbacks=[checkpointer, stopper], \n",
    "                 verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/891 [========================>.....] - ETA: 0s\n",
      "Training Accuracy: 0.856341190544\n"
     ]
    }
   ],
   "source": [
    "# Load the weights that yielded the best validation accuracy\n",
    "model.load_weights(model_weights_file)\n",
    "\n",
    "# Evaluate the model on the training set\n",
    "score = model.evaluate(X_train, y_train)\n",
    "print(\"\\nTraining Accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(418, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load test data\n",
    "df_test_raw = pd.read_csv(test_file)\n",
    "print(df_test_raw.shape)\n",
    "df_test_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before scaling: \n",
      "   PassengerId  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked  \\\n",
      "0          892       3    1  34.5      0      0   7.8292         1   \n",
      "1          893       3    0  47.0      1      0   7.0000         2   \n",
      "2          894       2    1  62.0      0      0   9.6875         1   \n",
      "3          895       3    1  27.0      0      0   8.6625         2   \n",
      "4          896       3    0  22.0      1      1  12.2875         2   \n",
      "\n",
      "   Family_Size  Title    ...     Name73  Name74  Name75  Name76  Name77  \\\n",
      "0            1      5    ...          0       0       0       0       0   \n",
      "1            2      6    ...          0       0       0       0       0   \n",
      "2            1      5    ...          0       0       0       0       0   \n",
      "3            1      5    ...          0       0       0       0       0   \n",
      "4            3      6    ...          0       0       0       0       0   \n",
      "\n",
      "   Name78  Name79  Name80  Name81  In_Cabin  \n",
      "0       0       0       0       0         1  \n",
      "1       0       0       0       0         1  \n",
      "2       0       0       0       0         1  \n",
      "3       0       0       0       0         1  \n",
      "4       0       0       0       0         1  \n",
      "\n",
      "[5 rows x 94 columns]\n",
      "After scaling: \n",
      "    0    1         2      3         4         5    6    7      8     9  ...   \\\n",
      "0  1.0  1.0  0.453947  0.000  0.000000  0.015282  0.5  0.0  0.625  0.06 ...    \n",
      "1  1.0  0.0  0.618421  0.125  0.000000  0.013663  1.0  0.1  0.750  0.38 ...    \n",
      "2  0.5  1.0  0.815789  0.000  0.000000  0.018909  0.5  0.0  0.625  0.24 ...    \n",
      "3  1.0  1.0  0.355263  0.000  0.000000  0.016908  1.0  0.0  0.625  0.06 ...    \n",
      "4  1.0  0.0  0.289474  0.125  0.111111  0.023984  1.0  0.2  0.750  0.62 ...    \n",
      "\n",
      "    83   84   85   86   87   88   89   90   91   92  \n",
      "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "\n",
      "[5 rows x 93 columns]\n",
      "(418, 93)\n",
      "[ 1.          1.          0.45394737  0.          0.          0.01528158\n",
      "  0.5         0.          0.625       0.06        0.18867925  0.75609756\n",
      "  0.85393256  0.84444445  0.98888886  0.13333334  0.          0.5\n",
      "  0.94252872  0.15555556  0.          0.49411765  0.74712646  0.92372882\n",
      "  0.83471072  0.94262296  0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "# Prepare the data for testing\n",
    "df_test = prep_data(df_test_raw)\n",
    "X_test = np.array(df_test)[:,:]\n",
    "X_test = X_test.astype('float32')\n",
    "print(X_test.shape)\n",
    "print(X_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.71559083  0.09956969]\n"
     ]
    }
   ],
   "source": [
    "# Predict for test data\n",
    "y_test = model.predict(X_test)\n",
    "print(y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save predictions\n",
    "with open(pred_file, 'w') as f:\n",
    "    f.write('PassengerId,Survived\\n')\n",
    "    for index, y_hat in enumerate(y_test):\n",
    "        prediction = np.argmax(y_hat)\n",
    "        f.write(str(int(df_test_raw.iloc[index]['PassengerId'])) + ',' + str(prediction)+'\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
