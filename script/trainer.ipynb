{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training and test data files\n",
    "train_file = '../input/train.csv'\n",
    "test_file = '../input/test.csv'\n",
    "model_file = '../output/titanic.model.json'\n",
    "model_weights_file = '../output/titanic.model.best.hdf5'\n",
    "pred_file = '../output/gender_submission.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 12)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load training data\n",
    "df_train_raw = pd.read_csv(train_file)\n",
    "print(df_train_raw.shape)\n",
    "df_train_raw.info()\n",
    "df_train_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prepare the data for training and testing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "max_name_len = df_train_raw.Name.map(len).max()\n",
    "max_ticket_len = df_train_raw.Ticket.map(len).max()\n",
    "\n",
    "title_list=['Mrs', 'Mr', 'Master', 'Miss', 'Major', 'Rev', 'Dr', 'Ms', 'Mlle',\n",
    "            'Col', 'Capt', 'Mme', 'Countess', 'Don', 'Jonkheer']\n",
    "\n",
    "import string\n",
    "def substrings_in_string(big_string, substrings):\n",
    "    for substring in substrings:\n",
    "        if substring in big_string:\n",
    "            return substring\n",
    "    return np.nan\n",
    "\n",
    "def prep_data(frame, mode='test'):\n",
    "    # Fill missing Age data with median \n",
    "    frame['Age'] = frame['Age'].fillna(frame['Age'].median())\n",
    "    \n",
    "    # Generate data about whether adult or minor\n",
    "    frame['Adult_Or_Minor'] = frame.apply(lambda row: 0 if row['Age'] < 18 else 1, axis=1)\n",
    "\n",
    "    # Generate data about whether senior citizen\n",
    "    frame['Senior_Citizen'] = frame.apply(lambda row: 0 if row['Age'] > 65 else 1, axis=1)\n",
    "\n",
    "    # Fill missing Fare data with median\n",
    "    frame['Fare'] = frame['Fare'].fillna(frame['Fare'].median())\n",
    "    \n",
    "    # Creating new family_size and fare per person columns \n",
    "    frame['Family_Size'] = frame['SibSp'] + frame['Parch'] + 1\n",
    "    frame['Alone'] = frame.apply(lambda row: 1 if row['Family_Size'] == 1 else 0, axis=1)\n",
    "    frame['Fare_Per_Person'] = frame['Fare']/frame['Family_Size']\n",
    "\n",
    "    # Convert Sex to number\n",
    "    frame['Sex'] = pd.Categorical(frame['Sex']).codes\n",
    "\n",
    "    # Generate data for missing Embarked and convert to number\n",
    "    frame['Embarked'] = frame['Embarked'].fillna('S')\n",
    "    frame['Embarked'] = pd.Categorical(frame['Embarked']).codes\n",
    "    \n",
    "    # Extract title from name\n",
    "    frame['Title'] = frame['Name'].map(lambda x: substrings_in_string(x, title_list))\n",
    "    frame['Title'] = pd.Categorical(frame['Title']).codes\n",
    "\n",
    "    # Convert Name into characters\n",
    "    frame['Name_Length'] = frame.apply(lambda row: len(row['Name']), axis=1)\n",
    "    frame['Words_In_Name'] = frame.apply(lambda row: len(row['Name'].split()), axis=1)    \n",
    "    for i in range(0, max_name_len):\n",
    "        col_name = 'Name' + str(i)\n",
    "        frame[col_name] = frame['Name'].str[i]\n",
    "        frame[col_name] = frame.apply(lambda row: 0 if isinstance(row[col_name], float) and math.isnan(row[col_name]) else ord(row[col_name]), axis=1)\n",
    "    frame.pop('Name')    \n",
    "    \n",
    "    # Convert Ticket into characters\n",
    "    frame['Ticket_Length'] = frame.apply(lambda row: len(row['Ticket']), axis=1)\n",
    "    for i in range(0, max_ticket_len):\n",
    "        col_name = 'Ticket' + str(i)\n",
    "        frame[col_name] = frame['Ticket'].str[i]\n",
    "        frame[col_name] = frame.apply(lambda row: 0 if isinstance(row[col_name], float) and math.isnan(row[col_name]) else ord(row[col_name]), axis=1)\n",
    "    frame.pop('Ticket')    \n",
    "    \n",
    "    # Convert Cabin column to whether in cabin\n",
    "    frame['Cabin'] = frame['Cabin'].fillna('')\n",
    "    frame['In_Cabin'] = frame.apply(lambda row: 1 if row['Cabin'] != '' else 0, axis=1)\n",
    "    frame['Number_Of_Cabins'] = frame.apply(lambda row: len(row['Cabin'].split()), axis=1)    \n",
    "    frame.pop('Cabin')\n",
    "    \n",
    "    frame.fillna(0, axis=1)\n",
    "    \n",
    "    # Introduce rows with some noise\n",
    "    if (mode == 'augment'):\n",
    "        print('Adding more rows to training data')\n",
    "        row_count = frame.shape[0]\n",
    "        print('Row count before: ', row_count)\n",
    "        col_std = np.std(frame) \n",
    "        for i in range(0, row_count):\n",
    "            row1 = pd.Series(frame.iloc[i])\n",
    "            row2 = pd.Series(frame.iloc[i])\n",
    "            col_list = frame.columns.tolist()\n",
    "            col_list.remove('PassengerId')\n",
    "            col_list.remove('Survived')\n",
    "            for col in frame.columns.tolist():\n",
    "                row1[col] = row1[col] + col_std[col]\n",
    "                row2[col] = row2[col] - col_std[col]\n",
    "            if np.random.random_sample() < 0.33:\n",
    "                frame = frame.append(row1)\n",
    "            if np.random.random_sample() > 0.66:\n",
    "                frame = frame.append(row2)\n",
    "        row_count = frame.shape[0]\n",
    "        print('Row count after: ', row_count)\n",
    "    \n",
    "    \n",
    "    print(\"Before scaling: \")\n",
    "    print(frame.head())\n",
    "    \n",
    "    # Scale everything except PassengerId\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    col_list = frame.columns.tolist()\n",
    "    col_list.remove('PassengerId')\n",
    "    frame = frame[col_list]\n",
    "    np_scaled = min_max_scaler.fit_transform(frame)\n",
    "    frame = pd.DataFrame(np_scaled)\n",
    "    \n",
    "    print(\"After scaling: \")\n",
    "    print(frame.head())\n",
    "\n",
    "    return frame\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before scaling: \n",
      "   PassengerId  Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked  \\\n",
      "0            1         0       3    1  22.0      1      0   7.2500         2   \n",
      "1            2         1       1    0  38.0      1      0  71.2833         0   \n",
      "2            3         1       3    0  26.0      0      0   7.9250         2   \n",
      "3            4         1       1    0  35.0      1      0  53.1000         2   \n",
      "4            5         0       3    1  35.0      0      0   8.0500         2   \n",
      "\n",
      "   Adult_Or_Minor        ...         Ticket10  Ticket11  Ticket12  Ticket13  \\\n",
      "0               1        ...                0         0         0         0   \n",
      "1               1        ...                0         0         0         0   \n",
      "2               1        ...               49        48        49        50   \n",
      "3               1        ...                0         0         0         0   \n",
      "4               1        ...                0         0         0         0   \n",
      "\n",
      "   Ticket14  Ticket15  Ticket16  Ticket17  In_Cabin  Number_Of_Cabins  \n",
      "0         0         0         0         0         0                 0  \n",
      "1         0         0         0         0         1                 1  \n",
      "2        56        50         0         0         0                 0  \n",
      "3         0         0         0         0         1                 1  \n",
      "4         0         0         0         0         0                 0  \n",
      "\n",
      "[5 rows x 120 columns]\n",
      "After scaling: \n",
      "   0    1    2         3      4    5         6    7    8    9    ...   \\\n",
      "0  0.0  1.0  1.0  0.271174  0.125  0.0  0.014151  1.0  1.0  1.0  ...    \n",
      "1  1.0  0.0  0.0  0.472229  0.125  0.0  0.139136  0.0  1.0  1.0  ...    \n",
      "2  1.0  1.0  0.0  0.321438  0.000  0.0  0.015469  1.0  1.0  1.0  ...    \n",
      "3  1.0  0.0  0.0  0.434531  0.125  0.0  0.103644  1.0  1.0  1.0  ...    \n",
      "4  0.0  1.0  1.0  0.434531  0.000  0.0  0.015713  1.0  1.0  1.0  ...    \n",
      "\n",
      "        109       110       111       112       113       114  115  116  117  \\\n",
      "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.0  0.0  0.0   \n",
      "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.0  0.0  1.0   \n",
      "2  0.485149  0.842105  0.859649  0.877193  0.982456  0.877193  0.0  0.0  0.0   \n",
      "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.0  0.0  1.0   \n",
      "4  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.0  0.0  0.0   \n",
      "\n",
      "    118  \n",
      "0  0.00  \n",
      "1  0.25  \n",
      "2  0.00  \n",
      "3  0.25  \n",
      "4  0.00  \n",
      "\n",
      "[5 rows x 119 columns]\n",
      "(891, 118)\n",
      "[ 1.          1.          0.27117366  0.125       0.          0.01415106\n",
      "  1.          1.          1.          0.1         0.          0.00707553\n",
      "  0.78571427  0.15714286  0.09090909  0.01886792  0.91463417  0.72222221\n",
      "  0.94444442  0.86666667  0.75555557  0.13483146  0.          0.50561798\n",
      "  0.95348835  0.15730338  0.          0.66386557  0.9834711   0.82786888\n",
      "  0.90909094  0.26229507  0.59016395  0.79508197  0.93442625  0.93442625\n",
      "  0.86065573  0.95041323  0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.40000001\n",
      "  0.42105263  0.23076923  0.38181818  0.40000001  0.51546389  0.42982456\n",
      "  0.46666667  0.47826087  0.42608696  0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "# Prep training data\n",
    "df_train = prep_data(df_train_raw, mode='train')\n",
    "\n",
    "# Construct the X array\n",
    "X_train = np.array(df_train)[:,1:]\n",
    "X_train = X_train.astype('float32')\n",
    "print(X_train.shape)\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 2)\n",
      "[[ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]]\n"
     ]
    }
   ],
   "source": [
    "# Extract survived data as predictions\n",
    "from keras.utils.np_utils import to_categorical\n",
    "y_train = np.array(df_train)[:,0]\n",
    "y_train = to_categorical(y_train, 2)\n",
    "print(y_train.shape)\n",
    "print(y_train[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_23 (Dense)             (None, 891)               106029    \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 891)               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 445)               396940    \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 445)               0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 2)                 892       \n",
      "=================================================================\n",
      "Total params: 503,861\n",
      "Trainable params: 503,861\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build a training network\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, RepeatVector, Flatten, Activation\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(891, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(445, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model_json = model.to_json()\n",
    "with open(model_file, 'w') as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 623 samples, validate on 268 samples\n",
      "Epoch 1/100\n",
      "500/623 [=======================>......] - ETA: 0s - loss: 0.6848 - acc: 0.5510Epoch 00000: val_loss improved from inf to 0.65049, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.6822 - acc: 0.5586 - val_loss: 0.6505 - val_acc: 0.6530\n",
      "Epoch 2/100\n",
      "580/623 [==========================>...] - ETA: 0s - loss: 0.6649 - acc: 0.6112Epoch 00001: val_loss improved from 0.65049 to 0.63156, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.6649 - acc: 0.6100 - val_loss: 0.6316 - val_acc: 0.6455\n",
      "Epoch 3/100\n",
      "620/623 [============================>.] - ETA: 0s - loss: 0.6515 - acc: 0.6258Epoch 00002: val_loss improved from 0.63156 to 0.61667, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.6504 - acc: 0.6276 - val_loss: 0.6167 - val_acc: 0.6511\n",
      "Epoch 4/100\n",
      "600/623 [===========================>..] - ETA: 0s - loss: 0.6391 - acc: 0.6292Epoch 00003: val_loss improved from 0.61667 to 0.60529, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.6384 - acc: 0.6276 - val_loss: 0.6053 - val_acc: 0.6828\n",
      "Epoch 5/100\n",
      "560/623 [=========================>....] - ETA: 0s - loss: 0.6239 - acc: 0.6598Epoch 00004: val_loss improved from 0.60529 to 0.59556, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.6246 - acc: 0.6573 - val_loss: 0.5956 - val_acc: 0.7146\n",
      "Epoch 6/100\n",
      "540/623 [=========================>....] - ETA: 0s - loss: 0.6181 - acc: 0.6611- ETA: 0s - loss: 0.6323 - acc: 0.6Epoch 00005: val_loss improved from 0.59556 to 0.58478, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.6155 - acc: 0.6677 - val_loss: 0.5848 - val_acc: 0.7220\n",
      "Epoch 7/100\n",
      "540/623 [=========================>....] - ETA: 0s - loss: 0.6083 - acc: 0.6667Epoch 00006: val_loss improved from 0.58478 to 0.57620, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.6083 - acc: 0.6709 - val_loss: 0.5762 - val_acc: 0.7313\n",
      "Epoch 8/100\n",
      "560/623 [=========================>....] - ETA: 0s - loss: 0.6002 - acc: 0.6857Epoch 00007: val_loss improved from 0.57620 to 0.56698, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.6033 - acc: 0.6814 - val_loss: 0.5670 - val_acc: 0.7463\n",
      "Epoch 9/100\n",
      "540/623 [=========================>....] - ETA: 0s - loss: 0.5939 - acc: 0.6981Epoch 00008: val_loss improved from 0.56698 to 0.55905, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.5923 - acc: 0.6974 - val_loss: 0.5590 - val_acc: 0.7444\n",
      "Epoch 10/100\n",
      "600/623 [===========================>..] - ETA: 0s - loss: 0.5888 - acc: 0.6983Epoch 00009: val_loss improved from 0.55905 to 0.54828, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.5865 - acc: 0.7014 - val_loss: 0.5483 - val_acc: 0.7481\n",
      "Epoch 11/100\n",
      "580/623 [==========================>...] - ETA: 0s - loss: 0.5766 - acc: 0.7026Epoch 00010: val_loss improved from 0.54828 to 0.54637, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.5809 - acc: 0.6942 - val_loss: 0.5464 - val_acc: 0.7575\n",
      "Epoch 12/100\n",
      "600/623 [===========================>..] - ETA: 0s - loss: 0.5720 - acc: 0.7008Epoch 00011: val_loss improved from 0.54637 to 0.53979, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.5691 - acc: 0.7055 - val_loss: 0.5398 - val_acc: 0.7649\n",
      "Epoch 13/100\n",
      "540/623 [=========================>....] - ETA: 0s - loss: 0.5533 - acc: 0.7306Epoch 00012: val_loss improved from 0.53979 to 0.53055, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.5570 - acc: 0.7303 - val_loss: 0.5305 - val_acc: 0.7668\n",
      "Epoch 14/100\n",
      "600/623 [===========================>..] - ETA: 0s - loss: 0.5527 - acc: 0.7308Epoch 00013: val_loss improved from 0.53055 to 0.52191, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.5556 - acc: 0.7279 - val_loss: 0.5219 - val_acc: 0.7705\n",
      "Epoch 15/100\n",
      "560/623 [=========================>....] - ETA: 0s - loss: 0.5542 - acc: 0.7330Epoch 00014: val_loss improved from 0.52191 to 0.51712, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.5504 - acc: 0.7360 - val_loss: 0.5171 - val_acc: 0.7687\n",
      "Epoch 16/100\n",
      "540/623 [=========================>....] - ETA: 0s - loss: 0.5533 - acc: 0.7204Epoch 00015: val_loss improved from 0.51712 to 0.50911, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.5475 - acc: 0.7271 - val_loss: 0.5091 - val_acc: 0.7743\n",
      "Epoch 17/100\n",
      "620/623 [============================>.] - ETA: 0s - loss: 0.5467 - acc: 0.7363Epoch 00016: val_loss improved from 0.50911 to 0.50348, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.5453 - acc: 0.7376 - val_loss: 0.5035 - val_acc: 0.7724\n",
      "Epoch 18/100\n",
      "560/623 [=========================>....] - ETA: 0s - loss: 0.5353 - acc: 0.7536Epoch 00017: val_loss improved from 0.50348 to 0.49759, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.5322 - acc: 0.7568 - val_loss: 0.4976 - val_acc: 0.7724\n",
      "Epoch 19/100\n",
      "580/623 [==========================>...] - ETA: 0s - loss: 0.5286 - acc: 0.7483Epoch 00018: val_loss improved from 0.49759 to 0.49333, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.5237 - acc: 0.7528 - val_loss: 0.4933 - val_acc: 0.7687\n",
      "Epoch 20/100\n",
      "600/623 [===========================>..] - ETA: 0s - loss: 0.5225 - acc: 0.7550Epoch 00019: val_loss improved from 0.49333 to 0.49015, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.5186 - acc: 0.7608 - val_loss: 0.4901 - val_acc: 0.7668\n",
      "Epoch 21/100\n",
      "580/623 [==========================>...] - ETA: 0s - loss: 0.5223 - acc: 0.7681Epoch 00020: val_loss improved from 0.49015 to 0.48514, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.5242 - acc: 0.7697 - val_loss: 0.4851 - val_acc: 0.7687\n",
      "Epoch 22/100\n",
      "580/623 [==========================>...] - ETA: 0s - loss: 0.5140 - acc: 0.7638Epoch 00021: val_loss improved from 0.48514 to 0.47867, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.5181 - acc: 0.7608 - val_loss: 0.4787 - val_acc: 0.7631\n",
      "Epoch 23/100\n",
      "580/623 [==========================>...] - ETA: 0s - loss: 0.5102 - acc: 0.7534Epoch 00022: val_loss improved from 0.47867 to 0.47822, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.5114 - acc: 0.7552 - val_loss: 0.4782 - val_acc: 0.7780\n",
      "Epoch 24/100\n",
      "620/623 [============================>.] - ETA: 0s - loss: 0.5086 - acc: 0.7702Epoch 00023: val_loss improved from 0.47822 to 0.47754, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.5077 - acc: 0.7713 - val_loss: 0.4775 - val_acc: 0.7799\n",
      "Epoch 25/100\n",
      "580/623 [==========================>...] - ETA: 0s - loss: 0.5099 - acc: 0.7672Epoch 00024: val_loss improved from 0.47754 to 0.46730, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.5057 - acc: 0.7729 - val_loss: 0.4673 - val_acc: 0.7799\n",
      "Epoch 26/100\n",
      "560/623 [=========================>....] - ETA: 0s - loss: 0.5084 - acc: 0.7589Epoch 00025: val_loss improved from 0.46730 to 0.46371, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.5036 - acc: 0.7648 - val_loss: 0.4637 - val_acc: 0.7799\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "580/623 [==========================>...] - ETA: 0s - loss: 0.4983 - acc: 0.7741Epoch 00026: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.5093 - acc: 0.7681 - val_loss: 0.4799 - val_acc: 0.7817\n",
      "Epoch 28/100\n",
      "600/623 [===========================>..] - ETA: 0s - loss: 0.4878 - acc: 0.7808Epoch 00027: val_loss improved from 0.46371 to 0.45800, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.4963 - acc: 0.7753 - val_loss: 0.4580 - val_acc: 0.7836\n",
      "Epoch 29/100\n",
      "580/623 [==========================>...] - ETA: 0s - loss: 0.4836 - acc: 0.7810Epoch 00028: val_loss improved from 0.45800 to 0.45581, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.4872 - acc: 0.7761 - val_loss: 0.4558 - val_acc: 0.7817\n",
      "Epoch 30/100\n",
      "520/623 [========================>.....] - ETA: 0s - loss: 0.4812 - acc: 0.7856Epoch 00029: val_loss improved from 0.45581 to 0.45096, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.4893 - acc: 0.7833 - val_loss: 0.4510 - val_acc: 0.7854\n",
      "Epoch 31/100\n",
      "540/623 [=========================>....] - ETA: 0s - loss: 0.4961 - acc: 0.7611Epoch 00030: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4915 - acc: 0.7673 - val_loss: 0.4511 - val_acc: 0.7910\n",
      "Epoch 32/100\n",
      "600/623 [===========================>..] - ETA: 0s - loss: 0.4841 - acc: 0.7800Epoch 00031: val_loss improved from 0.45096 to 0.44530, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.4834 - acc: 0.7809 - val_loss: 0.4453 - val_acc: 0.7910\n",
      "Epoch 33/100\n",
      "540/623 [=========================>....] - ETA: 0s - loss: 0.4810 - acc: 0.7796Epoch 00032: val_loss improved from 0.44530 to 0.44340, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.4857 - acc: 0.7777 - val_loss: 0.4434 - val_acc: 0.7929\n",
      "Epoch 34/100\n",
      "560/623 [=========================>....] - ETA: 0s - loss: 0.4719 - acc: 0.7973Epoch 00033: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4825 - acc: 0.7913 - val_loss: 0.4479 - val_acc: 0.7929\n",
      "Epoch 35/100\n",
      "580/623 [==========================>...] - ETA: 0s - loss: 0.4916 - acc: 0.7966Epoch 00034: val_loss improved from 0.44340 to 0.43944, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.4843 - acc: 0.8026 - val_loss: 0.4394 - val_acc: 0.8116\n",
      "Epoch 36/100\n",
      "580/623 [==========================>...] - ETA: 0s - loss: 0.4814 - acc: 0.7784Epoch 00035: val_loss improved from 0.43944 to 0.43765, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.4770 - acc: 0.7809 - val_loss: 0.4377 - val_acc: 0.8078\n",
      "Epoch 37/100\n",
      "500/623 [=======================>......] - ETA: 0s - loss: 0.4513 - acc: 0.8070Epoch 00036: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4784 - acc: 0.7857 - val_loss: 0.4436 - val_acc: 0.7948\n",
      "Epoch 38/100\n",
      "500/623 [=======================>......] - ETA: 0s - loss: 0.4847 - acc: 0.7780Epoch 00037: val_loss improved from 0.43765 to 0.43334, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.4764 - acc: 0.7857 - val_loss: 0.4333 - val_acc: 0.8078\n",
      "Epoch 39/100\n",
      "600/623 [===========================>..] - ETA: 0s - loss: 0.4834 - acc: 0.7933Epoch 00038: val_loss improved from 0.43334 to 0.43148, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.4823 - acc: 0.7945 - val_loss: 0.4315 - val_acc: 0.8134\n",
      "Epoch 40/100\n",
      "520/623 [========================>.....] - ETA: 0s - loss: 0.4607 - acc: 0.7923Epoch 00039: val_loss improved from 0.43148 to 0.42938, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.4679 - acc: 0.7881 - val_loss: 0.4294 - val_acc: 0.8041\n",
      "Epoch 41/100\n",
      "520/623 [========================>.....] - ETA: 0s - loss: 0.4746 - acc: 0.7865Epoch 00040: val_loss improved from 0.42938 to 0.42831, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.4767 - acc: 0.7897 - val_loss: 0.4283 - val_acc: 0.8078\n",
      "Epoch 42/100\n",
      "520/623 [========================>.....] - ETA: 0s - loss: 0.4482 - acc: 0.7962Epoch 00041: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4616 - acc: 0.7905 - val_loss: 0.4320 - val_acc: 0.7985\n",
      "Epoch 43/100\n",
      "620/623 [============================>.] - ETA: 0s - loss: 0.4670 - acc: 0.7944Epoch 00042: val_loss improved from 0.42831 to 0.42567, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.4663 - acc: 0.7937 - val_loss: 0.4257 - val_acc: 0.8097\n",
      "Epoch 44/100\n",
      "620/623 [============================>.] - ETA: 0s - loss: 0.4548 - acc: 0.8024Epoch 00043: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4564 - acc: 0.8010 - val_loss: 0.4269 - val_acc: 0.8116\n",
      "Epoch 45/100\n",
      "540/623 [=========================>....] - ETA: 0s - loss: 0.4423 - acc: 0.8074Epoch 00044: val_loss improved from 0.42567 to 0.42230, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.4602 - acc: 0.7937 - val_loss: 0.4223 - val_acc: 0.8060\n",
      "Epoch 46/100\n",
      "520/623 [========================>.....] - ETA: 0s - loss: 0.4509 - acc: 0.8038Epoch 00045: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4514 - acc: 0.8098 - val_loss: 0.4243 - val_acc: 0.8078\n",
      "Epoch 47/100\n",
      "540/623 [=========================>....] - ETA: 0s - loss: 0.4608 - acc: 0.7870Epoch 00046: val_loss improved from 0.42230 to 0.42024, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.4527 - acc: 0.7937 - val_loss: 0.4202 - val_acc: 0.8078\n",
      "Epoch 48/100\n",
      "520/623 [========================>.....] - ETA: 0s - loss: 0.4618 - acc: 0.8000Epoch 00047: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4598 - acc: 0.7986 - val_loss: 0.4218 - val_acc: 0.8060\n",
      "Epoch 49/100\n",
      "600/623 [===========================>..] - ETA: 0s - loss: 0.4502 - acc: 0.8042Epoch 00048: val_loss improved from 0.42024 to 0.41901, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.4492 - acc: 0.8042 - val_loss: 0.4190 - val_acc: 0.8041\n",
      "Epoch 50/100\n",
      "600/623 [===========================>..] - ETA: 0s - loss: 0.4560 - acc: 0.8042Epoch 00049: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4504 - acc: 0.8074 - val_loss: 0.4241 - val_acc: 0.8041\n",
      "Epoch 51/100\n",
      "620/623 [============================>.] - ETA: 0s - loss: 0.4365 - acc: 0.8161Epoch 00050: val_loss improved from 0.41901 to 0.41836, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.4351 - acc: 0.8170 - val_loss: 0.4184 - val_acc: 0.8041\n",
      "Epoch 52/100\n",
      "520/623 [========================>.....] - ETA: 0s - loss: 0.4425 - acc: 0.8010Epoch 00051: val_loss improved from 0.41836 to 0.41733, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.4389 - acc: 0.8010 - val_loss: 0.4173 - val_acc: 0.8078\n",
      "Epoch 53/100\n",
      "580/623 [==========================>...] - ETA: 0s - loss: 0.4512 - acc: 0.8086Epoch 00052: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4549 - acc: 0.8050 - val_loss: 0.4194 - val_acc: 0.8060\n",
      "Epoch 54/100\n",
      "480/623 [======================>.......] - ETA: 0s - loss: 0.4414 - acc: 0.8063Epoch 00053: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4518 - acc: 0.7986 - val_loss: 0.4226 - val_acc: 0.8022\n",
      "Epoch 55/100\n",
      "560/623 [=========================>....] - ETA: 0s - loss: 0.4617 - acc: 0.7991Epoch 00054: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4540 - acc: 0.8050 - val_loss: 0.4188 - val_acc: 0.8022\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "560/623 [=========================>....] - ETA: 0s - loss: 0.4452 - acc: 0.8027Epoch 00055: val_loss improved from 0.41733 to 0.41521, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.4425 - acc: 0.8034 - val_loss: 0.4152 - val_acc: 0.8060\n",
      "Epoch 57/100\n",
      "600/623 [===========================>..] - ETA: 0s - loss: 0.4538 - acc: 0.7917Epoch 00056: val_loss improved from 0.41521 to 0.41499, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.4491 - acc: 0.7929 - val_loss: 0.4150 - val_acc: 0.8116\n",
      "Epoch 58/100\n",
      "540/623 [=========================>....] - ETA: 0s - loss: 0.4415 - acc: 0.7935Epoch 00057: val_loss improved from 0.41499 to 0.41399, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.4450 - acc: 0.7897 - val_loss: 0.4140 - val_acc: 0.8078\n",
      "Epoch 59/100\n",
      "600/623 [===========================>..] - ETA: 0s - loss: 0.4383 - acc: 0.8100Epoch 00058: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4393 - acc: 0.8106 - val_loss: 0.4145 - val_acc: 0.8078\n",
      "Epoch 60/100\n",
      "620/623 [============================>.] - ETA: 0s - loss: 0.4381 - acc: 0.8129Epoch 00059: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4367 - acc: 0.8138 - val_loss: 0.4151 - val_acc: 0.8022\n",
      "Epoch 61/100\n",
      "520/623 [========================>.....] - ETA: 0s - loss: 0.4507 - acc: 0.8048Epoch 00060: val_loss improved from 0.41399 to 0.41281, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.4430 - acc: 0.8034 - val_loss: 0.4128 - val_acc: 0.8134\n",
      "Epoch 62/100\n",
      "620/623 [============================>.] - ETA: 0s - loss: 0.4391 - acc: 0.8153Epoch 00061: val_loss improved from 0.41281 to 0.41230, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.4378 - acc: 0.8162 - val_loss: 0.4123 - val_acc: 0.8097\n",
      "Epoch 63/100\n",
      "620/623 [============================>.] - ETA: 0s - loss: 0.4492 - acc: 0.8073Epoch 00062: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4476 - acc: 0.8082 - val_loss: 0.4141 - val_acc: 0.7985\n",
      "Epoch 64/100\n",
      "580/623 [==========================>...] - ETA: 0s - loss: 0.4338 - acc: 0.8155Epoch 00063: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4376 - acc: 0.8122 - val_loss: 0.4209 - val_acc: 0.8172\n",
      "Epoch 65/100\n",
      "600/623 [===========================>..] - ETA: 0s - loss: 0.4524 - acc: 0.7975Epoch 00064: val_loss improved from 0.41230 to 0.41076, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.4506 - acc: 0.7978 - val_loss: 0.4108 - val_acc: 0.8116\n",
      "Epoch 66/100\n",
      "600/623 [===========================>..] - ETA: 0s - loss: 0.4488 - acc: 0.7992Epoch 00065: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4460 - acc: 0.8018 - val_loss: 0.4110 - val_acc: 0.8116\n",
      "Epoch 67/100\n",
      "580/623 [==========================>...] - ETA: 0s - loss: 0.4321 - acc: 0.8095Epoch 00066: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4346 - acc: 0.8066 - val_loss: 0.4191 - val_acc: 0.8116\n",
      "Epoch 68/100\n",
      "600/623 [===========================>..] - ETA: 0s - loss: 0.4303 - acc: 0.8133Epoch 00067: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4390 - acc: 0.8098 - val_loss: 0.4120 - val_acc: 0.8116\n",
      "Epoch 69/100\n",
      "560/623 [=========================>....] - ETA: 0s - loss: 0.4261 - acc: 0.8223Epoch 00068: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4316 - acc: 0.8170 - val_loss: 0.4237 - val_acc: 0.8209\n",
      "Epoch 70/100\n",
      "500/623 [=======================>......] - ETA: 0s - loss: 0.4278 - acc: 0.8170Epoch 00069: val_loss improved from 0.41076 to 0.41046, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.4325 - acc: 0.8130 - val_loss: 0.4105 - val_acc: 0.8078\n",
      "Epoch 71/100\n",
      "600/623 [===========================>..] - ETA: 0s - loss: 0.4505 - acc: 0.7925Epoch 00070: val_loss improved from 0.41046 to 0.40916, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.4415 - acc: 0.8002 - val_loss: 0.4092 - val_acc: 0.8134\n",
      "Epoch 72/100\n",
      "560/623 [=========================>....] - ETA: 0s - loss: 0.4432 - acc: 0.8071Epoch 00071: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4419 - acc: 0.8058 - val_loss: 0.4108 - val_acc: 0.8078\n",
      "Epoch 73/100\n",
      "600/623 [===========================>..] - ETA: 0s - loss: 0.4336 - acc: 0.8125Epoch 00072: val_loss improved from 0.40916 to 0.40853, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.4324 - acc: 0.8106 - val_loss: 0.4085 - val_acc: 0.8209\n",
      "Epoch 74/100\n",
      "560/623 [=========================>....] - ETA: 0s - loss: 0.4258 - acc: 0.8134Epoch 00073: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4334 - acc: 0.8058 - val_loss: 0.4099 - val_acc: 0.8116\n",
      "Epoch 75/100\n",
      "520/623 [========================>.....] - ETA: 0s - loss: 0.4332 - acc: 0.8144Epoch 00074: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4281 - acc: 0.8082 - val_loss: 0.4094 - val_acc: 0.8116\n",
      "Epoch 76/100\n",
      "540/623 [=========================>....] - ETA: 0s - loss: 0.4303 - acc: 0.8222Epoch 00075: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4285 - acc: 0.8170 - val_loss: 0.4090 - val_acc: 0.8134\n",
      "Epoch 77/100\n",
      "540/623 [=========================>....] - ETA: 0s - loss: 0.4285 - acc: 0.8185Epoch 00076: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4270 - acc: 0.8194 - val_loss: 0.4115 - val_acc: 0.8172\n",
      "Epoch 78/100\n",
      "580/623 [==========================>...] - ETA: 0s - loss: 0.4278 - acc: 0.8172Epoch 00077: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4250 - acc: 0.8186 - val_loss: 0.4086 - val_acc: 0.8097\n",
      "Epoch 79/100\n",
      "540/623 [=========================>....] - ETA: 0s - loss: 0.4340 - acc: 0.8148Epoch 00078: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4407 - acc: 0.8058 - val_loss: 0.4099 - val_acc: 0.8134\n",
      "Epoch 80/100\n",
      "620/623 [============================>.] - ETA: 0s - loss: 0.4306 - acc: 0.8081Epoch 00079: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4307 - acc: 0.8074 - val_loss: 0.4088 - val_acc: 0.8116\n",
      "Epoch 81/100\n",
      "600/623 [===========================>..] - ETA: 0s - loss: 0.4052 - acc: 0.8250Epoch 00080: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4133 - acc: 0.8250 - val_loss: 0.4085 - val_acc: 0.8116\n",
      "Epoch 82/100\n",
      "540/623 [=========================>....] - ETA: 0s - loss: 0.4178 - acc: 0.8130Epoch 00081: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4260 - acc: 0.8138 - val_loss: 0.4114 - val_acc: 0.8153\n",
      "Epoch 83/100\n",
      "520/623 [========================>.....] - ETA: 0s - loss: 0.4135 - acc: 0.8240Epoch 00082: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4237 - acc: 0.8186 - val_loss: 0.4088 - val_acc: 0.8153\n",
      "Epoch 84/100\n",
      "540/623 [=========================>....] - ETA: 0s - loss: 0.4382 - acc: 0.8083Epoch 00083: val_loss improved from 0.40853 to 0.40778, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.4249 - acc: 0.8170 - val_loss: 0.4078 - val_acc: 0.8153\n",
      "Epoch 85/100\n",
      "580/623 [==========================>...] - ETA: 0s - loss: 0.4218 - acc: 0.8198Epoch 00084: val_loss improved from 0.40778 to 0.40753, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.4208 - acc: 0.8194 - val_loss: 0.4075 - val_acc: 0.8116\n",
      "Epoch 86/100\n",
      "560/623 [=========================>....] - ETA: 0s - loss: 0.4208 - acc: 0.8170Epoch 00085: val_loss improved from 0.40753 to 0.40741, saving model to ../output/titanic.model.best.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "623/623 [==============================] - 0s - loss: 0.4278 - acc: 0.8130 - val_loss: 0.4074 - val_acc: 0.8134\n",
      "Epoch 87/100\n",
      "540/623 [=========================>....] - ETA: 0s - loss: 0.4214 - acc: 0.8148Epoch 00086: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4162 - acc: 0.8202 - val_loss: 0.4141 - val_acc: 0.8060\n",
      "Epoch 88/100\n",
      "520/623 [========================>.....] - ETA: 0s - loss: 0.4326 - acc: 0.8260Epoch 00087: val_loss improved from 0.40741 to 0.40677, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.4253 - acc: 0.8323 - val_loss: 0.4068 - val_acc: 0.8134\n",
      "Epoch 89/100\n",
      "540/623 [=========================>....] - ETA: 0s - loss: 0.4000 - acc: 0.8241Epoch 00088: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4162 - acc: 0.8130 - val_loss: 0.4076 - val_acc: 0.8172\n",
      "Epoch 90/100\n",
      "580/623 [==========================>...] - ETA: 0s - loss: 0.4188 - acc: 0.8250Epoch 00089: val_loss improved from 0.40677 to 0.40583, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.4162 - acc: 0.8258 - val_loss: 0.4058 - val_acc: 0.8097\n",
      "Epoch 91/100\n",
      "540/623 [=========================>....] - ETA: 0s - loss: 0.4159 - acc: 0.8241Epoch 00090: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4194 - acc: 0.8226 - val_loss: 0.4059 - val_acc: 0.8190\n",
      "Epoch 92/100\n",
      "540/623 [=========================>....] - ETA: 0s - loss: 0.4129 - acc: 0.8370Epoch 00091: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4161 - acc: 0.8283 - val_loss: 0.4084 - val_acc: 0.8209\n",
      "Epoch 93/100\n",
      "560/623 [=========================>....] - ETA: 0s - loss: 0.4282 - acc: 0.8107Epoch 00092: val_loss improved from 0.40583 to 0.40543, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.4219 - acc: 0.8194 - val_loss: 0.4054 - val_acc: 0.8134\n",
      "Epoch 94/100\n",
      "560/623 [=========================>....] - ETA: 0s - loss: 0.4107 - acc: 0.8223Epoch 00093: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4111 - acc: 0.8218 - val_loss: 0.4100 - val_acc: 0.8228\n",
      "Epoch 95/100\n",
      "500/623 [=======================>......] - ETA: 0s - loss: 0.4134 - acc: 0.8150Epoch 00094: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4201 - acc: 0.8130 - val_loss: 0.4088 - val_acc: 0.8209\n",
      "Epoch 96/100\n",
      "560/623 [=========================>....] - ETA: 0s - loss: 0.4109 - acc: 0.8241Epoch 00095: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4048 - acc: 0.8234 - val_loss: 0.4060 - val_acc: 0.8246\n",
      "Epoch 97/100\n",
      "560/623 [=========================>....] - ETA: 0s - loss: 0.4219 - acc: 0.8250Epoch 00096: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4162 - acc: 0.8234 - val_loss: 0.4064 - val_acc: 0.8265\n",
      "Epoch 98/100\n",
      "580/623 [==========================>...] - ETA: 0s - loss: 0.4269 - acc: 0.8190Epoch 00097: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4202 - acc: 0.8218 - val_loss: 0.4057 - val_acc: 0.8265\n",
      "Epoch 99/100\n",
      "560/623 [=========================>....] - ETA: 0s - loss: 0.4013 - acc: 0.8259Epoch 00098: val_loss did not improve\n",
      "623/623 [==============================] - 0s - loss: 0.4121 - acc: 0.8202 - val_loss: 0.4073 - val_acc: 0.8284\n",
      "Epoch 100/100\n",
      "560/623 [=========================>....] - ETA: 0s - loss: 0.4189 - acc: 0.8125Epoch 00099: val_loss improved from 0.40543 to 0.40453, saving model to ../output/titanic.model.best.hdf5\n",
      "623/623 [==============================] - 0s - loss: 0.4194 - acc: 0.8106 - val_loss: 0.4045 - val_acc: 0.8078\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "checkpointer = ModelCheckpoint(filepath=model_weights_file, verbose=1, save_best_only=True)\n",
    "stopper = EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=10, verbose=1, mode='auto')\n",
    "hist = model.fit(X_train, y_train, epochs=100, batch_size=20, validation_split=0.3,\n",
    "                 callbacks=[checkpointer, stopper], \n",
    "                 verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "736/891 [=======================>......] - ETA: 0s\n",
      "Training Accuracy: 0.822109989646\n"
     ]
    }
   ],
   "source": [
    "# Load the weights that yielded the best validation accuracy\n",
    "model.load_weights(model_weights_file)\n",
    "\n",
    "# Evaluate the model on the training set\n",
    "score = model.evaluate(X_train, y_train)\n",
    "print(\"\\nTraining Accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(418, 11)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      "PassengerId    418 non-null int64\n",
      "Pclass         418 non-null int64\n",
      "Name           418 non-null object\n",
      "Sex            418 non-null object\n",
      "Age            332 non-null float64\n",
      "SibSp          418 non-null int64\n",
      "Parch          418 non-null int64\n",
      "Ticket         418 non-null object\n",
      "Fare           417 non-null float64\n",
      "Cabin          91 non-null object\n",
      "Embarked       418 non-null object\n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# Load test data\n",
    "df_test_raw = pd.read_csv(test_file)\n",
    "print(df_test_raw.shape)\n",
    "df_test_raw.head()\n",
    "df_test_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before scaling: \n",
      "   PassengerId  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked  \\\n",
      "0          892       3    1  34.5      0      0   7.8292         1   \n",
      "1          893       3    0  47.0      1      0   7.0000         2   \n",
      "2          894       2    1  62.0      0      0   9.6875         1   \n",
      "3          895       3    1  27.0      0      0   8.6625         2   \n",
      "4          896       3    0  22.0      1      1  12.2875         2   \n",
      "\n",
      "   Adult_Or_Minor  Senior_Citizen        ...         Ticket10  Ticket11  \\\n",
      "0               1               1        ...                0         0   \n",
      "1               1               1        ...                0         0   \n",
      "2               1               1        ...                0         0   \n",
      "3               1               1        ...                0         0   \n",
      "4               1               1        ...                0         0   \n",
      "\n",
      "   Ticket12  Ticket13  Ticket14  Ticket15  Ticket16  Ticket17  In_Cabin  \\\n",
      "0         0         0         0         0         0         0         0   \n",
      "1         0         0         0         0         0         0         0   \n",
      "2         0         0         0         0         0         0         0   \n",
      "3         0         0         0         0         0         0         0   \n",
      "4         0         0         0         0         0         0         0   \n",
      "\n",
      "   Number_Of_Cabins  \n",
      "0                 0  \n",
      "1                 0  \n",
      "2                 0  \n",
      "3                 0  \n",
      "4                 0  \n",
      "\n",
      "[5 rows x 119 columns]\n",
      "After scaling: \n",
      "   0    1         2      3         4         5    6    7    8    9   ...   \\\n",
      "0  1.0  1.0  0.452723  0.000  0.000000  0.015282  0.5  1.0  1.0  0.0 ...    \n",
      "1  1.0  0.0  0.617566  0.125  0.000000  0.013663  1.0  1.0  1.0  0.1 ...    \n",
      "2  0.5  1.0  0.815377  0.000  0.000000  0.018909  0.5  1.0  1.0  0.0 ...    \n",
      "3  1.0  1.0  0.353818  0.000  0.000000  0.016908  1.0  1.0  1.0  0.0 ...    \n",
      "4  1.0  0.0  0.287881  0.125  0.111111  0.023984  1.0  1.0  1.0  0.2 ...    \n",
      "\n",
      "   108  109  110  111  112  113  114  115  116  117  \n",
      "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "\n",
      "[5 rows x 118 columns]\n",
      "(418, 118)\n",
      "[ 1.          1.          0.45272321  0.          0.          0.01528158\n",
      "  0.5         1.          1.          0.          1.          0.02983973\n",
      "  0.625       0.06        0.          0.18867925  0.75609756  0.85393256\n",
      "  0.84444445  0.98888886  0.13333334  0.          0.5         0.94252872\n",
      "  0.15555556  0.          0.49411765  0.74712646  0.92372882  0.83471072\n",
      "  0.94262296  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.2         0.05263158\n",
      "  0.36538461  0.30769232  0.71249998  0.50515461  0.42982456  0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "# Prepare the data for testing\n",
    "df_test = prep_data(df_test_raw)\n",
    "\n",
    "# Construct the X array\n",
    "X_test = np.array(df_test)[:,:]\n",
    "X_test = X_test.astype('float32')\n",
    "print(X_test.shape)\n",
    "print(X_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.88791049  0.11443626]\n"
     ]
    }
   ],
   "source": [
    "# Predict for test data\n",
    "y_test = model.predict(X_test)\n",
    "print(y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save predictions\n",
    "with open(pred_file, 'w') as f:\n",
    "    f.write('PassengerId,Survived\\n')\n",
    "    for index, y_hat in enumerate(y_test):\n",
    "        prediction = np.argmax(y_hat)\n",
    "        f.write(str(int(df_test_raw.iloc[index]['PassengerId'])) + ',' + str(prediction)+'\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
